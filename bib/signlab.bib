@phdthesis{boers:21,
  title = {Learning to use space: A study into the SL2 acquisition process of adult learners of Sign Language of the Netherlands},
  author = {Boers-Visker, Eveline},
  publisher = {Netherlands Graduate School of Linguistics {(LOT)}},
  year = {2020},
  url = {https://www.lotpublications.nl/Documents/569_fulltext.pdf},
  abstract = {This dissertation addresses the acquisition of Sign Language of the Netherlands (Nederlandse Gebarentaal, NGT) in adult learners with a spoken language background. These learners acquire a new language in a new modality, the visual-spatial modality, which differs from the oral-auditory modality of their native language, Dutch. One of the modality-specific linguistic features attested in signed languages, but not in spoken languages, is the use of space to express grammatical and topographical relations. Our knowledge of the acquisition of linguistic devices related to the use of space (e.g., pointing signs, agreement verbs, classifier predicates and signs marked for location), and of appropriate pedagogical practices to teach these structures, is very limited. This thesis contributes to filling this gap by improving our understanding of processes underlying the acquisition of these devices in L2-learners of NGT, and by investigating whether certain pedagogical practices, which have been shown to be effective for L2-learners of a spoken language, would facilitate the acquisition of these devices. Four studies were carried out. The first three studies, in which we analyze (semi-)natural and elicited production data of novel NGT learners who were followed longitudinally, serve as basis for the fourth study, in which we investigate whether learners benefit from pedagogical interventions aimed at focusing their attention on the form-meaning mappings of one of the devices under investigation, agreement verb forms. This dissertation provides valuable information for practitioners in the field, and adds to our understanding of the intersecting fields of sign language linguistics, second language acquisition and pedagogy, as well as gesture studies.}
}

@article{boers:20,
  title = {Space oddities: The acquisition of agreement verbs by L2 learners of Sign Language of the Netherlands},
  author = {Boers-visker, Eveline and Pfau, Roland},
  publisher = {Wiley Online Library},
  journal = {The Modern Language Journal},
  volume = {104},
  number = {4},
  pages = {757--780},
  year = {2020},
  doi = {10.1111/modl.12676},
  url = {https://onlinelibrary.wiley.com/doi/full/10.1111/modl.12676},
  abstract = {This article reports the results of the first longitudinal study that systematically investigates the acquisition of verb agreement by hearing learners of a sign language. During a 2-year period, 14 novel learners of Sign Language of the Netherlands (NGT) with a spoken language background performed an elicitation task 15 times. Seven deaf native signers and NGT teachers performed the same task to serve as a benchmark group. The results obtained show that for some learners, the verb agreement system of NGT was difficult to master, despite numerous examples in the input. As compared to the benchmark group, learners tended to omit agreement markers on verbs that could be modified, did not always correctly use established locations associated with discourse referents, and made characteristic errors with respect to properties that are important in the expression of agreement (movement and orientation). The outcomes of the study are of value to practitioners in the field, as they are informative with regard to the nature of the learning process during the first stages of learning a sign language.}
}

@article{boven:21a,
  title = {Phonological restrictions on nominal pluralization in Sign Language of the Netherlands: evidence from corpus and elicited data},
  author = {Boven, Cindy van},
  publisher = {De Gruyter Mouton},
  journal = {Folia Linguistica},
  year = {2021},
  doi = {10.1515/flin-2021-2039},
  url = {https://www.degruyter.com/document/doi/10.1515/flin-2021-2039/html},
  abstract = {This study focuses on nominal pluralization in Sign Language of the Netherlands (NGT). The aim is to offer a comprehensive description of nominal pluralization processes in the language, based on both corpus data and elicited data, taking into account potential phonological restrictions. The results reveal that NGT nouns can undergo several pluralization processes, the main ones being simple reduplication (i.e., repeating the noun sign at one location) and sideward reduplication (i.e., repeating the noun sign while moving the hand sideward). The choice of pluralization process depends on phonological properties of the base noun: (i) nouns that are body-anchored or involve a complex movement undergo simple reduplication; (ii) nouns articulated at the lateral side of the signing space undergo sideward reduplication; (iii) nouns articulated on the midsagittal plane can undergo both simple and sideward reduplication. Strikingly, the data show considerable variation, and all types of nouns can be zero-marked, that is, plural marking on the noun is not obligatory. The results further suggest that all nouns can undergo at least one type of reduplication. Thus, while phonological properties of the base noun influence the type of reduplication, they do not block reduplication altogether. Plural reduplication in NGT is therefore less constrained than has been reported for other sign languages, where certain noun types cannot undergo reduplication. This shows that reduplication – despite being iconically motivated – is subject to language-specific grammatical constraints.}
}

@inproceedings{boven:21b,
  title = {Fill the gap: A novel test to elicit nominal plurals in Sign Language of the Netherlands},
  author = {Boven, Cindy van},
  publisher = {FEAST. Formal and Experimental Advances in Sign Language Theory},
  volume = {3},
  pages = {56--67},
  year = {2020},
  doi = {10.31009/FEAST.i3.05},
  url = {https://www.signlab-amsterdam.nl/publications/boven21b.pdf},
  abstract = {The present study introduces a novel gap-filling test to elicit plural nouns in Sign Language of the Netherlands (NGT). As of yet, nominal plurals in NGT have not been described in detail, as eliciting plural nouns is not without challenges. In previous research on NGT (Zwitserlood and Nijhof 1999), native signers were asked to describe pictures of plural objects. However, when describing pictures, the signers automatically also expressed the spatial distribution of the objects depicted on the stimulus picture, using localization. As a consequence, it remains unclear what ‘pure’ plurals – without localization – look like. The goal of our gap-filling task is to disentangle pluralization from localization: participants are asked to insert plural nouns in signed sentence contexts where the spatial distribution of the referents is irrelevant. After piloting the task, five deaf native signers participated. The task succeeded in eliciting pure plural forms that were not spatially distributed, and the results show that NGT optionally employs reduplication to mark the pure plural of nouns. We conclude that our gap-filling task successfully controls for localization, targeting the desired structure without using written language. In future studies, the gap-filling task can be applied to other sign languages, targeting also other construction types.}
}

@article{boven:21c,
  title = {Habituals in Sign Language of the Netherlands: A corpus-based study},
  author = {Boven, Cindy van and Oomen, Marloes},
  journal = {Linguistics in Amsterdam},
  volume = {14},
  number = {1},
  pages = {160--184},
  year = {2021},
  url = {https://www.researchgate.net/profile/Marloes-Oomen/publication/349685298_Habituals_in_Sign_Language_of_the_Netherlands_A_corpus-based_study/links/603cad7d4585158939d99668/Habituals-in-Sign-Language-of-the-Netherlands-A-corpus-based-study.pdf},
  abstract = {In this corpus-based study on habituals in Sign Language of the Netherlands (NGT), we investigate the manual and non-manual marking of habituality in naturalistic data. We show that both reduplication of the predicate and adverbials with a habitual flavor are used in habitual contexts, but both of these manual markers appear to be optional. As for non-manual markers, even more variation is attested; left-to-right head and body movements and narrowed eyes are the most frequently occurring non-manuals in habitual contexts but are by no means obligatory. The findings contrast with the results reported in two previous studies on habituals in NGT (Hoiting & Slobin 2001; Oomen 2016), which can be partially explained by the fact that these studies used elicitation methods. As such, the present study underscores the importance of using a combination of different methods in investigating linguistic phenomena.}
}

@inproceedings{khristoforova:21,
  title = {Question-answer pairs in Russian Sign Language: a corpus study},
  author = {Khristoforova, Evgeniia and Kimmelman, Vadim},
  publisher = {FEAST. Formal and Experimental Advances in Sign language Theory},
  volume = {4},
  pages = {101--112},
  issn = {2565-1781},
  year = {2021},
  doi = {10.31009/FEAST.i4.08},
  url = {https://www.signlab-amsterdam.nl/publications/khristoforova21.pdf},
  abstract = {We describe basic morphosyntactic and semantic properties of question-answer pairs(QAPs) collected from the online corpus of Russian Sign Language (RSL). We identified two classes of QAPs: classical and discourse QAPs, which are different in the semantic relation between the question and answer parts. We discovered that non-manual marking and word order in both types of QAPs are different from other constructions involving wh-signs, namely regular questions and free relative clauses. Guided by the similarity between non-manual marking of QAPs and role shift marking, we hypothesize on a possible grammaticalization process connecting the two constructions}
}

@article{kimmelman:20,
  title = {Argument structure of classifier predicates in Russian Sign Language},
  author = {Kimmelman, Vadim and Pfau, Roland and Aboh, Enoch O},
  publisher = {Springer},
  journal = {Natural Language \& Linguistic Theory},
  volume = {38},
  number = {2},
  pages = {539--579},
  year = {2020},
  doi = {10.1007/s11049-019-09448-9},
  url = {https://link.springer.com/content/pdf/10.1007/s11049-019-09448-9.pdf},
  abstract = {We analyze classifier predicates in Russian Sign Language (RSL) using a combination of naturalistic corpus and elicited data in order to determine their argument structure, and to test the generalization, based on research on other sign languages, that there is a clear relation between argument structure and classifier type (Benedicto and Brentari 2004). We propose that whole-entity classifier predicates are intransitive unaccusative, and that body-part classifier predicates are optionally transitive. Contrary to previous research on other sign languages, we argue that handling classifier predicates in RSL describe complex events with two subevents: one of handling, and one of movement, which are not necessarily causally connected. We further suggest that the ‘moving legs’ classifier predicate in RSL also describes a complex event consisting of two subevents. To account for these facts, we develop a formal analysis of classifier predicates in RSL. Specifically, we argue that whole-entity and body-part classifier handshapes are agreement markers, while handling classifier handshapes as well as the ‘moving legs’ classifier handshape represent an argument in combination with a verbal root. This casts doubt on the observation made in the literature that classifiers straightforwardly determine the argument structure of classifier predicates, since different classifiers in RSL represent different grammatical phenomena. In addition, we show that event structures associated with some classifier predicates are more complex than those associated with monoclausal structures in spoken languages.}
}

@incollection{kimmelman:21,
  title = {Information structure: Theoretical perspectives},
  author = {Kimmelman, Vadim and Pfau, Roland},
  publisher = {Routledge},
  booktitle = {The Routledge Handbook of Theoretical and Experimental Sign Language Research},
  pages = {591--613},
  year = {2021},
  url = {http://vadimkimmelman.com/papers/Kimmelman%20Pfau%202021%20IS.pdf},
  abstract = {This chapter discusses the terminology commonly used in the information structure literature: in particular, topic, focus, contrast, and emphasis. An important component of our discussion is the impact of the visual-gestural modality on the syntactic and prosodic encoding of information structure. Kimmelman argued that in RSL and NGT, doubling is also used for information structure-related functions, but proposed that the functions of doubling are better described as foregrounding. Information structure is a field of linguistics covered in numerous books and articles. Information structure in sign languages has also been investigated almost from the first days of sign linguistics; however, as is often the case, most of the available studies focus on a very small number of sign languages, and among these, American Sign Language is the one most prominently represented. The chapter aims to theoretical research, It discusses the few available experimental or psycholinguistic studies on information structure in sign languages.}
}

@phdthesis{klomp:21,
  title = {A descriptive grammar of Sign Language of the Netherlands},
  author = {Klomp, Ulrika},
  year = {2021},
  publisher = {Netherlands Graduate School of Linguistics {(LOT)}},
  abstract = {Sign Language of the Netherlands (Nederlandse Gebarentaal, NGT) is a minority language in the Netherlands, but has only recently gained legal recognition of this status. It is estimated that 60,000 people in the Netherlands sign NGT, of whom 10,000 are early onset deaf signers. This book is the first comprehensive descriptive grammar of NGT. It offers a detailed description of its phonology, morphology, and selected aspects of its syntax. Whenever possible, the linguistic phenomena are illustrated by naturalistic corpus data. The grammatical description is complemented by a brief overview of the socio-historical background of NGT and of the Dutch sign language community. The European SIGN-HUB project, of which this dissertation is a result, hosts a platform where a digital version of this grammar can be found, along with video fragments providing illustrations of many of the linguistic characteristics addressed in the book: www.sign-hub.eu/grammar. This resource may be used for cross-linguistic research, for the development of NGT acquisition materials, and as a reference work.},
  url = {https://www.researchgate.net/profile/Ulrika-Klomp-2/publication/351188644_A_descriptive_grammar_of_Sign_Language_of_the_Netherlands/links/60bdca06458515218f9a1558/A-descriptive-grammar-of-Sign-Language-of-the-Netherlands.pdf}
}

@article{lint:20,
  title = {From meaning to form and back in American Sign Language verbal classifier morphemes},
  author = {Lint, Vanja de},
  publisher = {Edinburgh University Press},
  journal = {Word Structure},
  volume = {13},
  number = {1},
  pages = {69--101},
  year = {2020},
  doi = {10.3366/word.2020.0160},
  url = {https://www.euppublishing.com/doi/10.3366/word.2020.0160},
  abstract = {In a seminal paper, Benedicto & Brentari (2004) present a theoretical proposal in which they analyze American Sign Language (ASL) classifier morphemes as instantiations of functional heads F1 and F2 that determine the external or internal position of the argument that lands in their specifier through a structural agreement relation. It has served as a ground for several follow-up studies investigating argument structure in sign language classifier constructions. However, their proposal requires both theoretical amendment and empirical corroboration. In this paper, I critically assess the proposal by Benedicto & Brentari (2004) and provide empirical support for a modified version.}
}

@article{oomen:20,
  title = {Spatial verbs are demonstration verbs},
  author = {Oomen, Marloes},
  journal = {Revista Lingu{\'\i}stica},
  volume = {16},
  number = {3},
  pages = {227--249},
  year = {2020},
  doi = {10.31513/linguistica.2020.v16n3a36966},
  url = {https://www.researchgate.net/profile/Marloes-Oomen/publication/349591032_Spatial_verbs_are_demonstration_verbs/links/60379931299bf1cc26edcac2/Spatial-verbs-are-demonstration-verbs.pdf},
  abstract = {The literature has been divided over the question of whether spatial verbs should be subsumed into a single verb class with agreement verbs. The main point of contention has been that, even if the nature of the elements that these verb types agree with differs, the morphosyntactic mechanism, i.e. a path movement, appears to be the same. Contributing to this debate, this corpus-based study scrutinizes the morphosyntactic properties of a set of spatial verbs in German Sign Language (DGS). It is shown that spatial verbs display striking variability in where they begin and end their movement in space. They may align with locations or person loci, but often they simply mark arbitrary locations, which may convey meaningful yet less specific information about the (direction of) movement of a referent relative to the signer. Furthermore, null subjects are found to occur remarkably often in constructions with spatial verbs, despite the absence of systematic subject marking on the verb itself. These results stand in contrast with those reported for regular agreement verbs in DGS (OOMEN, 2020), and thus provide support for a distinction between the two types. It is proposed that spatial verbs in DGS involve a demonstration component (cf. DAVIDSON, 2015) which ensures the recoverability of referents involved in the event denoted by the verb, thus loosening the restrictions on both agreement marking and subject drop that apply to regular agreement verbs. As such, spatial verbs are argued to be somewhere in between conventionalized lexical verbs and classifier predicates.}
}

@phdthesis{oomen:21a,
  title = {Iconicity as a mediator between verb semantics and morphosyntactic structure: a corpus-based study on verbs in German Sign Language},
  author = {Oomen, Marloes},
  publisher = {Netherlands Graduate School of Linguistics {(LOT)}},
  volume = {24},
  number = {1},
  pages = {132--141},
  year = {2021},
  abstract = {In many sign languages around the world, some verbs can express grammatical agreement with not just one but two arguments, while other verbs do not express agreement at all. Moreover, and rather curiously, there is a remarkable degree of semantic overlap across sign languages between verbs that possess agreement properties. It has been suggested that iconicity has some part to play in this: in sign languages, there is the potential for aspects of verb meaning to be iconically represented in a verb’s form. In this dissertation, I investigate how semantics and morphosyntactic structure interact in constructions containing verbs with varying agreement properties in German Sign Language (DGS), using naturalistic dialogues between signers from the DGS Corpus as the primary data source. I show that certain semantic properties – also known to govern transitivity marking in spoken languages – are predictive of verb type in DGS, where indeed systematic iconic mappings play a mediating role. The results enable the formulation of cross-linguistic predictions about the interplay between verb semantics and verb type in sign languages. A subsequent analysis of a range of morphosyntactic properties of different verb types leads up to the conclusion that even ‘plain’ verbs, in fact, grammatically agree with their arguments. This in turn motivates a unified syntactic analysis in terms of agreement of constructions with verbs that do and do not overtly express it, thus presenting a novel solution to the typological puzzle that supposedly only verbs of a (partially) semantically definable subset agree in DGS and other sign languages.},
  url = {https://www.researchgate.net/profile/Marloes-Oomen/publication/341178832_Iconicity_as_a_mediator_between_verb_semantics_and_morphosyntactic_structure_A_corpus-based_study_on_verbs_in_German_Sign_Language/links/5eb26e6f92851cbf7fa9492f/Iconicity-as-a-mediator-between-verb-semantics-and-morphosyntactic-structure-A-corpus-based-study-on-verbs-in-German-Sign-Language.pdf}
}

@book{oomen:21b,
  title = {Iconicity and Verb Agreement: A Corpus-Based Syntactic Analysis of German Sign Language},
  author = {Oomen, Marloes},
  publisher = {De Gruyter Mouton},
  volume = {15},
  year = {2021},
  url = {https://books.google.nl/books?hl=en&lr=&id=hw5QEAAAQBAJ&oi=fnd&pg=PP13&ots=HiMEkpbZjP&sig=K47YaIrlIk4oedkZASJt1gFNNcM&redir_esc=y#v=onepage&q&f=false},
  keywords = {textbook}
}

@book{pfau:21a,
  title = {Our Lives--Our Stories: Life Experiences of Elderly Deaf People},
  author = {Pfau, Roland and G{\"o}ksel, Asli and Hosemann, Jana},
  volume = {14},
  year = {2021},
  keywords = {textbook},
  publisher = {De Gruyter Mouton},
  abstract = {Sign languages are non-written languages. Given that the use of digital media and video recordings in documenting sign languages started only some 30 years ago, the life stories of Deaf elderly signers born in the 1930s-1940s have – except for a few scattered fragments in film – not been documented and are therefore under serious threat of being lost. The chapters compiled in this volume document important aspects of past and present experiences of elderly Deaf signers across Europe, as well as in Israel and the United States. Issues addressed include (i) historical events and how they were experienced by Deaf people, (ii) issues of identity and independence, (iii) aspects of language change, (iv) experiences of suppression and discrimination. The stories shared by elderly signers reveal intriguing, yet hidden, aspects of Deaf life. On the negative side, these include experiences of the Deaf in Nazi Germany and occupied countries and harsh practices in educational settings, to name a few. On the positive side, there are stories of resilience and vivid memories of school years and social and professional life. In this way, the volume contributes in a significant way to the preservation of the cultural and linguistic heritage of Deaf communities and sheds light on lesser known aspects against an otherwise familiar background.},
  doi = {10.1515/9783110701906},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110701906/html}
}

@incollection{pfau:21b,
  title = {Much more than a treasure: the life stories of elderly Deaf people},
  author = {Pfau, Roland and G{\"o}ksel, Asl{\i} and Hosemann, Jana},
  booktitle = {Our Lives--Our Stories: Life Experiences of Elderly Deaf People},
  publisher = {De Gruyter Mouton},
  volume = {14},
  pages = {1--15},
  year = {2021},
  doi = {10.1515/9783110701906-001},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110701906-001/html}
}

@incollection{pfau:21c,
  title = {Pink sign: Identity challenges, choices, and changes among elderly Deaf homosexuals in the Netherlands},
  author = {Pfau, Roland and Kampen, Annemieke van and Harterink, Menno},
  booktitle = {Our Lives--Our Stories: Life Experiences of Elderly Deaf People},
  publisher = {De Gruyter Mouton},
  volume = {14},
  pages = {129--167},
  year = {2021},
  doi = {10.1515/9783110701906-001},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110701906-006/html}
}

@incollection{pfau:21d,
  title = {Number in Sign Languages},
  author = {Pfau, Roland and Steinbach, Markus},
  booktitle = {The Oxford Handbook of Grammatical Number},
  pages = {644--660},
  year = {2021},
  doi = {10.1093/oxfordhb/9780198795858.013.31},
  url = {https://watermark.silverchair.com/303222023.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAsQwggLABgkqhkiG9w0BBwagggKxMIICrQIBADCCAqYGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMAM4265XWzaPig-A1AgEQgIICd4bTyMHkxH5x94H-3xgHeMC-KCtNdBW0tnBEJ16xiMm57KFcg7pgUnG8rqAhJYSBE3rX0vGkrTnDxt-lMawtzO5h7h-rx2lOIDnKzuByTbc4Tn9fi0TvuGjSqWqbFF7Tv8eU-2UmFcTbU28iHrp64ZGBpMY-8rxAdBW1K-sadkMVh0tzKgrfx76KZaAG2W_EnBX1xfdIW9hMaRrTeJ64rFAaKifrL8FrQ7hkyibqqEwaIMAsNkOE6nxzCRW8uZ8iSdKJMwAdIF5UYt9yvbjmavELriA2fzxYthELFPCfkH6L8wT10B0_DgKVwURP_SzyXrnSwKuIQspmpi9rxtIAPrPPvtULyka9B4mJN3_5bUmWCmHBIzg6dQMjoo9VnbE3LK3scgAr1QsUaZJZOcVMBJWbU9C70m60rItcNpvSBTYurjRjorX6cL9LIlXaTYHKauEyfRibi-5Mrxjya1uVY4j-oruZWuqQdXbtYl2ZiorXaUsHQFbYvuk2LLdlfjgRgpzkwdU-WEjY825ZZJzGjAnrSTovMk62RRKqzpHbzax3okEvARsZvc4u4i5CJOuCmR1UxtPtwwIVC2ruaiakCmpCh2BLx-VbOTmlqHoVLk6cn7-Uq_1T7N3fAKfDyvmH3FSmPl8trwFUSuAM2EHykj93r-Vgc4Fre7WWBFgX7uXv2GTnzHWzXPAUeCoqiqJyivNnkqwXSRkB9mMc2D7TR-76btmjAjnyMMLQ7sN0VuC0TdKPobDMd5gG3FYxZOlIWrTQ5orMacdav7NJNb_zLIhJMDiCtSQiyNIu-EXGCpQ8EFYAZsouLrwWE-QUkCFznZIc9L5Xtr0}
}

@book{quer:21,
  title = {The Routledge Handbook of Theoretical and Experimental Sign Language Research},
  author = {Quer, Josep and Pfau, Roland and Herrmann, Annika},
  publisher = {Routledge},
  year = {2021},
  doi = {10.4324/9781315754499},
  url = {https://www.taylorfrancis.com/books/edit/10.4324/9781315754499/routledge-handbook-theoretical-experimental-sign-language-research-josep-quer-roland-pfau-annika-herrmann},
  keywords = {textbook},
  abstract = {The Routledge Handbook of Theoretical and Experimental Sign Language Research bridges the divide between theoretical and experimental approaches to provide an up-to-date survey of key topics in sign language research. With 29 chapters written by leading and emerging scholars from around the world, this Handbook covers the following key areas: On the theoretical side, all crucial aspects of sign language grammar studied within formal frameworks such as Generative Grammar;　　 On the experimental side, theoretical accounts are supplemented by experimental evidence gained in psycho- and neurolinguistic studies;　 On the descriptive side, the main phenomena addressed in the reviewed scholarship are summarized in a way that is accessible to readers without previous knowledge of sign languages. Each chapter features an introduction, an overview of existing research, and a critical assessment of hypotheses and findings. The Routledge Handbook of Theoretical and Experimental Sign Language Research is key reading for all advanced students and researchers working at the intersection of sign language research, linguistics, psycholinguistics, and neurolinguistics.}
}

@inproceedings{wang:22,
  title = {Active Learning for Multilingual Fingerspelling Corpora},
  author = {Wang, Shuai and Nalisnick, Eric},
  booktitle = {Adaptive Experimental Design and Active Learning in the Real World},
  year = {2022},
  url = {https://www.signlab-amsterdam.nl/publications/Active_Learning_for_Multilingual_Fingerspelling_Corpora.pdf},
  abstract = {We apply active learning to help with data scarcity problems in sign languages. In particular, we perform a novel analysis of the effect of pre-training. Since many sign languages are linguistic descendants of French sign language, they share hand configurations, which pre-training can hopefully exploit. We test this hypothesis on American, Chinese, German, and Irish fingerspelling corpora. We do observe a benefit from pre-training, but this may be due to visual rather than linguistic similarities.}
}

@inproceedings{Roelofsen:21a,
  title = {Online evaluation of text-to-sign translation by deaf end users: Some methodological recommendations},
	author = {Roelofsen, Floris and Esselink, Lyke and Mende-Gillings, Shani and Meulder, Maartje de and Sijm, Nienke and Smeijers, Anika},
	booktitle = {Proceedings of the First International Workshop on Automatic Translation for Sign and Spoken Languages (AT4SSL)},
  publisher = {Association for Machine Translation in the Americas},
  pages = {82--87},
  year = {2021},
  address = {Virtual},
	url = {https://aclanthology.org/2021.mtsummit-at4ssl.9/},
  abstract = {{We present a number of methodological recommendations concerning the online evaluation of avatars for text-to-sign translation, focusing on the structure, format and length of the questionnaire, as well as methods for eliciting and faithfully transcribing responses.}}
}

@inproceedings{Roelofsen:21b,
  title = {Sign language translation in a healthcare setting},
  author = {Roelofsen, Floris and Esselink, Lyke and Mende-Gillings, Shani and Smeijers, Anika},
	booktitle = {Translation and Interpreting Technology (TRITON)},
  publisher = {INCOMA Ltd.},
	pages = {110-124},
	year = {2021},
  address = {Virtual},
  url = {http://triton-conference.org/proceedings/},
  abstract = {{Communication between healthcare professionals and deaf patients is challenging, and the current COVID-19 pandemic makes this issue even more acute. Sign language interpreters can often not enter hospitals and face masks make lipreading impossible. To address this urgent problem, we developed a system which allows healthcare professionals to translate sentences that are frequently used in the diagnosis and treatment of COVID-19 into Sign Language of the Netherlands (NGT). Translations are displayed by means of videos and avatar animations. The architecture of the system is such that it could be extended to other applications and other sign languages in a relatively straightforward way.}}
}

@inproceedings{Gemert:22,
  title = {First Steps Towards a Signing Avatar for Railway Travel Announcements in the {Netherlands}},
  author = {Gemert, Britt van and Cokart, Richard and Esselink, Lyke and Meulder, Maartje de and Sijm, Nienke and Roelofsen, Floris},
  booktitle = {Proceedings of the 7th International Workshop on Sign Language Translation and Avatar Technology (SLTAT): The Junction of the Visual and the Textual: Challenges and Perspectives},
  publisher = {European Language Resources Association},
  pages = {109--116},
  year = {2022},
  address = {Marseille, France},
  url = {https://aclanthology.org/2022.sltat-1.17.pdf},
  abstract = {This paper presents first steps towards a sign language avatar for communicating railway travel announcements in Dutch Sign Language. Taking an interdisciplinary approach, it demonstrates effective ways to employ co-design and focus group methods in the context of developing sign language technology, and presents several concrete findings and results obtained through co-design and focus group sessions which have not only led to improvements of our own prototype but may also inform the development of signing avatars for other languages and in other application domains.}
}

@unpublished{Corsel:20,
  title = {{Multidimensionality in Sign Language Synthesis: Translation of Dutch into Sign Language of the Netherlands}},
  author = {Corsel, Adriana},
  year = {2020},
  url = {https://dspace.uba.uva.nl/server/api/core/bitstreams/0bb6b586-7133-49ad-b722-2cfc08555dcc/content},
  keywords = {bachelorsthesis},
  abstract = {This paper explores the implementation of a translator to sign language, using the JASigning avatarsoftware. Specifically, translation of Dutch into Sign Language of the Netherlands (NGT). As Dutch has been translated to a textual version of NGT in previous research, this research translated from textual NGT to synthesised NGT, the output signed by an avatar. This is one of three papers, each focusing on a different aspect of the translator: Lexical Resources, the Signing Space, and Multidimensionality. This paper pertains to the latter, and thus attempts to implement multiple dimensions into the avatar: the manual and non-manual component, which are both necessary to properly articulate a sign. The non-manual component of a sign being, for example, a facial expression, a head shake, the posture ofthe signer, etc. Specifically, it attempts to implement the non-manual markers paired with interrogative and negative constructs in NGT. Although the scope of this project is limited, it could provide a decent foundation for further research.},
  note = {University of Amsterdam}
}

@unpublished{Mende-Gillings:20,
  title = {{The signing space for the synthesis of directional verbs in NGT}},
  author = {Mende-Gillings, Shani},
  year = {2020},
  url = {https://dspace.uba.uva.nl/server/api/core/bitstreams/6d3b7a8d-3927-4032-8837-a91659a48a9d/content},
  keywords = {bachelorsthesis},
  abstract = {Hearing parents who have deaf children are often put in a difficult position. They most likely know no sign language and resources for learning are limited and expensive. Research into sign language translation and synthesis has increased in the past two decades, due to a growing interest into making public spaces and services more accessible to Deaf people.<br> This research looks at the potential of a translator from Dutch to Dutch sign language (NGT) using a sign language avatar. In particular the focus lies on the synthesis of directional verbs, a critical grammatical component of sign language. The implementation is very limited and therefore the sentences it produces are not always comprehensible and the signs do not always look natural. It does, however, also demonstrate the potential of a sign language avatar as a tool for learning sign language.},
  note = {University of Amsterdam}
}

@unpublished{Esselink:20,
  title = {{Lexical resources for sign language synthesis: The translation of Dutch to Sign Language of the Netherlands}},
  author = {Esselink, Lyke},
  year =  {2020},
  url = {https://dspace.uba.uva.nl/server/api/core/bitstreams/90908bfa-d553-42f9-a191-2f9249686a9c/content},
  keywords = {bachelorsthesis},
  abstract = {Deaf people oftentimes have no choice but to communicate in the lingua franca of their country, despite the fact that this is a second language for them. Their ability to read and write is significantly worse than that of a hearing person. Additionally, if a deaf child is born into a family of hearing parents, it is vital that the parents communicate with the child through sign language as soon as possible, otherwise the language region of that child's brain will be underdeveloped. There are currently few resources available for people to learn Sign Language of the Netherlands (NGT). A tool that makes this possible would be invaluable to those who need it. <br> This thesis investigates what components are necessary to build a system that uses an avatar to translate a Dutch sentence to NGT. On the basis of the workings of NGT and previous research on the matter, three main components are devised and implemented: software for sign language synthesis, lexical resources for encoding signs, and grammatical resources for structuring sentences. Results show a proof of concept with a corpus of 2226 signs, the ability to make correct use of classifiers, and the abilities to fingerspell any word that is not in the corpus and convey numbers correctly. However, the corpus contains a number of errors and of which manual errors and unnatural mouth signs should particularly be improved. Moreover, further research is necessary to improve the comprehensibility of signs.},
  note = {University of Amsterdam}
}

@unpublished{Esselink:21,
  title = {Text-To-Sign Translation: Making Information Accessible},
  author = {Esselink, Lyke and Roelofsen, Floris},
  year = {2021},
  url = {https://www.signlab-amsterdam.nl/publications/SeminarSlides.pdf},
  keywords = {slides},
  note = {Seminar slides on the work of SignLab.}
}

@mastersthesis{gemert:22,
  title = {Co-designing a Sign Language Avatar for Railway Announcements},
  author = {Gemert, Britt van},
  school = {Radboud University},
  year = {2022},
  url = {https://www.signlab-amsterdam.nl/publications/van_Gemert.pdf},
  abstract = {Public transport organisations, such as Dutch railway operator Nederlandse Spoorwegen (NS), generally communicate important messages through spoken announcements in the train or station. As a result, Deaf people miss crucial information. Because of varying levels of reading proficiency, textual information is not always a solution. Moreover, video footage is not scalable and will not yield satisfactory results when individual video parts need an update. Virtual sign language avatars can provide consistent, anonymous and scalable translations. For the development of a comprehensible and fluent sign language avatar, collaboration between experts in language technology, avatar technology and sign language is fundamental. Unfortunately, inclusive approaches are not evident in existing technologies. To address these problems, we present a case study on co-designing a sign language avatar for the automatic translation of railway announcements into Sign Language of the Netherlands (NGT). For the initial design, video sign language translations of NS announcements created by the Dutch Sign Center were annotated and used for the translation basis. A scripted keyframe animation technique for the JASigning avatar engine makes it possible to efficiently create many variants of a given template, without expensive equipment. Three iterative co-design sessions took place with an interdisciplinary research team including deaf sign language experts. Simultaneously, hearing passengers from NS were consulted for additional remarks on the sign language avatar. Subsequently, multiple phrase variants of the system were evaluated within a diverse focus group audience to account for demographic differences. Combining the various disciplines led to mayor adjustments of the avatar (manual movements, facial expressions, mouthing, grammar, transitions between signs, camera angle and speed). With this case study, we aimed to effectively and inclusively develop sign language avatar technology. More research and focus groups are necessary to ensure high quality translations (improved mouthings, facial expressions and prosody), resulting in enhanced comprehensibility and natural appearance of the avatar.}
}

@unpublished{Jeu:22,
  title = {Using avatar animation software for sign language synthesis},
  author = {Jeu, Roel de},
  year =  {2022},
  url = {https://dspace.uba.uva.nl/server/api/core/bitstreams/5f83a355-f4c2-4bd6-b263-885a9d6a6df6/content},
  keywords = {bachelorsthesis},
  abstract = {Deaf people can have a reading and writing delay due to the fact that the sign language of their country is their first language. Most hearing people do not understand sign language. This causes a language barrier to exist between deaf and hearing people. While tools like Google Translate support many languages, not a single sign language is included. This research reduces the language barrier between deaf and hearing people by developing a synthesis tool for sign language. This research focuses on evaluating different gaming and Virtual Reality avatar animation software to create signing avatars used for the synthesis tool. It also looks at converting motion capture data in to animations for the signing avatars. This conversion is implemented fully for one avatar. The resulting animation shows some unnatural movement but looks promising.},
  note = {University of Amsterdam}
}

@unpublished{Gennissen:22,
  title = {Mouth visualizations on modern avatars as support for speech comprehension for the Dutch language and NGT},
  author = {Gennissen, Loes},
  year = {2022},
  url = {https://dspace.uba.uva.nl/bitstreams/a4d4666b-27aa-4a7f-99f8-e13621d2b91d/download},
  keywords = {bachelorsthesis},
  abstract = {This thesis explores the effect of mouth visualizations on modern avatars as support for speech comprehension. The mouth visualizations of the avatars were acquired by two state-of-the-art facial visualization methods in the field of deep learning and computer vision. An initial exploration was performed to inspect the possibilities and advantages of the two methods. Furthermore, the two methods were tested on their applicability to the Dutch language and the Dutch Sign Language (NGT). To analyze the effect of different kinds of avatars on speech comprehensibility, a survey experiment was conducted to gather information on the performance and opinions of participants.},
  note = {University of Amsterdam}
}

@unpublished{Atia:22,
  title = {Use of a modern avatar for sign language synthesis: Movement tracking of manual gestures},
  author = {Atia, Merel},
  year = {2022},
  url = {https://dspace.uba.uva.nl/bitstreams/7a1dbcc9-2e6f-428f-8e13-ee65c504399e/download},
  keywords = {bachelorsthesis},
  abstract = {It is of great importance to make Dutch Sign Language (NGT) accessible to hearing people in order to improve the relationship between the deaf and hearing communities. We want to achieve this by creating an application that converts Dutch text to NGT performed by an avatar. To achieve this, an avatar must be created that is able to perform the different components of speaking sign language. In this research, the approach will be to let the avatar adapt motions performed by real live NGT speakers using a motion tracker. The results of previous research showed that gestures with specific finger positions, mainly when fingers overlap, were difficult to track. This research solves this problem by recording a NGT speaker from different views, and combining the results using a rigid body transformation. This way, the number of detected outliers are reduced significantly. The addition of cameras provides more insight into depth usage and estimation of the z-axis. It enables to detect bodyparts that are blocked from the main camera, which leads to more accurate tracking of gestures.},
  note = {University of Amsterdam}
}


@unpublished{Shilo:21,
  title = {{Use of a modern avatar for sign language synthesis: Visualisation of non-manual NGT gestures}},
  author = {Shilo, Alon},
  year = {2021},
  url = {https://dspace.uba.uva.nl/bitstreams/fc79c65e-e35c-411e-bced-052a55ed8300/download},
  keywords = {bachelorsthesis},
  abstract = {This thesis explores the implementation for visualising the translation from Dutch sentences to the sign language of the Netherlands (NGT). This is one of three theses, each focusing on different parts of the avatar, which are eventually combined into one program. For this thesis, the goal is to implement a part of the non-manual side of NGT to create a proof of concept. The non-manual body parts of NGT include the head, face, shoulders and upper body. NGT is a complex language. Therefore it will take more time to completely visualize NGT using a new modern avatar, but this thesis provides a foundation for further research and implementation of the non-manual gestures of NGT.},
  note = {University of Amsterdam}
}

@unpublished{Vijver:21,
  title = {Use of a modern avatar for sign language synthesis: Hand animations and the signing space},
  author = {Vijver, Matthijs van de},
  year = {2021},
  url = {https://dspace.uba.uva.nl/bitstreams/128a1797-658b-49c2-8562-9cd1d3f81872/download},
  keywords = {bachelorsthesis},
  abstract = {For deaf people, the written and spoken language of their country is often their second language. The first language for most deaf people is the sign language of their country. Because deaf people often have a reading and writing delay and not many hearing people speak sign language, a barrier is formed between deaf people who speak sign language and hearing people who do not. To overcome this problem ’signing avatars’ have been researched in the past decade: 3D computer models that can perform sign language. For the Dutch sign language and many other sign languages, the animation techniques that are used for this are deprecated. This research is focused on using modern techniques for animating these signing avatars. A model was built that shows potential in using these modern techniques to perform signs that are described in a dedicated markup language.},
  note = {University of Amsterdam}
}


@unpublished{Hofwegen:21,
  title = {Modern avatar simulation for sign language synthesis: Hand configurations of the SiGML},
  author = {Hofwegen, Mark van},
  year = {2021},
  url = {https://dspace.uba.uva.nl/bitstreams/473c469e-4102-4133-9e53-e377263d5782/download},
  keywords = {bachelorsthesis},
  abstract = {Loss of hearing at young age has devastating effects on the development of a child. One of these effects is a learning deficit. This learning deficit can be strongly mitigated by introducing sign language as soon as deafness is diagnosed. However, most of deaf children are born to hearing parents who can not speak the Dutch Sign Language (NGT). Language acquisition of NGT is difficult for Dutch speaking people, since NGT has its own grammar and vocabulary. The main purpose of this thesis is to find out if modern avatar simulation techniques can be used to create a virtual sign language avatar to aid the learning process of NGT. Results show that modern software is applicable, but three main components are needed by the software in order to do so. A phonetic representation of the sign, a compatible rig with as many control points as needed by the phonetic representation and animation software to alter the orientation/position of the control points.},
  note = {University of Amsterdam}
}


@unpublished{Bleijlevens:20,
  title = {{Learn Sign Online! A proposal for an online platform to learn Dutch Sign Language}},
  author = {Bleijlevens, Jasmijn},
  year = {2020},
  url = {https://www.signlab-amsterdam.nl/publications/Bleijlevens-2020.pdf},
  keywords = {bachelorsthesis},
  abstract = {This project studies the possibilities of designing an online platform for acquiring Dutch Sign Language (NGT), specifically focused on parents of deaf children. Children need a lot of (diverse) language input to lay a groundwork for their language development and it is thus important that people in their surroundings speak a language the child can interpret. Over the past decades, a lot of different distance learning technology have been developed for second language acquisition. This research will look into NGT and discuss all the grammatical topics which should be explained to people wanting to learn the language. Then, different technologies and will analyse which would suit learning NGT the best. Lastly, the two research topics will be combined and a design for a platform is proposed.},
  note = {Amsterdam University College}
}

@article{sumer:20,
  title = {No effects of modality in development of locative expressions of space in signing and speaking children},
  author = {S{\"u}mer, Beyza and {\"O}zy{\"u}rek, Asl{\i}},
  publisher = {Cambridge University Press},
  journal = {Journal of Child Language},
  volume = {47},
  number = {6},
  pages = {1101--1131},
  year = {2020},
  doi = {10.1017/S0305000919000928},
  url = {https://www.cambridge.org/core/services/aop-cambridge-core/content/view/BBC33DFE646C026A6821511B4CD3CD68/S0305000919000928a.pdf/no-effects-of-modality-in-development-of-locative-expressions-of-space-in-signing-and-speaking-children.pdf},
  abstract = {Linguistic expressions of locative spatial relations in sign languages are mostly visually motivated representations of space involving mapping of entities and spatial relations between them onto the hands and the signing space. These are also morphologically complex forms. It is debated whether modality-specific aspects of spatial expressions modulate spatial language development differently in signing compared to speaking children. In a picture description task, we compared the use of locative expressions for containment, support, and occlusion relations by deaf children acquiring Turkish Sign Language and hearing children acquiring Turkish (age 3;5–9;11). Unlike previous reports suggesting a boosting effect of iconicity, and/or a hindering effect of morphological complexity of the locative forms in sign languages, our results show similar developmental patterns for signing and speaking children's acquisition of these forms. Our results suggest the primacy of cognitive development guiding the acquisition of locative expressions by speaking and signing children.}
}

@article{manhardt:20,
  title = {Iconicity in spatial language guides visual attention: A comparison between signers’ and speakers’ eye gaze during message preparation.},
  author = {Manhardt, Francie and {\"O}zy{\"u}rek, Asl{\i} and S{\"u}mer, Beyza and Mulder, Kimberley and Karad{\"o}ller, Dilay Z and Brouwer, Susanne},
  publisher = {American Psychological Association},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {46},
  number = {9},
  pages = {1735},
  year = {2020},
  doi = {10.1037/xlm0000843},
  url = {https://psycnet.apa.org/doiLanding?doi=10.1037%2Fxlm0000843},
  abstract = {To talk about space, spoken languages rely on arbitrary and categorical forms (e.g., left, right). In sign languages, however, the visual–spatial modality allows for iconic encodings (motivated form-meaning mappings) of space in which form and location of the hands bear resemblance to the objects and spatial relations depicted. We assessed whether the iconic encodings in sign languages guide visual attention to spatial relations differently than spatial encodings in spoken languages during message preparation at the sentence level. Using a visual world production eye-tracking paradigm, we compared 20 deaf native signers of Sign-Language-of-the-Netherlands and 20 Dutch speakers’ visual attention to describe left versus right configurations of objects (e.g., “pen is to the left/right of cup”). Participants viewed 4-picture displays in which each picture contained the same 2 objects but in different spatial relations (lateral [left/right], sagittal [front/behind], topological [in/on]) to each other. They described the target picture (left/right) highlighted by an arrow. During message preparation, signers, but not speakers, experienced increasing eye-gaze competition from other spatial configurations. This effect was absent during picture viewing prior to message preparation of relational encoding. Moreover, signers’ visual attention to lateral and/or sagittal relations was predicted by the type of iconicity (i.e., object and space resemblance vs. space resemblance only) in their spatial descriptions. Findings are discussed in relation to how “thinking for speaking” differs from “thinking for signing” and how iconicity can mediate the link between language and human experience and guides signers’ but not speakers’ attention to visual aspects of the world.}
}

@inproceedings{karadoller:21a,
  title = {Spatial language use predicts spatial memory of children: Evidence from sign, speech, and speech-plus-gesture},
  author = {Karadoller, Dilay Z and S{\"u}mer, Beyza and {\"U}nal, Ercenur and {\"O}zy{\"u}rek, Asl{\i}},
  booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume = {43},
  number = {43},
  year = {2021},
  issn = {1069-7977},
  url = {https://escholarship.org/content/qt4vp063gj/qt4vp063gj.pdf?t=qwi375&v=lg},
  abstract = {There is a strong relation between children’s exposure to spatial terms and their later memory accuracy. In the current study, we tested whether the production of spatial terms by children themselves predicts memory accuracy and whether and how language modality of these encodings modulates memory accuracy differently. Hearing child speakers of Turkish and deaf child signers of Turkish Sign Language described pictures of objects in various spatial relations to each other and later tested for their memory accuracy of these pictures in a surprise memory task. We found that having described the spatial relation between the objects predicted better memory accuracy. However, the modality of these descriptions in sign, speech, or speech-plus-gesture did not reveal differences in memory accuracy. We discuss the implications of these findings for the relation between spatial language, memory, and the modality of encoding.}
}

@article{karadoller:21b,
  title = {Effects and non-effects of late language exposure on spatial language development: Evidence from deaf adults and children},
  author = {Karad{\"o}ller, Dilay Z and S{\"u}mer, Beyza and {\"O}zy{\"u}rek, Asl{\i}},
  publisher = {Taylor \& Francis},
  journal = {Language Learning and Development},
  volume = {17},
  number = {1},
  pages = {1--25},
  year = {2021},
  doi = {10.1080/15475441.2020.1823846},
  url = {https://www.tandfonline.com/doi/pdf/10.1080/15475441.2020.1823846?needAccess=true},
  abstract = {Late exposure to the first language, as in the case of deaf children with hearing parents, hinders the production of linguistic expressions, even in adulthood. Less is known about the development of language soon after language exposure and if late exposure hinders all domains of language in children and adults. We compared late signing adults and children (MAge = 8;5) 2 years after exposure to sign language, to their age-matched native signing peers in expressions of two types of locative relations that are acquired in certain cognitive-developmental order: view-independent (IN-ON-UNDER) and view-dependent (LEFT-RIGHT). Late signing children and adults differed from native signers in their use of linguistic devices for view-dependent relations but not for view-independent relations. These effects were also modulated by the morphological complexity. Hindering effects of late language exposure on the development of language in children and adults are not absolute but are modulated by cognitive and linguistic complexity.}
}

@article{gur:22,
  title = {Learning to introduce referents in narration is resilient to the effects of late sign language exposure},
  author = {Gur, C and S{\"u}mer, Beyza},
  journal = {Sign Language \& Linguistics},
  year = {2022}
}

@article{sumer:22,
  title = {Cross-modal investigation of event component omissions in language development: a comparison of signing and speaking children},
  author = {S{\"u}mer, Beyza and {\"O}zy{\"u}rek, Asl{\i}},
  publisher = {Taylor \& Francis},
  journal = {Language, Cognition and Neuroscience},
  pages = {1--17},
  year = {2022},
  doi = {10.1080/23273798.2022.2042336},
  url = {https://www.tandfonline.com/doi/pdf/10.1080/23273798.2022.2042336?needAccess=true},
  abstract = {Language development research suggests a universal tendency for children to be under- informative in narrating motion events by omitting components such as Path, Manner or Ground. However, this assumption has not been tested for children acquiring sign language. Due to the affordances of the visual-spatial modality of sign languages for iconic expression, signing children might omit event components less frequently than speaking children. Here we analysed motion event descriptions elicited from deaf children (4–10 years) acquiring Turkish Sign Language (TİD) and their Turkish-speaking peers. While children omitted all types of event components more often than adults, signing children and adults encoded more Path and Manner in TİD than their peers in Turkish. These results provide more evidence for a general universal tendency for children to omit event components as well as a modality bias for sign languages to encode both Manner and Path more frequently than spoken languages.}
}

@article{karadoller:22,
  title = {Late sign language exposure does not modulate the relation between spatial language and spatial memory in deaf children and adults},
  author = {Karad{\"o}ller, Dilay Z and S{\"u}mer, Beyza and {\"U}nal, Ercenur and {\"O}zy{\"u}rek, Asl{\i}},
  publisher = {Springer},
  journal = {Memory \& Cognition},
  pages = {1--19},
  year = {2022},
  doi = {10.3758/s13421-022-01281-7},
  url = {https://link.springer.com/content/pdf/10.3758/s13421-022-01281-7.pdf},
  abstract = {Prior work with hearing children acquiring a spoken language as their first language shows that spatial language and cognition are related systems and spatial language use predicts spatial memory. Here, we further investigate the extent of this relationship in signing deaf children and adults and ask if late sign language exposure, as well as the frequency and the type of spatial language use that might be affected by late exposure, modulate subsequent memory for spatial relations. To do so, we compared spatial language and memory of 8-year-old late-signing children (after 2 years of exposure to a sign language at the school for the deaf) and late-signing adults to their native-signing counterparts. We elicited picture descriptions of Left-Right relations in Turkish Sign Language (Türk İşaret Dili) and measured the subsequent recognition memory accuracy of the described pictures. Results showed that late-signing adults and children were similar to their native-signing counterparts in how often they encoded the spatial relation. However, late-signing adults but not children differed from their native-signing counterparts in the type of spatial language they used. However, neither late sign language exposure nor the frequency and type of spatial language use modulated spatial memory accuracy. Therefore, even though late language exposure seems to influence the type of spatial language use, this does not predict subsequent memory for spatial relations. We discuss the implications of these findings based on the theories concerning the correspondence between spatial language and cognition as related or rather independent systems.}
}

@unpublished{esselink:nd,
  author = {Esselink, Lyke and Roelofsen, Floris and Dotla{\v{c}}il, Jakub and Mende-Gillings, Shani and Meulder, Maartje de and Sijm, Nienke and Smeijers, Anika},
  title = {Exploring automatic text-to-sign translation in a healthcare setting},
  year = {N.D.},
  keywords = {manuscript},
  url = {https://www.signlab-amsterdam.nl/publications/Esselink22.pdf},
  abstract = {Communication between healthcare professionals and deaf patients has been particularly challenging during the COVID-19 pandemic. We have explored the possibility to automatically translate phrases that are frequently used in the diagnosis and treatment of hospital patients, in particular phrases related to COVID-19, from Dutch or English to Dutch Sign Language (NGT). The prototype system we developed displays translations either by means of pre-recorded videos featuring a deaf human signer (for a limited number of sentences) or by means of animations featuring a computer-generated signing avatar (for a larger, though still restricted number of sentences). We evaluated the comprehensibility of the signing avatar, as compared to the human signer. We found that, while individual signs are recognized correctly when signed by the avatar almost as frequently as when signed by a human, sentence comprehension rates and clarity scores for the avatar are substantially lower than for the human signer. We identify a number of concrete limitations of the JAsigning avatar engine that underlies our system. Namely, the engine currently does not offer sufficient control over mouth shapes, the relative speed and intensity of signs in a sentence (prosody), and transitions between signs. These limitations need to be overcome in future work for the engine to become usable in practice.},
  note = {Unpublished}
}

@article{motamedi:22,
  title = {From improvisation to learning: how naturalness and systematicity shape language evolution},
  author = {Motamedi, Yasamin and Wolters, Lucie and Naegeli, Danielle and Kirby, Simon and Schouwstra, Marieke},
  publisher = {Elsevier},
  journal = {Cognition},
  volume = {228},
  year = {2022},
  doi = {10.1016/j.cognition.2022.105206},
  url = {https://reader.elsevier.com/reader/sd/pii/S0010027722001949?token=30EF48857FED119FAFE86A8780B2A3F46374F7A756DC93BE40B355F59199CFD7D202EA7569D0ED9CB6DB465E74E8B841&originRegion=eu-west-1&originCreation=20220928152802},
  abstract = {Silent gesture studies, in which hearing participants from different linguistic backgrounds produce gestures to communicate events, have been used to test hypotheses about the cognitive biases that govern cross-linguistic word order preferences. In particular, the differential use of SOV and SVO order to communicate, respectively, extensional events (where the direct object exists independently of the event; e.g., girl throws ball) and intensional events (where the meaning of the direct object is potentially dependent on the verb; e.g., girl thinks of ball), has been suggested to represent a natural preference, demonstrated in improvisation contexts. However, natural languages tend to prefer systematic word orders, where a single order is used regardless of the event being communicated. We present a series of studies that investigate ordering preferences for SOV and SVO orders using an online forced-choice experiment, where English-speaking participants select orders for different events i) in the absence of conventions and ii) after learning event-order mappings in different frequencies in a regularisation experiment. Our results show that natural ordering preferences arise in the absence of conventions, replicating previous findings from production experiments. In addition, we show that participants regularise the input they learn in the manual modality in two ways, such that, while the preference for systematic order patterns increases through learning, it exists in competition with the natural ordering preference, that conditions order on the semantics of the event. Using our experimental data in a computational model of cultural transmission, we show that this pattern is expected to persist over generations, suggesting that we should expect to see evidence of semantically-conditioned word order variability in at least some languages.}
}

@inproceedings{dona:22,
  title = {Modelling the Emergence of Linguistic Conventions for Word Order: The Roles of Semantics, Structural Priming, and Population Structure},
  author = {Dona, Lo{\"\i}s and Schouwstra, Marieke},
  booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume = {44},
  number = {44},
  year = {2022},
  url = {https://escholarship.org/content/qt5dp2600s/qt5dp2600s.pdf?t=reckca&v=lg},
  abstract = {We used agent-based modelling to study the emergence of linguistic conventions for basic word order (the order of subject, object and verb) in different populations. As a starting point, we take word order variation based on semantic properties, as observed in improvised gesture experiments. In our first simulation we explore the relative contributions of two pressures, one for semantically conditioned variation, and the other structural priming (which takes place when two individuals engage in communication), and show that a relatively increasing influence of structural priming best explains an increase in word order regularity. Next we implement a larger simulation, investigating how properties of the population affect regularization of word order. Our models compare population sizes with different population densities, and show that the speed of regularization in languages is heavily influenced by population density, and population size has little effect.}
}

@inproceedings{naegeli:22,
  title = {Cross-cultural differences in the emergence of referential strategies in artificial sign languages},
  author = {Naegeli, Danielle and Peeters, David and Krahmer, Emiel and Schouwstra, Marieke and Motamedi, Yasamin and De Vos, Connie},
  booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume = {44},
  number = {44},
  year = {2022},
  url = {https://escholarship.org/content/qt7861289g/qt7861289g.pdf?t=recks3&v=lg},
  abstract = {While the grammatical use of space for referential strategies is attested across many sign languages of Western Europe, Kata Kolok, a rural sign language used in Northern Bali, has not developed anaphoric pointing in space nor agreement verbs (Engberg-Pedersen, 1993; Liddell, 2003; de Vos, 2012). To find out whether such typological differences can be explained by differences in the respective co-speech gesture systems, this preregistered study is collecting data for a cross-cultural comparison. Building on Motamedi et al. (2021), we are conducting studies in Bali and the Netherlands using an iterated learning silent gesture paradigm in which hearing people communicate transitive events using only gestures. Preliminary data indeed suggest that our Balinese participants do not employ space the same way our Dutch participants do. We will present comparative analyses and evaluate the role of co-speech gesture systems in sign language emergence in the lab or when evolving from spontaneous interaction.}
}

@article{schouwstra:22,
  title = {Investigating Word Order Emergence: Constraints From Cognition and Communication},
  author = {Schouwstra, Marieke and Naegeli, Danielle and Kirby, Simon},
  publisher = {Frontiers},
  journal = {Frontiers in Psychology},
  pages = {1855},
  year = {2022},
  doi = {10.3389/fpsyg.2022.805144},
  url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2022.805144/full},
  abstract = {How do cognitive biases and mechanisms from learning and use interact when a system of language conventions emerges? We investigate this question by focusing on how transitive events are conveyed in silent gesture production and interaction. Silent gesture experiments (in which participants improvise to use gesture but no speech) have been used to investigate cognitive biases that shape utterances produced in the absence of a conventional language system. In this mode of communication, participants do not follow the dominant order of their native language (e.g., Subject-Verb-Object), and instead condition the structure on the semantic properties of the events they are conveying. An important source of variability in structure in silent gesture is the property of reversibility. Reversible events typically have two animate participants whose roles can be reversed (girl kicks boy). Without a syntactic/conventional means of conveying who does what to whom, there is inherent unclarity about the agent and patient roles in the event (by contrast, this is less pressing for non-reversible events like girl kicks ball). In experiment 1 we test a novel, fine-grained analysis of reversibility. Presenting a silent gesture production experiment, we show that the variability in word order depends on two factors (properties of the verb and properties of the direct object) that together determine how reversible an event is. We relate our experimental results to principles from information theory, showing that our data support the “noisy channel” account of constituent order. In experiment 2, we focus on the influence of interaction on word order variability for reversible and non-reversible events. We show that when participants use silent gesture for communicative interaction, they become more consistent in their usage of word order over time, however, this pattern less pronounced for events that are classified as strongly non-reversible. We conclude that full consistency in word order is theoretically a good strategy, but word order use in practice is a more complex phenomenon.}
}

@misc{motamedi:21a,
	title = {The effects of iconicity and conventionalisation on word order preferences},
	author = {Motamedi, Yasamin and Wolters, Lucie and Schouwstra, Marieke and Kirby, Simon},
  publisher = {PsyArXiv},
  year = {2021},
  doi = {10.31234/osf.io/u5amg},
	url = {https://doi.org/10.31234/osf.io/u5amg},
  abstract = {Of the 6 possible orderings of the 3 main constituents of language (subject, verb and object), two —- SOV and SVO —- are predominant cross-linguistically. Previous research using the silent gesture paradigm in which hearing participants produce or respond to gestures without speech, has shown that different factors such as reversibility, salience and animacy can affect the preferences for different orders. Here, we test whether participants’ preferences for orders that are conditioned on the semantics of the event change depending on i) the iconicity of individual gestural elements and ii) the prior knowledge of a conventional lexicon. Our findings demonstrate the same preference for semantically-conditioned word order found in previous studies, specifically that SOV and SVO are preferred differentially for different types of events. We do not find that iconicity of individual gestures affects participants’ ordering preferences, however we do find that learning a lexicon leads to a stronger preference for SVO-like orders overall. Finally, we compare our findings from English speakers, using an SVO-dominant language, with data from speakers of an SOV-dominant language, Turkish. We find that, while learning a lexicon leads to an increase in SVO preference for both sets of participants, this effect is mediated by language background and event type, suggesting that an interplay of factors together determine preferences for different ordering patterns. Taken together, our results support a view of word order as a gradient phenomenon responding to multiple biases.}
}

@misc{royka:21,
  title = {I Know You Know I’m Signaling: Novel gestures are designed to guide observers’ inferences about communicative goals},
  author = {Royka, Amanda and Schouwstra, Marieke and Kirby, Simon and Jara-Ettinger, Julian},
  publisher = {PsyArXiv},
  year = {2021},
  doi = {10.31234/osf.io/2h5vu},
  url = {psyarxiv.com/2h5vu},
  abstract = {For a gesture to be successful, observers must recognize its communicative purpose. Are communicators sensitive to this problem and do they try to ease their observer’s inferential burden? We propose that people shape their gestures to help observers easily infer that their movements are meant to communicate. Using computational models of recursive goal inference, we show that this hypothesis predicts that gestures ought to reveal that the movement is inconsistent with the space of non-communicative goals in the environment. In two gesture-design experiments, we find that people spontaneously shape communicative movements in response to the distribution of potential instrumental goals, ensuring that the movement can be easily differentiated from instrumental action. Our results show that people are sensitive to the inferential demands that observers face. As a result, people actively work to help ensure that the goal of their communicative movement is understood.}
}

@article{motamedi:21b,
  title = {The emergence of systematic argument distinctions in artificial sign languages},
  author = {Motamedi, Yasamin and Smith, Kenny and Schouwstra, Marieke and Culbertson, Jennifer and Kirby, Simon},
  publisher = {Oxford University Press},
  journal = {Journal of Language Evolution},
  volume = {6},
  number = {2},
  pages = {77--98},
  year = {2021},
  doi = {10.1093/jole/lzab002},
  url = {https://academic.oup.com/jole/article/6/2/77/6303767},
  abstract = {Word order is a key property by which languages indicate the relationship between a predicate and its arguments. However, sign languages use a number of other modality-specific tools in addition to word order such as spatial agreement, which has been likened to verbal agreement in spoken languages, and role shift, where the signer takes on characteristics of propositional agents. In particular, data from emerging sign languages suggest that, though some use of a conventional word order can appear within a few generations, systematic spatial modulation as a grammatical feature takes time to develop. We experimentally examine the emergence of systematic argument marking beyond word order, investigating how artificial gestural systems evolve over generations of participants in the lab. We find that participants converge on different strategies to disambiguate clause arguments, which become more consistent through the use and transmission of gestures; in some cases, this leads to conventionalized iconic spatial contrasts, comparable to those found in natural sign languages. We discuss how our results connect with theoretical issues surrounding the analysis of spatial agreement and role shift in established and newly emerging sign languages, and the possible mechanisms behind its evolution.}
}

@inproceedings{motamedi:21c,
  title = {Regularisation, systematicity and naturalness in a silent gesture learning task},
  author = {Motamedi, Yasamin and Wolters, Lucie and Naegeli, Danielle and Schouwstra, Marieke and Kirby, Simon},
  booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume = {43},
  number = {43},
  year = {2021},
  url = {https://escholarship.org/content/qt8xf3216h/qt8xf3216h.pdf?t=qwi3pz&v=lg},
  abstract = {Typological analysis of the world’s language shows that, of the 6 possible basic word orders, SOV and SVO orders are predominant, a preference supported by experimental studies in which participants improvise gestures to describe events. Silent gesture studies have also provided evidence for natural ordering patterns, where SOV and SVO orders are used selectively depending on the semantics of the event, a finding recently supported by data from natural sign languages. We present an artificial language learning task using gesture to ask to what extent preferences for natural ordering patterns, in addition to biases for regular languages, are at play during learning in the manual modality.}
}

@article{kirton:21,
  title = {Constituent order in silent gesture reflects the perspective of the producer},
  author = {Kirton, Fiona and Kirby, Simon and Smith, Kenny and Culbertson, Jennifer and Schouwstra, Marieke},
  publisher = {Oxford University Press},
  journal = {Journal of Language Evolution},
  volume = {6},
  number = {1},
  pages = {54--76},
  year = {2021},
  doi = {10.1093/jole/lzaa010},
  url = {https://academic.oup.com/jole/article/6/1/54/6179035},
  abstract = {Understanding the relationship between human cognition and linguistic structure is a central theme in language evolution research. Numerous studies have investigated this question using the silent gesture paradigm in which participants describe events using only gesture and no speech. Research using this paradigm has found that Agent–Patient–Action (APV) is the most commonly produced gesture order, regardless of the producer’s native language. However, studies have uncovered a range of factors that influence ordering preferences. One such factor is salience, which has been suggested as a key determiner of word order. Specifically, humans, who are typically agents, are more salient than inanimate objects, so tend to be mentioned first. In this study, we investigated the role of salience in more detail and asked whether manipulating the salience of a human agent would modulate the tendency to express humans before objects. We found, first, that APV was less common than expected based on previous literature. Secondly, salience influenced the relative ordering of the patient and action, but not the agent and patient. For events involving a non-salient agent, participants typically expressed the patient before the action and vice versa for salient agents. Thirdly, participants typically omitted non-salient agents from their descriptions. We present details of a novel computational solution that infers the orders participants would have produced had they expressed all three constituents on every trial. Our analysis showed that events involving salient agents tended to elicit AVP; those involving a non-salient agent were typically described with APV, modulated by a strong tendency to omit the agent. We argue that these findings provide evidence that the effect of salience is realized through its effect on the perspective from which a producer frames an event.}
}

@misc{schouwstra:20,
 title = {The emergence of word order conventions: improvisation, interaction and transmission},
 author = {Schouwstra, Marieke and Smith, Kenny and Kirby, Simon},
 publisher = {PsyArXiv},
 year = {2020},
 doi = {10.31234/osf.io/wdfu2},
 url = {psyarxiv.com/wdfu2},
 abstract = {When people improvise to convey information by using only gesture and no speech (‘silent gesture’), they show language-independent word order preferences: SOV for extensional events (e.g., boy-ball-throw), but SVO for intensional events (e.g., boy-search-ball). Real languages tend not to condition word order on this kind of semantic distinction but instead use the same order irrespective of event type. Word order therefore exemplifies a contrast between naturalness in improvisation and conventionalised regularity in linguistic systems. We present an experimental paradigm in which initially-improvised silent gesture is both used for communication and culturally transmitted through artificial generations of lab participants. In experiments 1 and 2 we investigate the respective contributions of communicative interaction and cultural transmission on natural word order behaviour. We show that both interaction and iterated learning lead to a simplification of the word order regime, and the way in which this unfolds over time is surprisingly similar under the two mechanisms. The resulting dominant word order is mostly SVO, the order of the native language of our participants. In experiment 3, we manipulate the frequency of different semantic event types, and show that this can allow SOV order, rather than SVO order, to conventionalise. Taken together, our experiments demonstrate that where pressures for naturalness and regularity are in conflict, naturalness will give way to regularity as word order becomes conventionalised through repeated usage.}
}

@article{sato:20,
  title = {Do all aspects of learning benefit from iconicity? Evidence from motion capture},
  author = {Sato, Asha and Schouwstra, Marieke and Flaherty, Molly and Kirby, Simon},
  publisher = {Cambridge University Press},
  journal = {Language and Cognition},
  volume = {12},
  number = {1},
  pages = {36--55},
  year = {2020},
  doi = {10.1017/langcog.2019.37},
  url = {https://www.cambridge.org/core/services/aop-cambridge-core/content/view/55EDF990ED0E81A85100F8F01988B7C2/S1866980819000371a.pdf/do-all-aspects-of-learning-benefit-from-iconicity-evidence-from-motion-capture.pdf},
  abstract = {Recent work suggests that not all aspects of learning benefit from an iconicity advantage (Ortega, 2017). We present the results of an artificial sign language learning experiment testing the hypothesis that iconicity may help learners to learn mappings between forms and meanings, whilst having a negative impact on learning specific features of the form. We used a 3D camera (Microsoft Kinect) to capture participants’ gestures and quantify the accuracy with which they reproduce the target gestures in two conditions. In the iconic condition, participants were shown an artificial sign language consisting of congruent gesture–meaning pairs. In the arbitrary condition, the language consisted of non-congruent gesture–meaning pairs. We quantified the accuracy of participants’ gestures using dynamic time warping (Celebi et. al., 2013). Our results show that participants in the iconic condition learn mappings more successfully than participants in the arbitrary condition, but there is no difference in the accuracy with which participants reproduce the forms. While our work confirms that iconicity helps to establish form–meaning mappings, our study did not give conclusive evidence about the effect of iconicity on production; we suggest that iconicity may only have an impact on learning forms when these are complex.}
}

@article{culbertson:20,
  title = {From the world to word order: deriving biases in noun phrase order from statistical properties of the world},
  author = {Culbertson, Jennifer and Schouwstra, Marieke and Kirby, Simon},
  publisher = {Linguistic Society of America},
  journal = {Language},
  volume = {96},
  number = {3},
  pages = {696--717},
  year = {2020},
  doi = {10.1353/lan.2020.0045},
  url = {https://www.linguisticsociety.org/sites/default/files/08_96.3Culbertson.pdf},
  abstract = {The world’s languages exhibit striking diversity. At the same time, recurring linguistic patterns suggest the possibility that this diversity is shaped by features of human cognition. One well-studied example is word order in complex noun phrases (like these two red vases). While many orders of these elements are possible, a subset appear to be preferred. It has been argued that this ordering reflects a single underlying representation of noun phrase structure, from which preferred orders are straightforwardly derived (e.g. Cinque 2005). Building on previous experimental evidence using artificial language learning (Culbertson & Adger 2014), we show that these preferred orders arise not only in existing languages, but also in improvised sequences of gestures produced by English speakers. We then use corpus data from a wide range of languages to argue that the hypothesized underlying structure of the noun phrase might be learnable from statistical features relating objects and their properties conceptually. Using an information-theoretic measure of strength of association, we find that adjectival properties (e.g. red) are on average more closely related to the objects they modify (e.g. wine) than numerosities are (e.g. two), which are in turn more closely related to the objects they modify than demonstratives are (e.g. this). It is exactly those orders which transparently reflect this—by placing adjectives closest to the noun, and demonstratives farthest away—that are more common across languages and preferred in our silent gesture experiments. These results suggest that our experience with objects in the world, combined with a preference for transparent mappings from conceptual structure to linear order, can explain constraints on noun phrase order.}
}
