@inproceedings{ranum2024the,
title={The {NGT}200 Dataset - Geometric Multi-View Isolated Sign Recognition},
author={Oline Ranum and David Wessels and Gom{\`e}r Otterspeer and Erik J Bekkers and Floris Roelofsen and Jari I. Andersen},
booktitle={ICML 2024 Workshop on Geometry-grounded Representation Learning and Generative Modeling},
year={2024},
url={https://openreview.net/forum?id=idkNzTC67X},
abstract={Sign Language Processing (SLP) provides the foundation for a more inclusive future in language technology; however, the field must first overcome significant challenges. This work addresses multi-view isolated sign recognition (MV-ISR), emphasizing the critical importance of 3D awareness for real-world SLP applications. We introduce a new benchmark for MV-ISR, the NGT200 dataset, and define MV-ISR as a distinct task from single-view ISR. We showcase the benefits of including synthetic data, and propose to condition sign representations on the spatial symmetries inherent to the visual modality of sign language. We enhance MV-ISR performance by 8%-22% using a geometrically grounded model compared to the SL-GCN baseline.}
}

@InProceedings{ranum-EtAl:2024:signlang,
  author    = {Ranum, Oline  and  Otterspeer, Gom{\`e}r  and  Andersen, Jari  and  Belleman, Robert  and  Roelofsen, Floris},
  title     = {3D-LEX v1.0 - 3D Lexicons for American Sign Language and Sign Language of the Netherlands},
  booktitle      = {Proceedings of the {LREC-COLING} 2024 11th Workshop on the Representation and Processing of Sign Languages: Evaluation of Sign Language Resources},
  month          = {May},
  year           = {2024},
  address        = {Torino, Italy},
  publisher      = {ELRA and ICCL},
  pages     = {290--301},
  abstract  = {In this work, we present an efficient approach for capturing sign language in 3D, introduce the 3D-LEX v1.0 dataset, and detail a method for semi-automatic annotation of phonetic properties. Our procedure integrates three motion capture techniques encompassing high-resolution 3D poses, 3D handshapes, and depth-aware facial features, to attain an average sampling rate of one sign every 10 seconds. This includes the time for presenting a sign example, performing and recording the sign, and archiving the capture. The 3D-LEX dataset includes 1,000 signs from American Sign Language and an additional 1,000 signs from the Sign Language of the Netherlands. We showcase the dataset utility by presenting a simple method for generating handshape annotations directly from 3D-LEX. We produce handshape labels for 1,000 signs from American Sign Language and evaluate the labels in a sign recognition task. The labels enhance gloss recognition accuracy by 5\% over using no handshape annotations, and by 1\% over expert annotations. Our motion capture data supports in-depth analysis of sign features and facilitates the generation of 2D projections from any viewpoint. The 3D-LEX collection has been aligned with existing sign language benchmarks and linguistic resources, to support studies in 3D-aware sign language processing.},
  url       = {https://aclanthology.org/2024.signlang-1.33}
}


@article{Esselink2024:automatic,
	abstract = {Communication between healthcare professionals and deaf patients has been particularly challenging during the COVID-19 pandemic. We have explored the possibility to automatically translate phrases that are frequently used in the diagnosis and treatment of hospital patients, in particular phrases related to COVID-19, from Dutch or English to Dutch Sign Language (NGT). The prototype system we developed displays translations either by means of pre-recorded videos featuring a deaf human signer (for a limited number of sentences) or by means of animations featuring a computer-generated signing avatar (for a larger, though still restricted number of sentences). We evaluated the comprehensibility of the signing avatar, as compared to the human signer. We found that, while individual signs are recognized correctly when signed by the avatar almost as frequently as when signed by a human, sentence comprehension rates and clarity scores for the avatar are substantially lower than for the human signer. We identify a number of concrete limitations of the JASigning avatar engine that underlies our system. Namely, the engine currently does not offer sufficient control over mouth shapes, the relative speed and intensity of signs in a sentence (prosody), and transitions between signs. These limitations need to be overcome in future work for the engine to become usable in practice.},
	author = {Esselink, Lyke and Roelofsen, Floris and Dotla{\v c}il, Jakub and Mende-Gillings, Shani and de Meulder, Maartje and Sijm, Nienke and Smeijers, Anika},
	date = {2024/03/01},
	date-added = {2024-12-24 16:00:53 +0100},
	date-modified = {2024-12-24 16:00:53 +0100},
	doi = {10.1007/s10209-023-01042-6},
	id = {Esselink2024},
	isbn = {1615-5297},
	journal = {Universal Access in the Information Society},
	number = {1},
	pages = {35--57},
	title = {Exploring automatic text-to-sign translation in a healthcare setting},
	url = {https://doi.org/10.1007/s10209-023-01042-6},
	volume = {23},
	year = {2024},
	bdsk-url-1 = {https://doi.org/10.1007/s10209-023-01042-6}}



@InProceedings{esselink-oomen-roelofsen:2024:signlang,
  author    = {Esselink, Lyke D.  and  Oomen, Marloes  and  Roelofsen, Floris},
  title     = {Evaluating Inter-Annotator Agreement for Non-Manual Markers in Sign Languages},
  booktitle      = {Proceedings of the {LREC-COLING} 2024 11th Workshop on the Representation and Processing of Sign Languages: Evaluation of Sign Language Resources},
  year           = {2024},
  address        = {Torino, Italy},
  publisher      = {ELRA and ICCL},
  pages     = {66--76},
  abstract  = {This paper is part of a larger project that aims to create a standardized procedure for annotating non-manual markers (NMMs) in sign language data. The paper describes two approaches to evaluating inter-annotator agreement, the event-based approach and the frame-based approach, and uses a combination of these two approaches to evaluate the annotation guidelines introduced in Oomen et al. (2023). The evaluation reveals that for several labels in the annotation scheme inter-annotator agreement is rather low. This indicates that the annotations guidelines need to be further improved. We present concrete recommendations for how this may be achieved, and intend to implement these recommendations in future work. All data and analysis scripts are available.},
  url       = {https://aclanthology.org/2024.signlang-1.7}
}


@inproceedings{Notarte:forthcoming,
    author =    {Notarte Balanquit, Liberty},
    year =      {Forthc.},
    title =     {Probabilities of Lexicalization: phonological change in Filipino Sign Language cardinal numerals},
    booktitle = {(2 ed.) Penn Working Papers in Linguistics},
    publisher = {Graduate Linguistics Society (GradLingS)}
}

@inproceedings{Notarte:23,
  author = {Notarte Balanquit, Liberty and Dagani, Carolyn B. and Martinez, Liza L.},
  title = {{Matapos ang Apat na Dekada: Muling pagsipat sa panganganib ng Wikang Senyas ng Pilipino [After four decades: a review of the status of FSL endangerment].}},
  year = {2023},
  url = {https://www.researchgate.net/publication/384729744_Matapos_ang_Apat_na_Dekada_Muling_pagsipat_sa_panganganib_ng_Wikang_Senyas_ng_Pilipino},
  booktitle = {Pambansang Kongreso sa Nanganganib na Wika 2022 [National Congress on Endangered Languages 2022]},
  numpages = {13},
  location = {Manila, Philippines}
}

@inproceedings{ritmeester:24,
  author = {Ritmeester, Jos and S\"{u}mer, Beyza and Boonstra, Marije and de Meulder, Maartje and van der Aa, Belinda and Roelofsen, Floris},
  title = {{ZINinNGT: A Mobile Tool to Aid Hearing Parents Learning Dutch Sign Language}},
  year = {2024},
  isbn = {9798400706776},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3663548.3688529},
  doi = {10.1145/3663548.3688529},
  booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
  articleno = {82},
  numpages = {5},
  location = {St. John's, NL, Canada},
  series = {ASSETS '24},
  abstract = {This study examines the potential of the ZINinNGT app, a mobile learning application designed to support hearing parents of deaf and hard-of-hearing (DHH) children in learning Dutch Sign Language. We conducted interviews with ten parents to investigate their current sign language learning experiences and to gather feedback on the ZINinNGT prototype. While results indicated that an app cannot overcome many of the challenges parents face, parents still expressed a very positive attitude towards using a sign language learning app. Feedback on the ZINinNGT prototype identified the need for enhanced usability and a desire to include quizzes and information on the handshapes of signs. Overall, feedback was very positive, indicating that a mobile app has the potential to support hearing parents by providing relevant content going beyond vocabulary level.}
}


@phdthesis{boers:21,
  title = {Learning to use space: A study into the SL2 acquisition process of adult learners of Sign Language of the Netherlands},
  author = {Boers-Visker, Eveline},
  publisher = {Netherlands Graduate School of Linguistics {(LOT)}},
  year = {2020},
  url = {https://www.lotpublications.nl/Documents/569_fulltext.pdf},
  abstract = {This dissertation addresses the acquisition of Sign Language of the Netherlands (Nederlandse Gebarentaal, NGT) in adult learners with a spoken language background. These learners acquire a new language in a new modality, the visual-spatial modality, which differs from the oral-auditory modality of their native language, Dutch. One of the modality-specific linguistic features attested in signed languages, but not in spoken languages, is the use of space to express grammatical and topographical relations. Our knowledge of the acquisition of linguistic devices related to the use of space (e.g., pointing signs, agreement verbs, classifier predicates and signs marked for location), and of appropriate pedagogical practices to teach these structures, is very limited. This thesis contributes to filling this gap by improving our understanding of processes underlying the acquisition of these devices in L2-learners of NGT, and by investigating whether certain pedagogical practices, which have been shown to be effective for L2-learners of a spoken language, would facilitate the acquisition of these devices. Four studies were carried out. The first three studies, in which we analyze (semi-)natural and elicited production data of novel NGT learners who were followed longitudinally, serve as basis for the fourth study, in which we investigate whether learners benefit from pedagogical interventions aimed at focusing their attention on the form-meaning mappings of one of the devices under investigation, agreement verb forms. This dissertation provides valuable information for practitioners in the field, and adds to our understanding of the intersecting fields of sign language linguistics, second language acquisition and pedagogy, as well as gesture studies.}
}

@article{boers:20,
  title = {Space oddities: The acquisition of agreement verbs by L2 learners of Sign Language of the Netherlands},
  author = {Boers-visker, Eveline and Pfau, Roland},
  publisher = {Wiley Online Library},
  journal = {The Modern Language Journal},
  volume = {104},
  number = {4},
  pages = {757--780},
  year = {2020},
  doi = {10.1111/modl.12676},
  url = {https://onlinelibrary.wiley.com/doi/full/10.1111/modl.12676},
  abstract = {This article reports the results of the first longitudinal study that systematically investigates the acquisition of verb agreement by hearing learners of a sign language. During a 2-year period, 14 novel learners of Sign Language of the Netherlands (NGT) with a spoken language background performed an elicitation task 15 times. Seven deaf native signers and NGT teachers performed the same task to serve as a benchmark group. The results obtained show that for some learners, the verb agreement system of NGT was difficult to master, despite numerous examples in the input. As compared to the benchmark group, learners tended to omit agreement markers on verbs that could be modified, did not always correctly use established locations associated with discourse referents, and made characteristic errors with respect to properties that are important in the expression of agreement (movement and orientation). The outcomes of the study are of value to practitioners in the field, as they are informative with regard to the nature of the learning process during the first stages of learning a sign language.}
}

@incollection{Kimmelman:24,
  title = {{Headshakes in NGT: Relation between phonetic properties & linguistic function}},
  author = {Kimmelman, Vadim and Oomen, Marloes and Pfau, Roland},
  publisher={ELRA Language Resources Association},
  editor    = {Efthimiou, Eleni and Fotinea, Stavroula-Evita and Hanke, Thomas and Hochgesang, Julie A. and Mesch, Johanna and Schulder, Marc},
  booktitle = {Proceedings of the {LREC-COLING} 2024 11th Workshop on the Representation and Processing of Sign Languages: Evaluation of Sign Language Resources},
  maintitle = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation ({LREC-COLING} 2024)},
  pages = {62--70},
  address   = {Torino, Italy},
  year = {2024},
  url = {https://www.sign-lang.uni-hamburg.de/lrec/pub/24008.pdf},
  abstract = {Non-manual markers (such as facial expressions and head movements) have been shown to fulfil a wide range of grammatical functions across sign languages. One nonmanual marker that is very wide-spread is headshake used to express negation. While negation and headshake have been studied for a variety of sign languages, phonetic/kinematic research on headshake has been mostly absent. In this paper, we conduct a phonetic analysis of headshake in Sign Language of the Netherlands using a Computer Vision solution, namely OpenFace. We specifically analyze whether linguistic properties of headshake (e.g. spreading and the type of signs co-occurring with the headshake) influence its phonetic form.}
}

@article{pfau:24a,
  title = {When shifts root: Some observations regarding nouns and noun phrases in spontaneous speech errors},
  author = {Pfau, Roland},
  journal = {Linguistics in Amsterdam},
  volume = {15},
  number = {2},
  pages = {135--142},
  year = {2024},
  url = {https://www.signlab-amsterdam.nl/publications/Pfau_2024_LiA.pdf},
  abstract = {Deciding on a topic for my contribution to this festschrift did not come easy. The obvious choice would have been a topic related to sign language structure – and indeed, I reviewed a couple of ideas. However, given that this volume celebrates Kees Hengeveld’s academic achievements – and, on a more personal note, the wonderful and supportive colleague he has been for almost a quarter of a century – I finally decided to contribute a squib on the manipulation of nouns in spontaneous speech errors, as this topic has three straightforward links to studies that Kees has conducted over the years. First, I am focusing on a specific word class (and the nature of word classes more generally), and ever since his PhD thesis, Kees has had a keen interest in parts-of-speech (Hengeveld 1992; also see, e.g., Hengeveld 2013). Second, I discuss production data, and the Functional Discourse Grammar (FDG) model is characterized by a rigorous top- down architecture (Hengeveld & Mackenzie 2015), which aligns in important ways with that of serial models of language production (e.g., Levelt 1989). Third, on my only foray into the realm of (pre-FDG) Functional Grammar – a joint project with Dik Bakker – we actually addressed gender mismatches in spontaneous speech errors (Bakker & Pfau 2008). In this squib, I will analyze selected German speech errors by applying theoretical assumptions from Distributed Morphology (DM; Halle & Marantz 1993; Siddiqi 2010). In a nutshell, DM assumes that the computational system manipulates nothing but abstract roots and morphosyntactic features, while phonologically specified Vocabulary items (VIs) are inserted into terminal nodes only after syntax (“late insertion”). In Section 2, I will focus on roots and show how DM-mechanisms ensure their correct spell-out in a specific context. In Sections 3 and 4, I then turn to proposals regarding the internal structure of determiner phrases (DPs) and consider in how far the speech error data provide evidence regarding such proposals. I address certain predictions concerning the processing of the number feature (Section 3) and further functional structure that may impact the choice of derivational morphemes (Section 4).}
}

@article{pfau:24b,
  title = {Suprasegmentals in negation: A cross-modal perspective},
  author = {Pfau, Roland},
  journal = {To the left, to the right, and much in between: A Festschrift for Katharina Hartmann},
  publisher = {Goethe University Frankfurt},
  editor = {Himmelreich, A. and Hole, D. and Mursell, J.},
  pages = {127--138},
  year = {2024},
  url = {https://www.signlab-amsterdam.nl/publications/Pfau_KH.pdf},
  doi = {10.17605/OSF.IO/3FX4M},
  abstract = {Katharina Hartmann, whose academic achievements are celebrated with this volume, and I have a 30-year-long history of non-linguistic and linguistic interaction. We shared an apartment in Frankfurt for five years in the 1990s while we were both affiliated with the University of Frankfurt (she as PhD, then post-doc, and I as PhD). In retrospect, it seems to me that our conversations at home only rarely revolved around linguistic matters – except for the occasional gossip, of course. Yet, there has been a noteworthy, and coincidental, overlap in research focus in the late 1990s, and it is this incident that served as inspiration for my contribution to the volume. In that period, Katharina and I had both decided to extend the scope of our linguistic interests by learning an “exotic” language: she chose Hausa, while I took advantage of the fact that German Sign Language (Deutsche Gebärden-sprache, DGS) was offered for the first time at our university. Once we had acquired basic skills, it just so happened that both of us – independently of each other – selected the realization of negation in the respective language as topic of investigation. We noticed certain similarities between the two languages, which, in an odd sense of circularity, made her reference unpublished work of mine in a talk (Hartmann 1999), while I referred to that very talk in the published version of the chapter she had drawn information from (Pfau 2001).
  In the present chapter, I zoom in on a characteristic that the two (and many other) languages share, but which has not been discussed in much detail in the aforementioned works: the role of suprasegmentals in the expression of negation. In Section 2, I start by sketching selected properties and functions of suprasegmentals in the two modalities.2 Section 3 addresses negative particles that are specified for suprasegmental features, while Section 4 looks at verbs and how they may be suprasegmentally modified in negative contexts. The possibility of spreading of suprasegmental features is discussed in Section 5. Section 6 concludes.}
}

@incollection{pfau:23,
  title = {Morphology in sign languages: Theoretical issues and typological contrasts.},
  author = {Pfau, Roland and Steinbach, Markus},
  publisher={Oxford: Wiley Blackwell},
  booktitle = {The Wiley Blackwell companion to morphology},
  editor = {Ackema, Peter and Bendjaballah, Sabrina and Bonet, Eulàlia and Fábregas, Antonio},
  pages = {1--37},
  year = {2023},
  url = {https://www.signlab-amsterdam.nl/publications/Pfau_Steinbach_2023_Wiley.pdf},
  doi = {10.1002/9781119693604.morphcom048},
  keywords = {Morphology}
}

@article{boven:21a,
  title = {Phonological restrictions on nominal pluralization in Sign Language of the Netherlands: evidence from corpus and elicited data},
  author = {Boven, Cindy van},
  publisher = {De Gruyter Mouton},
  journal = {Folia Linguistica},
  year = {2021},
  doi = {10.1515/flin-2021-2039},
  url = {https://www.degruyter.com/document/doi/10.1515/flin-2021-2039/html},
  abstract = {This study focuses on nominal pluralization in Sign Language of the Netherlands (NGT). The aim is to offer a comprehensive description of nominal pluralization processes in the language, based on both corpus data and elicited data, taking into account potential phonological restrictions. The results reveal that NGT nouns can undergo several pluralization processes, the main ones being simple reduplication (i.e., repeating the noun sign at one location) and sideward reduplication (i.e., repeating the noun sign while moving the hand sideward). The choice of pluralization process depends on phonological properties of the base noun: (i) nouns that are body-anchored or involve a complex movement undergo simple reduplication; (ii) nouns articulated at the lateral side of the signing space undergo sideward reduplication; (iii) nouns articulated on the midsagittal plane can undergo both simple and sideward reduplication. Strikingly, the data show considerable variation, and all types of nouns can be zero-marked, that is, plural marking on the noun is not obligatory. The results further suggest that all nouns can undergo at least one type of reduplication. Thus, while phonological properties of the base noun influence the type of reduplication, they do not block reduplication altogether. Plural reduplication in NGT is therefore less constrained than has been reported for other sign languages, where certain noun types cannot undergo reduplication. This shows that reduplication – despite being iconically motivated – is subject to language-specific grammatical constraints.}
}

@inproceedings{boven:21b,
  title = {Fill the gap: A novel test to elicit nominal plurals in Sign Language of the Netherlands},
  author = {Boven, Cindy van},
  publisher = {FEAST. Formal and Experimental Advances in Sign Language Theory},
  volume = {3},
  pages = {56--67},
  year = {2020},
  doi = {10.31009/FEAST.i3.05},
  url = {https://www.signlab-amsterdam.nl/publications/boven21b.pdf},
  abstract = {The present study introduces a novel gap-filling test to elicit plural nouns in Sign Language of the Netherlands (NGT). As of yet, nominal plurals in NGT have not been described in detail, as eliciting plural nouns is not without challenges. In previous research on NGT (Zwitserlood and Nijhof 1999), native signers were asked to describe pictures of plural objects. However, when describing pictures, the signers automatically also expressed the spatial distribution of the objects depicted on the stimulus picture, using localization. As a consequence, it remains unclear what ‘pure’ plurals – without localization – look like. The goal of our gap-filling task is to disentangle pluralization from localization: participants are asked to insert plural nouns in signed sentence contexts where the spatial distribution of the referents is irrelevant. After piloting the task, five deaf native signers participated. The task succeeded in eliciting pure plural forms that were not spatially distributed, and the results show that NGT optionally employs reduplication to mark the pure plural of nouns. We conclude that our gap-filling task successfully controls for localization, targeting the desired structure without using written language. In future studies, the gap-filling task can be applied to other sign languages, targeting also other construction types.}
}

@article{boven:21c,
  title = {Habituals in Sign Language of the Netherlands: A corpus-based study},
  author = {Boven, Cindy van and Oomen, Marloes},
  journal = {Linguistics in Amsterdam},
  volume = {14},
  number = {1},
  pages = {160--184},
  year = {2021},
  url = {https://www.researchgate.net/profile/Marloes-Oomen/publication/349685298_Habituals_in_Sign_Language_of_the_Netherlands_A_corpus-based_study/links/603cad7d4585158939d99668/Habituals-in-Sign-Language-of-the-Netherlands-A-corpus-based-study.pdf},
  abstract = {In this corpus-based study on habituals in Sign Language of the Netherlands (NGT), we investigate the manual and non-manual marking of habituality in naturalistic data. We show that both reduplication of the predicate and adverbials with a habitual flavor are used in habitual contexts, but both of these manual markers appear to be optional. As for non-manual markers, even more variation is attested; left-to-right head and body movements and narrowed eyes are the most frequently occurring non-manuals in habitual contexts but are by no means obligatory. The findings contrast with the results reported in two previous studies on habituals in NGT (Hoiting & Slobin 2001; Oomen 2016), which can be partially explained by the fact that these studies used elicitation methods. As such, the present study underscores the importance of using a combination of different methods in investigating linguistic phenomena.}
}

@incollection{boven:23a,
  title = {Negative Concord in Sign Language of the Netherlands: a journey through a corpus},
  author = {Boven, Cindy van and Oomen, Marloes and Pfau, Roland and Rusch, Lotte},
  publisher={John Benjamins Publishing Company},
  booktitle = {Advances in sign language corpus linguistics},
  pages = {30--65},
  year = {2023},
  url = {https://doi.org/10.1075/scl.108.02van},
  doi = {10.1075/scl.108.02van},
  keywords = {Corpus NGT, Cross-modal typology, Doubling, Negation, Negative Concord, Variation},
  abstract = {In a Negative Concord (NC) configuration, two negative elements co-occur in a clause but the polarity of that clause still remains negative. NC involving two manual negators has been observed in various sign languages, but relevant examples are usually presented in the context of broader investigations on negation in a particular sign language. Also, examples are not usually drawn from natural discourse. In this chapter, we offer the first comprehensive study on NC in a single sign language, namely, the Sign Language of the Netherlands (NGT), based entirely on corpus data. We find that NC is attested in NGT, but that it is optional and rather infrequent. First, our contribution is of a typological nature, as we distinguish different types of NC and compare our corpus-based results with those reported for other signed and spoken languages. Second, we describe in detail our “journey”, that is, our search procedure and inclusion criteria, thereby offering methodological guidelines for future endeavors.}
}

@article{boven:23b,
  title = {Nominal plurals in Sign Language of the Netherlands: Accounting for allomorphy and variation},
  author = {Boven, Cindy van and Hamann, Silke and Pfau, Roland},
  journal = {Glossa: a journal of general linguistics},
  volume = {8},
  number = {1},
  pages = {1--47},
  year = {2023},
  url = {https://www.glossa-journal.org/article/id/9686/},
  doi = {https://doi.org/10.16995/glossa.9686},
  keywords = {Allomorphy, Corpus, Plural reduplication, Sign Language of the Netherlands, Stochastic OT, Variation},
  abstract = {In both signed and spoken languages, reduplication is a common process in the formation of morphologically complex structures, expressing, e.g., plurality and certain aspectual meanings. A framework in which spoken language reduplication has been formalized frequently is Optimality Theory (OT). While an important attribute of OT-constraints is their universality, to date, the question to what extent such constraints are modality-independent, and thus work for sign language reduplication as well, remains largely unanswered. In the present study, we offer the first OT-formalization of plural reduplication in Sign Language of the Netherlands (NGT). The NGT-data reveal that this language features different plural allomorphs, the choice of which depends on phonological properties of the base noun. However, we also identify variation, e.g., all noun types allow for zero marking.

  In our formalization, we aim to introduce constraints that are maximally modality-independent, using constraint types that have previously been proposed for spoken language reduplication. Our formalization is the first to take into account base-reduplicant faithfulness for a sign language, and also the first to account for variation in sign language data by employing stochastic OT, whereby some noise is added to the ranking value of each constraint at evaluation time. Evaluating the modality-(in)dependence of our proposed account suggests that the types of constraints we employ as well as the evaluation in the spirit of stochastic OT are not specific to a modality, while the featural implementation is inevitably modality-dependent.}
}

@article{boven:24a,
url = {https://www.signlab-amsterdam.nl/publications/vanboven24.pdf},
title = {Aspectual reduplication in Sign Language of the Netherlands: reconsidering phonological constraints and aspectual distinctions},
author = {Boven, Cindy van},
journal = {Linguistics},
doi = {doi:10.1515/ling-2022-0076},
year = {2024},
abstract = {This study investigates the use of predicate reduplication to express aspectual meaning in Sign Language of the Netherlands (NGT). The study focuses on three aspect types that have been found to be encoded by reduplication across sign languages – habitual, continuative, and iterative – and addresses potential phonological restrictions. }
}

@phdthesis{boven:24b,
  title = {Morphological reduplication in Sign Language of the Netherlands: A typological and theoretical perspective},
  author = {Boven, Cindy van},
  year = {2024},
  publisher = {Netherlands Graduate School of Linguistics {(LOT)}},
  abstract = {The topic of this dissertation is morphological reduplication in Sign Language of the Netherlands (Nederlandse Gebarentaal, NGT). Under reduplication, (part
of) a word or sign is repeated, in order to yield a systematic change in meaning. The present study focuses on three of its functions: nominal pluralization, aspect
marking, and reciprocal marking. Analysis of naturalistic corpus data is combined with data elicitation. Beyond offering a description of NGT reduplication, this book presents a
typological perspective on the phenomenon. The dissertation also presents a theoretical perspective by offering a
formalization of the results in stochastic Optimality Theory (OT).},
  url = {https://dare.uva.nl/search?identifier=0f34e615-6f5e-4146-96d5-b323fa5bfc1b}
}

@inproceedings{khristoforova:21,
  title = {Question-answer pairs in Russian Sign Language: a corpus study},
  author = {Khristoforova, Evgeniia and Kimmelman, Vadim},
  publisher = {FEAST. Formal and Experimental Advances in Sign language Theory},
  volume = {4},
  pages = {101--112},
  issn = {2565-1781},
  year = {2021},
  doi = {10.31009/FEAST.i4.08},
  url = {https://www.signlab-amsterdam.nl/publications/khristoforova21.pdf},
  abstract = {We describe basic morphosyntactic and semantic properties of question-answer pairs(QAPs) collected from the online corpus of Russian Sign Language (RSL). We identified two classes of QAPs: classical and discourse QAPs, which are different in the semantic relation between the question and answer parts. We discovered that non-manual marking and word order in both types of QAPs are different from other constructions involving wh-signs, namely regular questions and free relative clauses. Guided by the similarity between non-manual marking of QAPs and role shift marking, we hypothesize on a possible grammaticalization process connecting the two constructions}
}

@article{Khristoforova:23a,
   author = {Khristoforova, Evgeniia},
   title = {Subject agreement in control and modal constructions in Russian Sign Language: Implications for the hierarchy of person features},
   journal= {Sign Language \& Linguistics},
   year = {2023},
   volume = {26},
   number = {1},
   pages = {64-116},
   doi = {https://doi.org/10.1075/sll.21005.khr},
   url = {https://www.jbe-platform.com/content/journals/10.1075/sll.21005.khr},
   publisher = {John Benjamins},
   issn = {1387-9316},
   type = {Journal Article},
   keywords = {Sign language, Person feature, Finiteness, Control clause, Complement clause, Russian Sign Language, Verbal agreement},
   abstract = {The present research combines three fields of inquiry in sign language linguistics: verbal agreement, person features, and syntactic complexity. These topics have previously been addressed in isolation, but little is known about their interaction. This study attempts to fill this gap by investigating subject agreement in complement clauses in Russian Sign Language. By means of corpus investigation and grammaticality judgments, I found that subject agreement in clausal complements of the control predicates <span class="jp-small">try, love, want, begin</span>, and modal <span class="jp-small">can</span> may be deficient – in particular, it can be reduced to the forms identical to first-person marking even in the case of a third-person subject controller. Deficient subject agreement in complement clauses is thus reminiscent of non-finite verbal forms in spoken languages. I further argue that the choice of first-person forms in deficient agreement reveals a default status of first person in sign languages, which is consistent with proposals regarding the modality-specific properties of first-person reference in these languages.},
  }

@incollection{Khristoforova:23b,
    author =    {Khristoforova, Evgeniia},
    year =      {2023},
    title =     {The Implicational Complementation Hierarchy and size restructuring in the Sign Language of the Netherlands},
    booktitle = {Proceedings of the Fifty-Third Annual Meeting of the North East Linguistic Society},
    editor =    {Suet-Ying Lam and Satoru Ozaki},
    url = {https://www.signlab-amsterdam.nl/publications/Khristoforova_NELS53_2023.pdf},
    volume = {2},
    pages = {119}
}

@article{Khristoforova:23c,
    title={Indexicals under role shift in Sign Language of the Netherlands},
    volume={5},
    url={https://raco.cat/index.php/FEAST/article/view/422436},
    DOI={10.31009/FEAST.i5.06},
    journal={FEAST. Formal and Experimental Advances in Sign language Theory},
    author={Khristoforova, Evgeniia and David, Blunier},
    year={2023},
    pages={63-75}
}

@article{kimmelman:20,
  title = {Argument structure of classifier predicates in Russian Sign Language},
  author = {Kimmelman, Vadim and Pfau, Roland and Aboh, Enoch O},
  publisher = {Springer},
  journal = {Natural Language \& Linguistic Theory},
  volume = {38},
  number = {2},
  pages = {539--579},
  year = {2020},
  doi = {10.1007/s11049-019-09448-9},
  url = {https://link.springer.com/content/pdf/10.1007/s11049-019-09448-9.pdf},
  abstract = {We analyze classifier predicates in Russian Sign Language (RSL) using a combination of naturalistic corpus and elicited data in order to determine their argument structure, and to test the generalization, based on research on other sign languages, that there is a clear relation between argument structure and classifier type (Benedicto and Brentari 2004). We propose that whole-entity classifier predicates are intransitive unaccusative, and that body-part classifier predicates are optionally transitive. Contrary to previous research on other sign languages, we argue that handling classifier predicates in RSL describe complex events with two subevents: one of handling, and one of movement, which are not necessarily causally connected. We further suggest that the ‘moving legs’ classifier predicate in RSL also describes a complex event consisting of two subevents. To account for these facts, we develop a formal analysis of classifier predicates in RSL. Specifically, we argue that whole-entity and body-part classifier handshapes are agreement markers, while handling classifier handshapes as well as the ‘moving legs’ classifier handshape represent an argument in combination with a verbal root. This casts doubt on the observation made in the literature that classifiers straightforwardly determine the argument structure of classifier predicates, since different classifiers in RSL represent different grammatical phenomena. In addition, we show that event structures associated with some classifier predicates are more complex than those associated with monoclausal structures in spoken languages.}
}

@incollection{kimmelman:21,
  title = {Information structure: Theoretical perspectives},
  author = {Kimmelman, Vadim and Pfau, Roland},
  publisher = {Routledge},
  booktitle = {The Routledge Handbook of Theoretical and Experimental Sign Language Research},
  pages = {591--613},
  year = {2021},
  url = {http://vadimkimmelman.com/papers/Kimmelman%20Pfau%202021%20IS.pdf},
  abstract = {This chapter discusses the terminology commonly used in the information structure literature: in particular, topic, focus, contrast, and emphasis. An important component of our discussion is the impact of the visual-gestural modality on the syntactic and prosodic encoding of information structure. Kimmelman argued that in RSL and NGT, doubling is also used for information structure-related functions, but proposed that the functions of doubling are better described as foregrounding. Information structure is a field of linguistics covered in numerous books and articles. Information structure in sign languages has also been investigated almost from the first days of sign linguistics; however, as is often the case, most of the available studies focus on a very small number of sign languages, and among these, American Sign Language is the one most prominently represented. The chapter aims to theoretical research, It discusses the few available experimental or psycholinguistic studies on information structure in sign languages.}
}

@incollection{Burkova:23,
  title = {Syntactic functions of nonmanuals in Russian Sign Language},
  author = {Burkova, Svetlana and Khristoforova, Evgeniia and Kimmelman, Vadim},
  publisher={John Benjamins Publishing Company},
  booktitle = {Advances in sign language corpus linguistics},
  pages = {90--122},
  year = {2023},
  url = {https://doi.org/10.1075/scl.108.04bur},
  doi = {10.1075/scl.108.04bur},
  keywords = {Russian Sign Language, Nonmanuals, Questions, Topics, Conditionals, Concessives},
  abstract = {This chapter presents the Russian Sign Language (RSL) Corpus and demonstrates its capabilities as a research tool by summarizing three corpus-based studies primarily focused on syntactic functions of nonmanual markers. The first study considers question marking in regular wh-questions and in question-answer pairs. It shows that the two constructions have very different nonmanual markers. The second study analyzes marking of topics in RSL, and shows that nonmanual markers of topics are typologically common, but are infrequent in naturalistic corpus data. The third study investigates conditional and concessive constructions in RSL. It demonstrates that these constructions make extensive and frequent use of nonmanual markers, but that no single marker is specialized for the function of expressing conditional or concessive meaning. Instead, complex combinations of multiple markers are employed in these constructions. All three studies also contribute to sign language typology by providing novel descriptions of syntactic and discourse phenomena in RSL.}
}

@article{Khristoforova:20,
  title = {Syntax of relativization in Russian Sign Language: Basic features},
  author = {Khristoforova, Evgeniia and Kimmelman, Vadim},
  journal={Voprosy Jazykoznanija},
  volume={6},
  pages = {48--65},
  year = {2020},
  url = {https://doi.org/10.31857/0373-658X.2020.6.48-65},
  doi = {10.31857/0373-658X.2020.6.48-65},
  keywords = {Relative constructions, Russian Sign Language, sign languages},
  abstract = {This paper provides a first syntactic description of relativization in Russian Sign Language (RSL). We collected production data from nine signers performing a picture-based task. The signers produced 88 instances of relative constructions with the head noun being the subject or direct object in the main clause and in the relative clause. We found that RSL has head-external (postnominal) relative clauses, head-internal relative clauses, and double-headed relative clauses. Relative clauses might also be extra-posed to the sentence-final position or fronted. The main clause may be doubled, so that a part of it is repeated after the relative clause. Relative clauses might contain optional relative elements WHICH and INDEX, in clause-initial or clause-final position, or in both positions, and the two elements can co-occur. Finally, we found that relative clauses are nearly always prosodically separate from the main clause. The most frequent non-manual markers in relative construction are eye blinks; in addition, head leans and turns, eyebrow raise, and squints are sometimes used. However, no marker is specialized for marking the relative clause itself: they either are simply markers of boundaries of prosodic units (eye blinks), or they have some other functions (which we cannot fully identify yet). We conclude that RSL generally fits patterns found in other spoken and signed languages. However, we also observe specific differences, especially in the domain of non-manual marking.}
}

@phdthesis{klomp:21,
  title = {A descriptive grammar of Sign Language of the Netherlands},
  author = {Klomp, Ulrika},
  year = {2021},
  publisher = {Netherlands Graduate School of Linguistics {(LOT)}},
  abstract = {Sign Language of the Netherlands (Nederlandse Gebarentaal, NGT) is a minority language in the Netherlands, but has only recently gained legal recognition of this status. It is estimated that 60,000 people in the Netherlands sign NGT, of whom 10,000 are early onset deaf signers. This book is the first comprehensive descriptive grammar of NGT. It offers a detailed description of its phonology, morphology, and selected aspects of its syntax. Whenever possible, the linguistic phenomena are illustrated by naturalistic corpus data. The grammatical description is complemented by a brief overview of the socio-historical background of NGT and of the Dutch sign language community. The European SIGN-HUB project, of which this dissertation is a result, hosts a platform where a digital version of this grammar can be found, along with video fragments providing illustrations of many of the linguistic characteristics addressed in the book: www.sign-hub.eu/grammar. This resource may be used for cross-linguistic research, for the development of NGT acquisition materials, and as a reference work.},
  url = {https://www.researchgate.net/profile/Ulrika-Klomp-2/publication/351188644_A_descriptive_grammar_of_Sign_Language_of_the_Netherlands/links/60bdca06458515218f9a1558/A-descriptive-grammar-of-Sign-Language-of-the-Netherlands.pdf}
}


@article{Klomp:23,
  title = {Review of ‘The Handbook of Language Assessment Across Modalities. Eds. T. Haug, W. Mann and U. Knoch (2022)’},
  author = {Klomp, Ulrika},
  year = {2023},
  journal={Applied Linguistics amad064},
  url = {https://www.signlab-amsterdam.nl/publications/klomp23-review.pdf}
}

@article{Klompetal:23,
  title = {Totstandkoming van de Nederlandse functionele definitie van doofblindheid},
  author = {Bak, Michelle and Klomp, Ulrika and Heppe, Eline},
  year = {2023},
  journal={Van Horen Zeggen},
  url = {https://vhz-online.nl/totstandkoming-van-de-nederlandse-functionele-definitie-van-doofblindheid},
  abstract = {Het klinkt vanzelfsprekend: kan je slecht horen? Dan ben je doof of slechthorend. Kan je slecht zien? Dan heb je een visuele beperking. Kan je slecht horen én slecht zien? Dan heb je een beperking in horen én zien, ook wel doofblindheid (a) genoemd. Maar in dit geval is 1 + 1 niet gelijk aan 2; een beperking in horen én zien is méér dan de optelsom van deze verschillende beperkingen. Het is een unieke beperking en verdient een definitie die rekening houdt met de wisselwerking van de individuele beperkingen en die kijkt naar de invloed hiervan op het dagelijks functioneren. Het doel van het Deelkrachtproject Functionele Definitie Doofblindheid is het opstellen van een Nederlandse functionele definitie die gebruikt wordt om de doelgroep te definiëren en om te hanteren in de toeleiding naar doofblind-specifieke zorg.}
}

@inproceedings{klompetal:24,
    author = {Klomp, Ulrika and Gierman, Lisa and Manders, Pieter and Nauta, Ellen and Otterspeer, Gomer and Pelupessy, Ray and Stern, Galya and Venter, Dalene and Wubbolts, Casper and Oomen, Marloes and Roelofsen, Floris},
    year = {2024},
    title = {An extension of the NGT dataset in Global Signbank},
    pages = {178--183},
    editor = {E. Efthimiou and S-E. Fotinea  and T. Hanke and J.A. Hochgesang and J. Mesch  and M.  Schulder},
    booktitle = {Proceedings of the LREC2024 11th Workshop on the representation and processing of sign languages: Evaluation of sign language resources},
    publisher = {European Language Resources Association.},
    location = {Turin},
    url = {https://www.signlab-amsterdam.nl/publications/klomp_et_al_lrec24.pdf},
    abstract = {To support language documentation, linguistic research, and acquisition of Sign Language of the Netherlands (NGT), we are expanding the NGT dataset in the lexical database Global Signbank. Our most prioritized goal is to
add ca. 11,000 glosses (entries). We further aim at adding ca. 3,000 example sentences and to provide linguistic information with as many glosses as possible. As for linguistic information, Signbank allows for extensive
phonological descriptions of signs, and the addition of multiple senses per sign, which we would like to connect to synsets in the Multilingual Sign Language Wordnet. Additionally, we are recording extra video data: we make
multiple videos of the same sign, taken from different angles, and videos with non-manual expressions. Furthermore, we are collecting motion capture data, for improved (automatic) sign language recognition and production in the future. In this paper, we describe how we proceed, the decisions that have been made so far, and
future uses of the dataset.}
}

@incollection{Klompetal:forthcoming,
  title = {Negation in Sign Language of the Netherlands},
  author = {Klomp, Ulrika and Oomen, Marloes and Pfau, Roland},
  booktitle = {Negation in the languages of the world},
  publisher = {Language Science Press},
  year = {Forthc.},
  location = {Berlin},
  editor = {L. Veselinova and M. Miestamo},
  url = {https://www.signlab-amsterdam.nl/publications/Klomp-Oomen-Pfau-accepted-manuscript-Negation-in-NGT.pdf},
  abstract = {This chapter addresses negation in Sign Language of the Netherlands, a language in the visual-spatial modality. Throughout this chapter, we will address several aspects of negation that are modality-independent, such as the occurrence of negative particles, but also pay attention to structures that are particular for sign languages, such as the simultaneous use of grammatical non-manual markers. In the
introduction, we provide some information on Sign Language of the Netherlands (NGT) in general, and we briefly go into our methodology. Then we continue to describe properties of negation in NGT step by step, based on previous research, but also by providing new data on phenomena that have, until now, not received much attention within the field of sign language linguistics, such as negative transport.}
}

@article{lint:20,
  title = {From meaning to form and back in American Sign Language verbal classifier morphemes},
  author = {Lint, Vanja de},
  publisher = {Edinburgh University Press},
  journal = {Word Structure},
  volume = {13},
  number = {1},
  pages = {69--101},
  year = {2020},
  doi = {10.3366/word.2020.0160},
  url = {https://www.euppublishing.com/doi/10.3366/word.2020.0160},
  abstract = {In a seminal paper, Benedicto & Brentari (2004) present a theoretical proposal in which they analyze American Sign Language (ASL) classifier morphemes as instantiations of functional heads F1 and F2 that determine the external or internal position of the argument that lands in their specifier through a structural agreement relation. It has served as a ground for several follow-up studies investigating argument structure in sign language classifier constructions. However, their proposal requires both theoretical amendment and empirical corroboration. In this paper, I critically assess the proposal by Benedicto & Brentari (2004) and provide empirical support for a modified version.}
}

@article{oomen:20a,
  title = {Spatial verbs are demonstration verbs},
  author = {Oomen, Marloes},
  journal = {Revista Lingu{\'\i}stica},
  volume = {16},
  number = {3},
  pages = {227--249},
  year = {2020},
  doi = {10.31513/linguistica.2020.v16n3a36966},
  url = {https://www.researchgate.net/profile/Marloes-Oomen/publication/349591032_Spatial_verbs_are_demonstration_verbs/links/60379931299bf1cc26edcac2/Spatial-verbs-are-demonstration-verbs.pdf},
  abstract = {The literature has been divided over the question of whether spatial verbs should be subsumed into a single verb class with agreement verbs. The main point of contention has been that, even if the nature of the elements that these verb types agree with differs, the morphosyntactic mechanism, i.e. a path movement, appears to be the same. Contributing to this debate, this corpus-based study scrutinizes the morphosyntactic properties of a set of spatial verbs in German Sign Language (DGS). It is shown that spatial verbs display striking variability in where they begin and end their movement in space. They may align with locations or person loci, but often they simply mark arbitrary locations, which may convey meaningful yet less specific information about the (direction of) movement of a referent relative to the signer. Furthermore, null subjects are found to occur remarkably often in constructions with spatial verbs, despite the absence of systematic subject marking on the verb itself. These results stand in contrast with those reported for regular agreement verbs in DGS (OOMEN, 2020), and thus provide support for a distinction between the two types. It is proposed that spatial verbs in DGS involve a demonstration component (cf. DAVIDSON, 2015) which ensures the recoverability of referents involved in the event denoted by the verb, thus loosening the restrictions on both agreement marking and subject drop that apply to regular agreement verbs. As such, spatial verbs are argued to be somewhere in between conventionalized lexical verbs and classifier predicates.}
}

@phdthesis{oomen:20b,
  title = {Iconicity as a mediator between verb semantics and morphosyntactic structure: a corpus-based study on verbs in German Sign Language},
  author = {Oomen, Marloes},
  publisher = {Netherlands Graduate School of Linguistics {(LOT)}},
  volume = {24},
  number = {1},
  pages = {132--141},
  year = {2021},
  abstract = {In many sign languages around the world, some verbs can express grammatical agreement with not just one but two arguments, while other verbs do not express agreement at all. Moreover, and rather curiously, there is a remarkable degree of semantic overlap across sign languages between verbs that possess agreement properties. It has been suggested that iconicity has some part to play in this: in sign languages, there is the potential for aspects of verb meaning to be iconically represented in a verb’s form. In this dissertation, I investigate how semantics and morphosyntactic structure interact in constructions containing verbs with varying agreement properties in German Sign Language (DGS), using naturalistic dialogues between signers from the DGS Corpus as the primary data source. I show that certain semantic properties – also known to govern transitivity marking in spoken languages – are predictive of verb type in DGS, where indeed systematic iconic mappings play a mediating role. The results enable the formulation of cross-linguistic predictions about the interplay between verb semantics and verb type in sign languages. A subsequent analysis of a range of morphosyntactic properties of different verb types leads up to the conclusion that even ‘plain’ verbs, in fact, grammatically agree with their arguments. This in turn motivates a unified syntactic analysis in terms of agreement of constructions with verbs that do and do not overtly express it, thus presenting a novel solution to the typological puzzle that supposedly only verbs of a (partially) semantically definable subset agree in DGS and other sign languages.},
  url = {https://www.researchgate.net/profile/Marloes-Oomen/publication/341178832_Iconicity_as_a_mediator_between_verb_semantics_and_morphosyntactic_structure_A_corpus-based_study_on_verbs_in_German_Sign_Language/links/5eb26e6f92851cbf7fa9492f/Iconicity-as-a-mediator-between-verb-semantics-and-morphosyntactic-structure-A-corpus-based-study-on-verbs-in-German-Sign-Language.pdf}
}

@book{oomen:21,
  title = {Iconicity and Verb Agreement: A Corpus-Based Syntactic Analysis of German Sign Language},
  author = {Oomen, Marloes},
  publisher = {De Gruyter Mouton},
  volume = {15},
  year = {2021},
  url = {https://books.google.nl/books?hl=en&lr=&id=hw5QEAAAQBAJ&oi=fnd&pg=PP13&ots=HiMEkpbZjP&sig=K47YaIrlIk4oedkZASJt1gFNNcM&redir_esc=y#v=onepage&q&f=false},
  keywords = {textbook}
}

@inproceedings{otterspeeretal:24,
    author = {Otterspeer, Gomer and Klomp, Ulrika and Roelofsen, Floris},
    year = {2024},
    title = {SignCollect: A 'touchless' pipeline for constructing large-scale sign language repositories.},
    pages = {269--275},
    editor = {E. Efthimiou and S-E. Fotinea  and T. Hanke and J.A. Hochgesang and J. Mesch  and M.  Schulder},
    booktitle = {Proceedings of the LREC2024 11th Workshop on the representation and processing of sign languages: Evaluation of sign language resources},
    publisher = {European Language Resources Association.},
    location = {Turin},
    url = {https://www.signlab-amsterdam.nl/publications/otterspeeretal_lrec24.pdf},
    abstract = {The projectteam of the Signbank project at the University of Amsterdam intends to substantially extend the NGT lexicon in Global Signbank within a limited timespan. To make this possible, the signCollect platform was developed
to automate a major part of the workflow. The signCollect system includes a ‘touchless’ interface which enables a signer to control the system through simple gestures (recognized using computer vision) to (i) prompt the display
of the next lexical entry, (ii) start a new recording, and (iii) approve/disapprove a recording. This capability allows a signer to record between 60 to 120 signs per hour, without the need for any assisting staff to be present. The
approved recordings immediately become visible in the signCollect database, so that other members of the team can add metadata. With feedback from workshop participants we intend to further optimize the signCollect platform and
make it available as an open-source tool for all sign language research teams.}
}

@book{pfau:21a,
  title = {Our Lives--Our Stories: Life Experiences of Elderly Deaf People},
  author = {Pfau, Roland and G{\"o}ksel, Asli and Hosemann, Jana},
  volume = {14},
  year = {2021},
  keywords = {textbook},
  publisher = {De Gruyter Mouton},
  abstract = {Sign languages are non-written languages. Given that the use of digital media and video recordings in documenting sign languages started only some 30 years ago, the life stories of Deaf elderly signers born in the 1930s-1940s have – except for a few scattered fragments in film – not been documented and are therefore under serious threat of being lost. The chapters compiled in this volume document important aspects of past and present experiences of elderly Deaf signers across Europe, as well as in Israel and the United States. Issues addressed include (i) historical events and how they were experienced by Deaf people, (ii) issues of identity and independence, (iii) aspects of language change, (iv) experiences of suppression and discrimination. The stories shared by elderly signers reveal intriguing, yet hidden, aspects of Deaf life. On the negative side, these include experiences of the Deaf in Nazi Germany and occupied countries and harsh practices in educational settings, to name a few. On the positive side, there are stories of resilience and vivid memories of school years and social and professional life. In this way, the volume contributes in a significant way to the preservation of the cultural and linguistic heritage of Deaf communities and sheds light on lesser known aspects against an otherwise familiar background.},
  doi = {10.1515/9783110701906},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110701906/html}
}

@incollection{pfau:21b,
  title = {Much more than a treasure: the life stories of elderly Deaf people},
  author = {Pfau, Roland and G{\"o}ksel, Asl{\i} and Hosemann, Jana},
  booktitle = {Our Lives--Our Stories: Life Experiences of Elderly Deaf People},
  publisher = {De Gruyter Mouton},
  volume = {14},
  pages = {1--15},
  year = {2021},
  doi = {10.1515/9783110701906-001},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110701906-001/html}
}

@incollection{pfau:21c,
  title = {Pink sign: Identity challenges, choices, and changes among elderly Deaf homosexuals in the Netherlands},
  author = {Pfau, Roland and Kampen, Annemieke van and Harterink, Menno},
  booktitle = {Our Lives--Our Stories: Life Experiences of Elderly Deaf People},
  publisher = {De Gruyter Mouton},
  volume = {14},
  pages = {129--167},
  year = {2021},
  doi = {10.1515/9783110701906-001},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110701906-006/html}
}

@incollection{pfau:21d,
  title = {Number in Sign Languages},
  author = {Pfau, Roland and Steinbach, Markus},
  booktitle = {The Oxford Handbook of Grammatical Number},
  pages = {644--660},
  year = {2021},
  doi = {10.1093/oxfordhb/9780198795858.013.31},
  url = {https://watermark.silverchair.com/303222023.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAsQwggLABgkqhkiG9w0BBwagggKxMIICrQIBADCCAqYGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMAM4265XWzaPig-A1AgEQgIICd4bTyMHkxH5x94H-3xgHeMC-KCtNdBW0tnBEJ16xiMm57KFcg7pgUnG8rqAhJYSBE3rX0vGkrTnDxt-lMawtzO5h7h-rx2lOIDnKzuByTbc4Tn9fi0TvuGjSqWqbFF7Tv8eU-2UmFcTbU28iHrp64ZGBpMY-8rxAdBW1K-sadkMVh0tzKgrfx76KZaAG2W_EnBX1xfdIW9hMaRrTeJ64rFAaKifrL8FrQ7hkyibqqEwaIMAsNkOE6nxzCRW8uZ8iSdKJMwAdIF5UYt9yvbjmavELriA2fzxYthELFPCfkH6L8wT10B0_DgKVwURP_SzyXrnSwKuIQspmpi9rxtIAPrPPvtULyka9B4mJN3_5bUmWCmHBIzg6dQMjoo9VnbE3LK3scgAr1QsUaZJZOcVMBJWbU9C70m60rItcNpvSBTYurjRjorX6cL9LIlXaTYHKauEyfRibi-5Mrxjya1uVY4j-oruZWuqQdXbtYl2ZiorXaUsHQFbYvuk2LLdlfjgRgpzkwdU-WEjY825ZZJzGjAnrSTovMk62RRKqzpHbzax3okEvARsZvc4u4i5CJOuCmR1UxtPtwwIVC2ruaiakCmpCh2BLx-VbOTmlqHoVLk6cn7-Uq_1T7N3fAKfDyvmH3FSmPl8trwFUSuAM2EHykj93r-Vgc4Fre7WWBFgX7uXv2GTnzHWzXPAUeCoqiqJyivNnkqwXSRkB9mMc2D7TR-76btmjAjnyMMLQ7sN0VuC0TdKPobDMd5gG3FYxZOlIWrTQ5orMacdav7NJNb_zLIhJMDiCtSQiyNIu-EXGCpQ8EFYAZsouLrwWE-QUkCFznZIc9L5Xtr0}
}

@article{pfau:22,
  title = {Negation and Negative Concord in Georgian Sign Language},
  author = {Pfau, Roland and Makharoblidze, Tamar and Zeijlstra, Hedde},
  journal = {Frontiers in Psychology},
  volume = {13},
  number = {734845},
  year = {2022},
  publisher = {Frontiers Media SA},
  doi = {10.3389/fpsyg.2022.734845},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9333067/},
  abstract = {Negation is a topic that has received considerable attention ever since the early days of sign language linguistics; also, it is one of the grammatical domains that has given the impetus for sign language typology. In this paper, we offer a typological and theoretical contribution to the study of sign language negation. As for the typological side, we add Georgian Sign Language (GESL) to the pool of languages investigated. Our description reveals that GESL displays a number of typologically unusual features: a considerable number of negative particles, including emphatic, prohibitive, and tense-specific particles; specialized negative modals; and a wide range of possibilities for Negative Concord (NC) involving two manual negative signs, including a unique tense-specific instance of NC. Most of the patterns we report -- available negative particles, their clausal position, and NC possibilities -- are clearly different from those attested in spoken Georgian. As for the theoretical contribution, we investigate how the highly complex GESL negation system compares to existing taxonomies of NC and Double Negation systems, and we conclude that GESL aligns with certain languages that have been classified as atypical NC languages.},
  note = {Special issue "Sign language research sixty years later: current and future perspectives".}
}

@article{hartmann:21,
  title = {Asymmetry and contrast: Coordination in Sign Language of the Netherlands},
  author = {Hartmann, Katharina and Pfau, Roland and Legeland, Iris},
  journal = {Glossa: a journal of general linguistics},
  volume = {6},
  number = {1},
  year = {2021},
  pages = {1--33},
  doi = {10.16995/glossa.5872},
  url = {https://www.glossa-journal.org/article/id/5872/},
  abstract = {This paper investigates coordination in Sign Language of the Netherlands (NGT). We offer an account for a typologically unusual coordination pattern found in this language. We show that the conjuncts of a coordinated structure in NGT may violate a constraint governing coordinated structures in spoken languages, which we refer to as the ‘Parallel Structure Constraint’. The violation consists in asymmetric fronting in the second conjunct of a coordinated structure. We argue that a violation of the Parallel Structure Constraint is acceptable in NGT in order to express a contrast across the conjuncts. Hence asymmetric reordering in the second conjunct is a strategy that allows signers to obtain the desired strength of marking when in situ marking is insufficient.},
  publisher={Open Library of Humanities}
}

@article{lutzenberger:22,
  title = {Emergence or Grammaticalization? The Case of Negation in Kata Kolok},
  author = {Lutzenberger, Hannah and Pfau, Roland and Vos, Connie de},
  journal = {Languages},
  volume = {7},
  number = {1},
  pages = {23},
  year = {2022},
  publisher = {MDPI},
  doi = {10.3390/languages7010023},
  url = {https://www.mdpi.com/2226-471X/7/1/23/htm},
  abstract = {Typological comparisons have revealed that signers can use manual elements and/or a non-manual marker to express standard negation, but little is known about how such systematic marking emerges from its gestural counterparts as a new sign language arises. We analyzed 1.73 h of spontaneous language data, featuring six deaf native signers from generations III-V of the sign language isolate Kata Kolok (Bali). These data show that Kata Kolok cannot be classified as a manual dominant or non-manual dominant sign language since both the manual negative sign and a side-to-side headshake are used extensively. Moreover, the intergenerational comparisons indicate a considerable increase in the use of headshake spreading for generation V which is unlikely to have resulted from contact with Indonesian Sign Language varieties. We also attest a specialized negative existential marker, namely, tongue protrusion, which does not appear in co-speech gesture in the surrounding community. We conclude that Kata Kolok is uniquely placed in the typological landscape of sign language negation, and that grammaticalization theory is essential to a deeper understanding of the emergence of grammatical structure from gesture.}
}

@book{quer:21,
  title = {The Routledge Handbook of Theoretical and Experimental Sign Language Research},
  author = {Quer, Josep and Pfau, Roland and Herrmann, Annika},
  publisher = {Routledge},
  year = {2021},
  doi = {10.4324/9781315754499},
  url = {https://www.taylorfrancis.com/books/edit/10.4324/9781315754499/routledge-handbook-theoretical-experimental-sign-language-research-josep-quer-roland-pfau-annika-herrmann},
  keywords = {textbook},
  abstract = {The Routledge Handbook of Theoretical and Experimental Sign Language Research bridges the divide between theoretical and experimental approaches to provide an up-to-date survey of key topics in sign language research. With 29 chapters written by leading and emerging scholars from around the world, this Handbook covers the following key areas: On the theoretical side, all crucial aspects of sign language grammar studied within formal frameworks such as Generative Grammar;　　 On the experimental side, theoretical accounts are supplemented by experimental evidence gained in psycho- and neurolinguistic studies;　 On the descriptive side, the main phenomena addressed in the reviewed scholarship are summarized in a way that is accessible to readers without previous knowledge of sign languages. Each chapter features an introduction, an overview of existing research, and a critical assessment of hypotheses and findings. The Routledge Handbook of Theoretical and Experimental Sign Language Research is key reading for all advanced students and researchers working at the intersection of sign language research, linguistics, psycholinguistics, and neurolinguistics.}
}

@inproceedings{wang:22,
  title = {Active Learning for Multilingual Fingerspelling Corpora},
  author = {Wang, Shuai and Nalisnick, Eric},
  booktitle = {Adaptive Experimental Design and Active Learning in the Real World},
  year = {2022},
  url = {https://www.signlab-amsterdam.nl/publications/Active_Learning_for_Multilingual_Fingerspelling_Corpora.pdf},
  abstract = {We apply active learning to help with data scarcity problems in sign languages. In particular, we perform a novel analysis of the effect of pre-training. Since many sign languages are linguistic descendants of French sign language, they share hand configurations, which pre-training can hopefully exploit. We test this hypothesis on American, Chinese, German, and Irish fingerspelling corpora. We do observe a benefit from pre-training, but this may be due to visual rather than linguistic similarities.}
}

@inproceedings{Roelofsen:21a,
  title = {Online evaluation of text-to-sign translation by deaf end users: Some methodological recommendations},
	author = {Roelofsen, Floris and Esselink, Lyke and Mende-Gillings, Shani and Meulder, Maartje de and Sijm, Nienke and Smeijers, Anika},
	booktitle = {Proceedings of the First International Workshop on Automatic Translation for Sign and Spoken Languages (AT4SSL)},
  publisher = {Association for Machine Translation in the Americas},
  pages = {82--87},
  year = {2021},
  address = {Virtual},
	url = {https://aclanthology.org/2021.mtsummit-at4ssl.9/},
  abstract = {{We present a number of methodological recommendations concerning the online evaluation of avatars for text-to-sign translation, focusing on the structure, format and length of the questionnaire, as well as methods for eliciting and faithfully transcribing responses.}}
}

@inproceedings{Roelofsen:21b,
  title = {Sign language translation in a healthcare setting},
  author = {Roelofsen, Floris and Esselink, Lyke and Mende-Gillings, Shani and Smeijers, Anika},
	booktitle = {Proceedings of the Translation and Interpreting Technology Online Conference (TRITON)},
  publisher = {INCOMA Ltd.},
	pages = {110-124},
	year = {2021},
  address = {Virtual},
  url = {https://aclanthology.org/2021.triton-1.13.pdf},
  abstract = {{Communication between healthcare professionals and deaf patients is challenging, and the current COVID-19 pandemic makes this issue even more acute. Sign language interpreters can often not enter hospitals and face masks make lipreading impossible. To address this urgent problem, we developed a system which allows healthcare professionals to translate sentences that are frequently used in the diagnosis and treatment of COVID-19 into Sign Language of the Netherlands (NGT). Translations are displayed by means of videos and avatar animations. The architecture of the system is such that it could be extended to other applications and other sign languages in a relatively straightforward way.}}
}

@inproceedings{Gemert:22,
  title = {First Steps Towards a Signing Avatar for Railway Travel Announcements in the {Netherlands}},
  author = {Gemert, Britt van and Cokart, Richard and Esselink, Lyke and Meulder, Maartje de and Sijm, Nienke and Roelofsen, Floris},
  booktitle = {Proceedings of the 7th International Workshop on Sign Language Translation and Avatar Technology (SLTAT): The Junction of the Visual and the Textual: Challenges and Perspectives},
  publisher = {European Language Resources Association},
  pages = {109--116},
  year = {2022},
  address = {Marseille, France},
  url = {https://aclanthology.org/2022.sltat-1.17.pdf},
  abstract = {This paper presents first steps towards a sign language avatar for communicating railway travel announcements in Dutch Sign Language. Taking an interdisciplinary approach, it demonstrates effective ways to employ co-design and focus group methods in the context of developing sign language technology, and presents several concrete findings and results obtained through co-design and focus group sessions which have not only led to improvements of our own prototype but may also inform the development of signing avatars for other languages and in other application domains.}
}

@unpublished{Corsel:20,
  title = {{Multidimensionality in Sign Language Synthesis: Translation of Dutch into Sign Language of the Netherlands}},
  author = {Corsel, Adriana},
  year = {2020},
  url = {https://dspace.uba.uva.nl/server/api/core/bitstreams/0bb6b586-7133-49ad-b722-2cfc08555dcc/content},
  keywords = {bachelorsthesis},
  abstract = {This paper explores the implementation of a translator to sign language, using the JASigning avatarsoftware. Specifically, translation of Dutch into Sign Language of the Netherlands (NGT). As Dutch has been translated to a textual version of NGT in previous research, this research translated from textual NGT to synthesised NGT, the output signed by an avatar. This is one of three papers, each focusing on a different aspect of the translator: Lexical Resources, the Signing Space, and Multidimensionality. This paper pertains to the latter, and thus attempts to implement multiple dimensions into the avatar: the manual and non-manual component, which are both necessary to properly articulate a sign. The non-manual component of a sign being, for example, a facial expression, a head shake, the posture ofthe signer, etc. Specifically, it attempts to implement the non-manual markers paired with interrogative and negative constructs in NGT. Although the scope of this project is limited, it could provide a decent foundation for further research.},
  note = {Bachelor's thesis, University of Amsterdam.}
}

@unpublished{Mende-Gillings:20,
  title = {{The signing space for the synthesis of directional verbs in NGT}},
  author = {Mende-Gillings, Shani},
  year = {2020},
  url = {https://dspace.uba.uva.nl/server/api/core/bitstreams/6d3b7a8d-3927-4032-8837-a91659a48a9d/content},
  keywords = {bachelorsthesis},
  abstract = {Hearing parents who have deaf children are often put in a difficult position. They most likely know no sign language and resources for learning are limited and expensive. Research into sign language translation and synthesis has increased in the past two decades, due to a growing interest into making public spaces and services more accessible to Deaf people.<br> This research looks at the potential of a translator from Dutch to Dutch sign language (NGT) using a sign language avatar. In particular the focus lies on the synthesis of directional verbs, a critical grammatical component of sign language. The implementation is very limited and therefore the sentences it produces are not always comprehensible and the signs do not always look natural. It does, however, also demonstrate the potential of a sign language avatar as a tool for learning sign language.},
  note = {Bachelor's thesis, University of Amsterdam.}
}

@unpublished{Esselink:20,
  title = {{Lexical resources for sign language synthesis: The translation of Dutch to Sign Language of the Netherlands}},
  author = {Esselink, Lyke},
  year =  {2020},
  url = {https://dspace.uba.uva.nl/server/api/core/bitstreams/90908bfa-d553-42f9-a191-2f9249686a9c/content},
  keywords = {bachelorsthesis},
  abstract = {Deaf people oftentimes have no choice but to communicate in the lingua franca of their country, despite the fact that this is a second language for them. Their ability to read and write is significantly worse than that of a hearing person. Additionally, if a deaf child is born into a family of hearing parents, it is vital that the parents communicate with the child through sign language as soon as possible, otherwise the language region of that child's brain will be underdeveloped. There are currently few resources available for people to learn Sign Language of the Netherlands (NGT). A tool that makes this possible would be invaluable to those who need it. <br> This thesis investigates what components are necessary to build a system that uses an avatar to translate a Dutch sentence to NGT. On the basis of the workings of NGT and previous research on the matter, three main components are devised and implemented: software for sign language synthesis, lexical resources for encoding signs, and grammatical resources for structuring sentences. Results show a proof of concept with a corpus of 2226 signs, the ability to make correct use of classifiers, and the abilities to fingerspell any word that is not in the corpus and convey numbers correctly. However, the corpus contains a number of errors and of which manual errors and unnatural mouth signs should particularly be improved. Moreover, further research is necessary to improve the comprehensibility of signs.},
  note = {Bachelor's thesis, University of Amsterdam.}
}

@unpublished{Esselink:21,
  title = {Text-To-Sign Translation: Making Information Accessible},
  author = {Esselink, Lyke and Roelofsen, Floris},
  year = {2021},
  url = {https://www.signlab-amsterdam.nl/publications/SeminarSlides.pdf},
  keywords = {slides},
  note = {Seminar slides on the work of SignLab.}
}

@mastersthesis{gemert:22,
  title = {Co-designing a Sign Language Avatar for Railway Announcements},
  author = {Gemert, Britt van},
  school = {Radboud University},
  year = {2022},
  url = {https://www.signlab-amsterdam.nl/publications/van_Gemert.pdf},
  abstract = {Public transport organisations, such as Dutch railway operator Nederlandse Spoorwegen (NS), generally communicate important messages through spoken announcements in the train or station. As a result, Deaf people miss crucial information. Because of varying levels of reading proficiency, textual information is not always a solution. Moreover, video footage is not scalable and will not yield satisfactory results when individual video parts need an update. Virtual sign language avatars can provide consistent, anonymous and scalable translations. For the development of a comprehensible and fluent sign language avatar, collaboration between experts in language technology, avatar technology and sign language is fundamental. Unfortunately, inclusive approaches are not evident in existing technologies. To address these problems, we present a case study on co-designing a sign language avatar for the automatic translation of railway announcements into Sign Language of the Netherlands (NGT). For the initial design, video sign language translations of NS announcements created by the Dutch Sign Center were annotated and used for the translation basis. A scripted keyframe animation technique for the JASigning avatar engine makes it possible to efficiently create many variants of a given template, without expensive equipment. Three iterative co-design sessions took place with an interdisciplinary research team including deaf sign language experts. Simultaneously, hearing passengers from NS were consulted for additional remarks on the sign language avatar. Subsequently, multiple phrase variants of the system were evaluated within a diverse focus group audience to account for demographic differences. Combining the various disciplines led to mayor adjustments of the avatar (manual movements, facial expressions, mouthing, grammar, transitions between signs, camera angle and speed). With this case study, we aimed to effectively and inclusively develop sign language avatar technology. More research and focus groups are necessary to ensure high quality translations (improved mouthings, facial expressions and prosody), resulting in enhanced comprehensibility and natural appearance of the avatar.}
}

@unpublished{morking:23,
  title = {Agent-Backgrounding in Sign Language of the Netherlands: A Corpus Investigation},
  author = {M{\"o}rking, Anna-Lina},
  year = {2023},
  url = {https://www.signlab-amsterdam.nl/publications/Morking_thesis.pdf},
  keywords = {bachelorsthesis},
  abstract = {In agent-backgrounding constructions the causer of a linguistic event is pushed out of the focus, that is, it is backgrounded. In this thesis, for the first time, agent-backgrounding strategies were researched in Sign Language of the Netherlands (NGT). This is a corpus-based investigation on impersonalisation strategies such as impersonal uses of personal pronouns (ex. you), dedicated referentially deficient pronouns (ex. someone), and valency-reducing operations (ex. passive constructions). The results confirm that many of the same strategies are used in NGT as in other spoken and sign languages. These findings are highly relevant, as agent-backgrounding has not previously been researched in NGT, so our study fiills an important gap in the literature.},
  note = {Bachelor's thesis, University of Amsterdam.}
}

@mastersthesis{vachaudez:23,
  title = {Analyzing the ZELF and other reflexive constructions in Sign Language of the Netherlands from a Functional Discourse Grammar perspective: a corpus- based typological and theoretical study},
  author = {Vachaudez, Sybil},
  school = {University of Amsterdam},
  year = {2023},
  url = {https://www.signlab-amsterdam.nl/publications/Vachaudez_thesis.pdf},
  abstract = {This paper presents the first corpus-based study of reflexivity in Sign Language of the Netherlands (henceforth, NGT) and the first study of reflexivity in a sign language from a Functional Discourse Grammar perspective. Importantly, seven reflexive constructions were identified in NGT: i) ZELF constructions with a pronominal pointing sign, ii) ZELF constructions without a pronominal sign, iii) constructions with a reflexivized agreeing verb, iv) constructions with a reflexivized agreeing verb and a pronominal pointing sign, v) EIGEN constructions, vi) constructions with a pronominal pointing sign and vii) constructions with object omission. I argue that the first five constitute specialized reflexive constructions and show that the Functional Discourse Grammar model can successfully account for reflexivity in sign languages and that NGT possesses all three types of reflexive constructions proposed by the model: two-place reflexives, one-place reflexives, and mixed reflexives. Furthermore, two non- reflexive uses of ZELF were found: the possessive use and the anticausative use. I conclude by locating the NGT data within the landscape of reflexivity in both signed and spoken languages, commenting on the cognitive saliency of reflexivity and event participant structure, and raising questions for future research. The data for this study comes from Corpus NGT.}
}

@mastersthesis{joosten:23,
  title = {Giving a sign to the next generation: a corpus study of the grammaticalization of GIVE in Sign Language of the Netherlands (NGT)},
  author = {Joosten, Vivianne Sylvana},
  school = {University of Amsterdam},
  year = {2023},
  url = {https://www.signlab-amsterdam.nl/publications/Joosten_thesis.pdf},
  abstract = {The transfer verb GIVE is a fruitful base for metaphorical extension and grammaticalization across languages. Previous work by Bos (1996/2016) and Couvee and Pfau (2018) has shown that the sign GIVE is used beyond its underlying concrete transfer meaning in sign language of the Netherlands (NGT) as well. In this corpus study, I find GIVE in NGT to be used in a prototypical concrete transfer meaning in fewer than 30\% of the instances. Other uses attested in the corpus include (i) abstract transfer of linguistic type items such as INFORMATION, (ii) light verb use as well as serial verb use where GIVE marks a RECIPIENT rather than describing the transfer action, (iii) used in a causative construction and (iv) passive auxiliary use. I propose two different grammaticalization paths of GIVE in NGT, as well as evaluating NGT GIVE in a typological context. Extensions of GIVE all have a RECIPIENT-focus in NGT and are comparable to the extensions of GIVE found in other languages, both spoken and signed.}
}

@unpublished{Jeu:22,
  title = {Using avatar animation software for sign language synthesis},
  author = {Jeu, Roel de},
  year =  {2022},
  url = {https://dspace.uba.uva.nl/server/api/core/bitstreams/5f83a355-f4c2-4bd6-b263-885a9d6a6df6/content},
  keywords = {bachelorsthesis},
  abstract = {Deaf people can have a reading and writing delay due to the fact that the sign language of their country is their first language. Most hearing people do not understand sign language. This causes a language barrier to exist between deaf and hearing people. While tools like Google Translate support many languages, not a single sign language is included. This research reduces the language barrier between deaf and hearing people by developing a synthesis tool for sign language. This research focuses on evaluating different gaming and Virtual Reality avatar animation software to create signing avatars used for the synthesis tool. It also looks at converting motion capture data in to animations for the signing avatars. This conversion is implemented fully for one avatar. The resulting animation shows some unnatural movement but looks promising.},
  note = {Bachelor's thesis, University of Amsterdam.}
}

@unpublished{Gennissen:22,
  title = {Mouth visualizations on modern avatars as support for speech comprehension for the Dutch language and NGT},
  author = {Gennissen, Loes},
  year = {2022},
  url = {https://dspace.uba.uva.nl/bitstreams/a4d4666b-27aa-4a7f-99f8-e13621d2b91d/download},
  keywords = {bachelorsthesis},
  abstract = {This thesis explores the effect of mouth visualizations on modern avatars as support for speech comprehension. The mouth visualizations of the avatars were acquired by two state-of-the-art facial visualization methods in the field of deep learning and computer vision. An initial exploration was performed to inspect the possibilities and advantages of the two methods. Furthermore, the two methods were tested on their applicability to the Dutch language and the Dutch Sign Language (NGT). To analyze the effect of different kinds of avatars on speech comprehensibility, a survey experiment was conducted to gather information on the performance and opinions of participants.},
  note = {Bachelor's thesis, University of Amsterdam.}
}

@unpublished{Atia:22,
  title = {Use of a modern avatar for sign language synthesis: Movement tracking of manual gestures},
  author = {Atia, Merel},
  year = {2022},
  url = {https://dspace.uba.uva.nl/bitstreams/7a1dbcc9-2e6f-428f-8e13-ee65c504399e/download},
  keywords = {bachelorsthesis},
  abstract = {It is of great importance to make Dutch Sign Language (NGT) accessible to hearing people in order to improve the relationship between the deaf and hearing communities. We want to achieve this by creating an application that converts Dutch text to NGT performed by an avatar. To achieve this, an avatar must be created that is able to perform the different components of speaking sign language. In this research, the approach will be to let the avatar adapt motions performed by real live NGT speakers using a motion tracker. The results of previous research showed that gestures with specific finger positions, mainly when fingers overlap, were difficult to track. This research solves this problem by recording a NGT speaker from different views, and combining the results using a rigid body transformation. This way, the number of detected outliers are reduced significantly. The addition of cameras provides more insight into depth usage and estimation of the z-axis. It enables to detect bodyparts that are blocked from the main camera, which leads to more accurate tracking of gestures.},
  note = {Bachelor's thesis, University of Amsterdam.}
}


@unpublished{Shilo:21,
  title = {{Use of a modern avatar for sign language synthesis: Visualisation of non-manual NGT gestures}},
  author = {Shilo, Alon},
  year = {2021},
  url = {https://dspace.uba.uva.nl/bitstreams/fc79c65e-e35c-411e-bced-052a55ed8300/download},
  keywords = {bachelorsthesis},
  abstract = {This thesis explores the implementation for visualising the translation from Dutch sentences to the sign language of the Netherlands (NGT). This is one of three theses, each focusing on different parts of the avatar, which are eventually combined into one program. For this thesis, the goal is to implement a part of the non-manual side of NGT to create a proof of concept. The non-manual body parts of NGT include the head, face, shoulders and upper body. NGT is a complex language. Therefore it will take more time to completely visualize NGT using a new modern avatar, but this thesis provides a foundation for further research and implementation of the non-manual gestures of NGT.},
  note = {Bachelor's thesis, University of Amsterdam.}
}

@unpublished{Vijver:21,
  title = {Use of a modern avatar for sign language synthesis: Hand animations and the signing space},
  author = {Vijver, Matthijs van de},
  year = {2021},
  url = {https://dspace.uba.uva.nl/bitstreams/128a1797-658b-49c2-8562-9cd1d3f81872/download},
  keywords = {bachelorsthesis},
  abstract = {For deaf people, the written and spoken language of their country is often their second language. The first language for most deaf people is the sign language of their country. Because deaf people often have a reading and writing delay and not many hearing people speak sign language, a barrier is formed between deaf people who speak sign language and hearing people who do not. To overcome this problem ’signing avatars’ have been researched in the past decade: 3D computer models that can perform sign language. For the Dutch sign language and many other sign languages, the animation techniques that are used for this are deprecated. This research is focused on using modern techniques for animating these signing avatars. A model was built that shows potential in using these modern techniques to perform signs that are described in a dedicated markup language.},
  note = {Bachelor's thesis, University of Amsterdam.}
}


@unpublished{Hofwegen:21,
  title = {Modern avatar simulation for sign language synthesis: Hand configurations of the SiGML},
  author = {Hofwegen, Mark van},
  year = {2021},
  url = {https://dspace.uba.uva.nl/bitstreams/473c469e-4102-4133-9e53-e377263d5782/download},
  keywords = {bachelorsthesis},
  abstract = {Loss of hearing at young age has devastating effects on the development of a child. One of these effects is a learning deficit. This learning deficit can be strongly mitigated by introducing sign language as soon as deafness is diagnosed. However, most of deaf children are born to hearing parents who can not speak the Dutch Sign Language (NGT). Language acquisition of NGT is difficult for Dutch speaking people, since NGT has its own grammar and vocabulary. The main purpose of this thesis is to find out if modern avatar simulation techniques can be used to create a virtual sign language avatar to aid the learning process of NGT. Results show that modern software is applicable, but three main components are needed by the software in order to do so. A phonetic representation of the sign, a compatible rig with as many control points as needed by the phonetic representation and animation software to alter the orientation/position of the control points.},
  note = {Bachelor's thesis, University of Amsterdam.}
}


@unpublished{Bleijlevens:20,
  title = {{Learn Sign Online! A proposal for an online platform to learn Dutch Sign Language}},
  author = {Bleijlevens, Jasmijn},
  year = {2020},
  url = {https://www.signlab-amsterdam.nl/publications/Bleijlevens-2020.pdf},
  keywords = {bachelorsthesis},
  abstract = {This project studies the possibilities of designing an online platform for acquiring Dutch Sign Language (NGT), specifically focused on parents of deaf children. Children need a lot of (diverse) language input to lay a groundwork for their language development and it is thus important that people in their surroundings speak a language the child can interpret. Over the past decades, a lot of different distance learning technology have been developed for second language acquisition. This research will look into NGT and discuss all the grammatical topics which should be explained to people wanting to learn the language. Then, different technologies and will analyse which would suit learning NGT the best. Lastly, the two research topics will be combined and a design for a platform is proposed.},
  note = {Bachelor's thesis, Amsterdam University College.}
}

@article{sumer:20,
  title = {No effects of modality in development of locative expressions of space in signing and speaking children},
  author = {S{\"u}mer, Beyza and {\"O}zy{\"u}rek, Asl{\i}},
  publisher = {Cambridge University Press},
  journal = {Journal of Child Language},
  volume = {47},
  number = {6},
  pages = {1101--1131},
  year = {2020},
  doi = {10.1017/S0305000919000928},
  url = {https://www.cambridge.org/core/services/aop-cambridge-core/content/view/BBC33DFE646C026A6821511B4CD3CD68/S0305000919000928a.pdf/no-effects-of-modality-in-development-of-locative-expressions-of-space-in-signing-and-speaking-children.pdf},
  abstract = {Linguistic expressions of locative spatial relations in sign languages are mostly visually motivated representations of space involving mapping of entities and spatial relations between them onto the hands and the signing space. These are also morphologically complex forms. It is debated whether modality-specific aspects of spatial expressions modulate spatial language development differently in signing compared to speaking children. In a picture description task, we compared the use of locative expressions for containment, support, and occlusion relations by deaf children acquiring Turkish Sign Language and hearing children acquiring Turkish (age 3;5–9;11). Unlike previous reports suggesting a boosting effect of iconicity, and/or a hindering effect of morphological complexity of the locative forms in sign languages, our results show similar developmental patterns for signing and speaking children's acquisition of these forms. Our results suggest the primacy of cognitive development guiding the acquisition of locative expressions by speaking and signing children.}
}

@article{manhardt:20,
  title = {Iconicity in spatial language guides visual attention: A comparison between signers’ and speakers’ eye gaze during message preparation.},
  author = {Manhardt, Francie and {\"O}zy{\"u}rek, Asl{\i} and S{\"u}mer, Beyza and Mulder, Kimberley and Karad{\"o}ller, Dilay Z and Brouwer, Susanne},
  publisher = {American Psychological Association},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {46},
  number = {9},
  pages = {1735},
  year = {2020},
  doi = {10.1037/xlm0000843},
  url = {https://psycnet.apa.org/doiLanding?doi=10.1037%2Fxlm0000843},
  abstract = {To talk about space, spoken languages rely on arbitrary and categorical forms (e.g., left, right). In sign languages, however, the visual–spatial modality allows for iconic encodings (motivated form-meaning mappings) of space in which form and location of the hands bear resemblance to the objects and spatial relations depicted. We assessed whether the iconic encodings in sign languages guide visual attention to spatial relations differently than spatial encodings in spoken languages during message preparation at the sentence level. Using a visual world production eye-tracking paradigm, we compared 20 deaf native signers of Sign-Language-of-the-Netherlands and 20 Dutch speakers’ visual attention to describe left versus right configurations of objects (e.g., “pen is to the left/right of cup”). Participants viewed 4-picture displays in which each picture contained the same 2 objects but in different spatial relations (lateral [left/right], sagittal [front/behind], topological [in/on]) to each other. They described the target picture (left/right) highlighted by an arrow. During message preparation, signers, but not speakers, experienced increasing eye-gaze competition from other spatial configurations. This effect was absent during picture viewing prior to message preparation of relational encoding. Moreover, signers’ visual attention to lateral and/or sagittal relations was predicted by the type of iconicity (i.e., object and space resemblance vs. space resemblance only) in their spatial descriptions. Findings are discussed in relation to how “thinking for speaking” differs from “thinking for signing” and how iconicity can mediate the link between language and human experience and guides signers’ but not speakers’ attention to visual aspects of the world.}
}

@inproceedings{karadoller:21a,
  title = {Spatial language use predicts spatial memory of children: Evidence from sign, speech, and speech-plus-gesture},
  author = {Karadoller, Dilay Z and S{\"u}mer, Beyza and {\"U}nal, Ercenur and {\"O}zy{\"u}rek, Asl{\i}},
  booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume = {43},
  number = {43},
  year = {2021},
  issn = {1069-7977},
  url = {https://escholarship.org/content/qt4vp063gj/qt4vp063gj.pdf?t=qwi375&v=lg},
  abstract = {There is a strong relation between children’s exposure to spatial terms and their later memory accuracy. In the current study, we tested whether the production of spatial terms by children themselves predicts memory accuracy and whether and how language modality of these encodings modulates memory accuracy differently. Hearing child speakers of Turkish and deaf child signers of Turkish Sign Language described pictures of objects in various spatial relations to each other and later tested for their memory accuracy of these pictures in a surprise memory task. We found that having described the spatial relation between the objects predicted better memory accuracy. However, the modality of these descriptions in sign, speech, or speech-plus-gesture did not reveal differences in memory accuracy. We discuss the implications of these findings for the relation between spatial language, memory, and the modality of encoding.}
}

@article{karadoller:21b,
  title = {Effects and non-effects of late language exposure on spatial language development: Evidence from deaf adults and children},
  author = {Karad{\"o}ller, Dilay Z and S{\"u}mer, Beyza and {\"O}zy{\"u}rek, Asl{\i}},
  publisher = {Taylor \& Francis},
  journal = {Language Learning and Development},
  volume = {17},
  number = {1},
  pages = {1--25},
  year = {2021},
  doi = {10.1080/15475441.2020.1823846},
  url = {https://www.tandfonline.com/doi/pdf/10.1080/15475441.2020.1823846?needAccess=true},
  abstract = {Late exposure to the first language, as in the case of deaf children with hearing parents, hinders the production of linguistic expressions, even in adulthood. Less is known about the development of language soon after language exposure and if late exposure hinders all domains of language in children and adults. We compared late signing adults and children (MAge = 8;5) 2 years after exposure to sign language, to their age-matched native signing peers in expressions of two types of locative relations that are acquired in certain cognitive-developmental order: view-independent (IN-ON-UNDER) and view-dependent (LEFT-RIGHT). Late signing children and adults differed from native signers in their use of linguistic devices for view-dependent relations but not for view-independent relations. These effects were also modulated by the morphological complexity. Hindering effects of late language exposure on the development of language in children and adults are not absolute but are modulated by cognitive and linguistic complexity.}
}

@article{gur:22,
  title = {Learning to introduce referents in narration is resilient to the effects of late sign language exposure},
  author = {G{\"u}r, C and S{\"u}mer, Beyza},
  journal = {Sign Language \& Linguistics},
  year = {2022},
  volume = {25},
  number = {2}
}

@article{sumer:22,
  title = {Cross-modal investigation of event component omissions in language development: a comparison of signing and speaking children},
  author = {S{\"u}mer, Beyza and {\"O}zy{\"u}rek, Asl{\i}},
  publisher = {Taylor \& Francis},
  journal = {Language, Cognition and Neuroscience},
  pages = {1--17},
  year = {2022},
  doi = {10.1080/23273798.2022.2042336},
  url = {https://www.tandfonline.com/doi/pdf/10.1080/23273798.2022.2042336?needAccess=true},
  abstract = {Language development research suggests a universal tendency for children to be under- informative in narrating motion events by omitting components such as Path, Manner or Ground. However, this assumption has not been tested for children acquiring sign language. Due to the affordances of the visual-spatial modality of sign languages for iconic expression, signing children might omit event components less frequently than speaking children. Here we analysed motion event descriptions elicited from deaf children (4–10 years) acquiring Turkish Sign Language (TİD) and their Turkish-speaking peers. While children omitted all types of event components more often than adults, signing children and adults encoded more Path and Manner in TİD than their peers in Turkish. These results provide more evidence for a general universal tendency for children to omit event components as well as a modality bias for sign languages to encode both Manner and Path more frequently than spoken languages.}
}

@article{karadoller:22,
  title = {Late sign language exposure does not modulate the relation between spatial language and spatial memory in deaf children and adults},
  author = {Karad{\"o}ller, Dilay Z and S{\"u}mer, Beyza and {\"U}nal, Ercenur and {\"O}zy{\"u}rek, Asl{\i}},
  publisher = {Springer},
  journal = {Memory \& Cognition},
  pages = {1--19},
  year = {2022},
  doi = {10.3758/s13421-022-01281-7},
  url = {https://link.springer.com/content/pdf/10.3758/s13421-022-01281-7.pdf},
  abstract = {Prior work with hearing children acquiring a spoken language as their first language shows that spatial language and cognition are related systems and spatial language use predicts spatial memory. Here, we further investigate the extent of this relationship in signing deaf children and adults and ask if late sign language exposure, as well as the frequency and the type of spatial language use that might be affected by late exposure, modulate subsequent memory for spatial relations. To do so, we compared spatial language and memory of 8-year-old late-signing children (after 2 years of exposure to a sign language at the school for the deaf) and late-signing adults to their native-signing counterparts. We elicited picture descriptions of Left-Right relations in Turkish Sign Language (Türk İşaret Dili) and measured the subsequent recognition memory accuracy of the described pictures. Results showed that late-signing adults and children were similar to their native-signing counterparts in how often they encoded the spatial relation. However, late-signing adults but not children differed from their native-signing counterparts in the type of spatial language they used. However, neither late sign language exposure nor the frequency and type of spatial language use modulated spatial memory accuracy. Therefore, even though late language exposure seems to influence the type of spatial language use, this does not predict subsequent memory for spatial relations. We discuss the implications of these findings based on the theories concerning the correspondence between spatial language and cognition as related or rather independent systems.}
}

@inproceedings{hollain:23a,
  author = {Hollain, Natalie and Larson, Martha and Roelofsen, Floris},
  booktitle={2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)},
  title={Distractor-Based Evaluation of Sign Spotting},
  year={2023},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICASSPW59220.2023.10193484},
  url = {https://doi.org/10.1109/ICASSPW59220.2023.10193484},
  keywords = {Sign spotting, Evaluation, Distractors},
  abstract = {Sign spotting is a subtask of sign language processing in which we determine when a given target sign occurs in a given sign sequence. This paper proposes a method for evaluating sign spotting systems, which we argue to be more reflective of the degree to which a system would satisfy the user’s requirements in practice than previously proposed evaluation methods. To deal with an incomplete ground truth, we introduce the concept of distractors: signs which are similar to the target sign according to a given distance measure. We assume that the performance of a sign spotting model when distinguishing a given target sign from the associated distractors will reflect the performance of the model on the complete ground truth. We develop a sign spotting model to demonstrate our evaluation method.}
}

@inproceedings{hollain:23b,
    title = {Analyzing the Potential of Linguistic Features for Sign Spotting: A Look at Approximative Features},
    author = {Hollain, Natalie and Larson, Martha  and Roelofsen, Floris},
    booktitle = {Proceedings of the Second International Workshop on Automatic Translation for Signed and Spoken Languages},
    month = {jun},
    year = {2023},
    address = {Tampere, Finland},
    publisher = {European Association for Machine Translation},
    url = {https://aclanthology.org/2023.at4ssl-1.1},
    pages = {1--10},
    abstract = {Sign language processing is the field of research that aims to recognize, retrieve, and spot signs in videos. Various approaches have been developed, varying in whether they use linguistic features and whether they use landmark detection tools or not. Incorporating linguistics holds promise for improving sign language processing in terms of performance, generalizability, and explainability. This paper focuses on the task of sign spotting and aims to expand on the approximative linguistic features that have been used in previous work, and to understand when linguistic features deliver an improvement over landmark features. We detect landmarks with Mediapipe and extract linguistically relevant features from them, including handshape, orientation, location, and movement. We compare a sign spotting model using linguistic features with a model operating on landmarks directly, finding that the approximate linguistic features tested in this paper capture some aspects of signs better than the landmark features, while they are worse for others.},
}

@mastersthesis{hollain:23c,
  title = {Towards Explainable Sign Spotting Systems: an Exploration of Approximative Linguistic Features and Evaluation Methods},
  author = {Hollain, Natalie},
  school = {Radboud University},
  year = {2023},
  url = {https://www.signlab-amsterdam.nl/publications/Natalie-Hollain-thesis.pdf},
  abstract = {This research project carried out an initial exploration into how sign spotting, the task of detecting when a target sign occurs in a given video, can be performed in a more explainable manner. Explainability demands that a system is correct, robust and interpretable to humans [1], [2]. Inspired by domain knowledge being used to increase the explainability and interpretability of systems in other domains [3], [4], we investigate the possibility of using a knowledge-based approach for sign spotting.

  One manner in which knowledge about sign language can be incorporated into sign language systems is through linguistic insights. Current sign spotting systems typically do not make use of such knowledge [5], thus limiting their interpretability. Similarly, evaluation methods for sign spotting do not draw on linguistic knowledge, resulting in a lack of explainability since they fail to robustly estimate model performance given an incomplete ground truth. Updates to the known ground truth, in particular the addition of challenging sign annotations, can significantly alter the estimated performance. Moreover, current evaluations do not reflect user expectations for sign spotting systems because spottings are allowed to occur after a relevant segment has already started. Users thus have to put in effort, such as rewinding the video, to watch the full relevant segment, which was found to not reflect what users expect [6].

  The goal of this thesis is to address these limitations using a knowledge-based approach. We incorporate linguistic knowledge about sign language into a sign spotting system and evaluation method. We aim to enhance explainability by enabling a sign spotting analysis based on linguistic insights. Furthermore, we develop linguistic features to ensure our model uses knowledge-based inputs as the basis for its decision-making. In this way, we hope to increase the explainability of current methods.

  To address the need for explainable sign spotting systems, we implemented features for a sign spotting model that approximate the basic phonological properties of signs, including handshape, orientation, location and movement [7], [8]. Our features are extracted from landmarks, which are keypoints in the body, such as the fingertips and shoulders, that we detected using a landmark detection tool. As far as we are aware, we are the first to implement a sign spotting model which extracts such features from landmarks. By taking into account the basic four phonological properties, we aim to create explainable sign representations for our model to encode. As a result, it is possible to perform a failure analysis for our model that is facilitated by the linguistic features.

  To address the need for explainable evaluation methods for sign spotting, we developed an evaluation that is rooted in the concept of tolerance to irrelevance (TTI) [9]. TTI builds on the assumption that users, given an entry point in a video or audio stream, keep watching or listening until their tolerance to irrelevant content is reached. Through this means, our evaluation method reflects the effort it takes for users to use a sign spotting system.

  However, TTI, like existing sign spotting evaluations, relies on a full ground truth to reliably determine a model’s performance, which may not be available for a sign spotting dataset. We address this limitation by using a novel approach that uses only the most challenging known cases to assess our model performance. These hardest cases are called distractors, which we define as those signs that are most similar to the target sign based on a distance measure. In our work, we develop a novel linguistic distance measure to determine the similarity between signs. Through the usage of these distractors, we estimate the performance for the full ground truth based solely on the hardest cases from the known ground truth, and assume that this makes our performance estimation robust to the addition of new annotations. We validated this assumption by investigating the effects of updates to the annotations on the performance estimates by our distractor-based evaluation compared to a baseline evaluation that uses random, as opposed to hard, cases. Our results show that the distractor-based evaluations provides a more conservative estimate of the performance of a model and is comparably robust to changes in the annotations compared to the baseline.

  We validated our linguistic features using an empirical analysis, where we compared the effectiveness of a non-linguistic baseline that used landmarks directly, to a model using our more explainable, linguistically motivated features that are extracted from landmarks. Moreover, we investigated whether a combination of linguistic and baseline landmark features would result in better performance. The conditions were compared through the use of our distractor-based evaluation. We determined that the combination of the features provided the best performance at the cost of linguistic representativeness.}
}

@mastersthesis{esselink:23a,
  title = {Computer Vision and Machine Learning for the Analysis of Non-Manual Markers in Biased Polar Questions in Sign Language of the Netherlands},
  author = {Esselink, Lyke},
  school = {Radboud University},
  year = {2023},
  url = {https://www.signlab-amsterdam.nl/publications/Master_Thesis_Lyke_Esselink.pdf},
  abstract = {This research project carried out a methodological exploration of the application of Computer Vision (CV) technologies for gathering data for sign language research, and of the application of Machine Learning (ML) techniques to analyse such data. In order to explore these methods, we applied them to the specific domain of analysing prototypical facial expressions for question marking in Sign Language of the Netherlands (NGT), otherwise referred to as non-manual markers (NMMs). Typically, the literature on this subject describes only one way in which questions are marked. However, there is more variation in the NMM of polar questions than is generally acknowledged in the literature. This research project aims to investigate if bias can account for part of this variation in NMM of polar questions in Sign Language of the Netherlands (NGT). We hypothesized that speaker bias could account for some of these variations in facial expressions, and that there are multiple variations with restrictions relating to applicability in specific contexts. Data was elicited in an experiment through role-play type conversations between participants and confederates. A 3D depth camera was used to measure engagement of 61 facial features, and the ML method clustering was used to find prototypical facial expressions in the data. We found two overarching prototypical facial expressions for marking polar questions in NGT. One included raised eyebrows and eyes wide open, whereas the other included furrowed eyebrows and squinted eyes. Further, we found several variations within these two facial expressions, varying in feature intensity and in additional non-manual markers such as a mouth frown. We found two definite constraints of these facial expressions relating to their applicability. The first was that facial expressions with raised eyebrows do not occur in contexts in which a person holds a positive prior belief and is subsequently presented with negative contextual evidence. The second constraint was that facial expressions involving significantly frowning mouth do not occur in the beginning of a question, but only in the middle and end. Future work includes further examination of these clusters by crossing contexts and temporal windows to investigate the temporal development of these facial expressions and whether further constraints can be found.}
}

@inproceedings{esselink:23b,
  author = {Esselink, Lyke and Oomen, Marloes and Roelofsen, Floris},
  booktitle={2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)},
  title={Truedepth Measurements of Facial Expressions: Sensitivity to the Angle Between Camera and Face},
  year={2023},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICASSPW59220.2023.10193107},
  url = {https://doi.org/10.1109/ICASSPW59220.2023.10193107},
  keywords = {Facial expressions, Depth-sensing cameras},
  abstract = {Facial expressions play an important role in communication, especially in sign languages. Linguistic analysis of the exact contribution of facial expressions, as well as the creation of realistic conversational avatars, especially sign language avatars, requires accurate measurements of the facial expressions of humans while engaged in linguistic interaction. Several recent projects have employed a TrueDepth camera to make such measurements. The present paper investigates how reliable this technique is. In particular, we consider the extent to which the obtained measurements are affected by the angle between the camera and the face. Overall, we find that there are generally significant, and often rather substantial differences between measurements from different angles. However, when the measured facial features are highly activated, measurements from different angles are generally strongly correlated.}
}

@article{esselink:23c,
  author={Esselink, Lyke and Marloes, Oomen and Floris, Roelofsen},
  title={Exploring new methods for measuring, analyzing, and visualizing facial expressions},
  journal={FEAST. Formal and Experimental Advances in Sign language Theory},
  volume={5},
  url={https://raco.cat/index.php/FEAST/article/view/422433},
  DOI={10.31009/FEAST.i5.04},
  year={2023},
  pages={35-48},
  keywords = {Facial expressions, Depth-sensing cameras, Clustering, Visualization},
  abstract = {We explore new methods for measuring, analyzing, and visualizing facial expressions and demonstrate the utility of these methods in a case study on polar questions in Sign Language of the Netherlands.}
}

@article{oomen:23a,
  author={Oomen, Marloes and Floris, Roelofsen},
  title={Biased polar question forms in Sign Language of the Netherlands (NGT)},
  journal={FEAST. Formal and Experimental Advances in Sign language Theory},
  volume={5},
  url={https://raco.cat/index.php/FEAST/article/view/422450},
  DOI={10.31009/FEAST.i5.13},
  year={2023},
  pages={156-168},
  keywords = {Sign Language of the Netherlands (NGT), polar questions, bias, headshake},
  abstract = {We identify several polar question forms in Sign Language of the Netherlands (NGT) through a production experiment in which we manipulate two types of biases: (i) the prior expectations of the person asking the question, and (ii) the evidence available in the immediate context of utterance. Our analysis in the present paper focuses on forms involving headshake. We find that in some cases headshake expresses negation, as ex- pected, but in other cases it fulfils another function, namely, it is part of a sentence-final phrase either expressing uncertainty or signalling a request for a response from the ad- dressee, or possibly both at the same time. We further observe that each question form has a distinct ‘bias profile’, indicating a certain combination of prior expectations and contextual evidence. Besides these empirical findings, our study also makes a method- ological contribution: our experimental design could be used in future work to identify polar question forms with different bias profiles in sign languages other than NGT, as well as visual cues accompanying polar questions with different bias profiles in spoken languages.}
}

@inproceedings{oomen:23b,
    author = {Marloes Oomen and Lyke Esselink and {de Ronde}, Tobias. and Floris Roelofsen},
    year = {2023},
    title = {First Steps Towards a Procedure for Annotating Non-Manual Markers in Sign Languages},
    language = {English},
    isbn = {9798869982261},
    volume = {2},
    pages = {257--266},
    editor = {S.-Y. Lam and S. Ozaki},
    booktitle = {NELS 53: Proceedings of the Fifty-Third Annual Meeting of the North East Linguistic Society},
    publisher = {GLSA},
    url = {https://www.signlab-amsterdam.nl/publications/NELS53_Proceedings_Oomen.pdf},
    abstract = {We report on the development, application, and evaluation of a procedure for annotating non-manual markers (NMM) in experimentally obtained sign language data. We also share resources to enable other researchers investigating NMM in sign languages or multimodal communication to utilize the annotation protocol we developed in their own research.}
}

@article{oomen:23c,
  author={Oomen, Marloes and Mirko, Santoro and Carlo, Geraci},
  title={Some properties of neg-raising in three sign languages},
  journal={FEAST. Formal and Experimental Advances in Sign language Theory},
  volume={5},
  url={https://raco.cat/index.php/FEAST/article/view/422449},
  DOI={10.31009/FEAST.i5.12},
  year={2023},
  pages={145-155},
  keywords = {Neg-raising, Negative Polarity Items, Negative quantifiers, Headshake},
  abstract = {Neg-raising, the phenomenon whereby a negation in the main clause of a complex construction is interpreted as if belonging to the embedded clause, has been intensively studied in spoken languages. The same cannot be said for sign languages. In this paper, we investigate the properties of Neg-raising constructions in three sign languages: French Sign Language, Italian Sign Language, and Sign Language of the Netherlands. We report on two syntactic tests we applied to disambiguate Neg-raising and non-Neg-raising readings, showing that Neg-raising constructions have similar properties in the three sign languages that we studied, as well as in comparable constructions in spoken languages. We also discuss some intricate headshake spreading patterns we found in Neg-raising constructions in Sign Language of the Netherlands, a non-manual dominant sign language.}
}

@inproceedings{neijman:22,
  author = {Neijman, Marise and Hof, Femke and Oosterom, Noelle and Pfau, Roland and Rooy, Bertus van and Son, Rob J.J.H. van and Brekel, Michiel M.W.M. van den},
  title = {{Compensation in Verbal and Nonverbal Communication after Total Laryngectomy}},
  year = {2022},
  booktitle = {Proc. Interspeech 2022},
  pages = {3613--3617},
  doi = {10.21437/Interspeech.2022-369},
  url = {https://www.isca-speech.org/archive/interspeech_2022/neijman22_interspeech.html},
  abstract = {Total laryngectomy is a major surgical procedure with life-changing consequences. As a result of the surgery, the upper and lower airways are disconnected, the natural voice is lost, and patients breathe through a tracheostoma in the neck. Tracheoesophageal speech is the most common speech rehabilitation technique. Due to the lack of air volume, and the amount of muscle tension in the esophagus, some patients may suffer from a hyper- or hypo-tonic voice, resulting in less intelligible speech. To communicate as intelligibly as possible, patients likely adapt their verbal and nonverbal communication to their physical disabilities. The current study aimed to explore the compensation techniques in verbal and nonverbal communication after total laryngectomy focusing on the complexity of grammar and the use of co-speech gestures. We analyzed previously obtained interviews of eight laryngectomized women on the syntactic complexity in speech and the use and type of co-speech gestures. Results were compared with analyses of productions by healthy controls. We found that laryngectomized women reduce the syntactic complexity of their speech, and use nonverbal gestures in their communication. Further research is needed with systematically obtained data and more suitable match-groups. Index Terms: total laryngectomy, communication, speech, co-speech gestures, grammar, compensation}
}

@incollection{Rodrigues:23,
  author = {Rodrigues, Ang{\'e}lica and Pfau, Roland},
  editor = {Massini-Cagliari, Gladis and Berlinck, Rosane Andrade and Rodrigues, Angelica},
  title = {Language Prejudice and Language Structure: On Missing and Emerging Conjunctions in Libras and Other Sign Languages},
  bookTitle = {Understanding Linguistic Prejudice: Critical Approaches to Language Diversity in Brazil},
  year = {2023},
  publisher = {Springer International Publishing},
  pages = {157--185},
  isbn = {978-3-031-25806-0},
  doi = {10.1007/978-3-031-25806-0_10},
  url = {https://doi.org/10.1007/978-3-031-25806-0_10},
  abstract = {Sign languages, just like many indigenous languages, have traditionally been subject to language prejudice and suppression, based in no small part on invalid claims about their structural complexity. In this chapter, we aim to contribute to the discussion on language prejudice by broadening the scope to include deaf communities and their sign languages. We review and reject claims according to which languages can be classified as ``primitive'' or ``evolved'' based on the absence of certain grammatical categories. One such grammatical category are conjunctions, and we investigate in some detail their absence or presence in sign languages. We present examples from various sign languages which show that -- just as in spoken languages -- conjunctions may emerge through diachronic processes of borrowing and grammaticalization. Focusing on data from Brazilian Sign Language, we then demonstrate that both these processes are at play in the language and that manual conjunctions marking disjunctive, adversative, conditional, and causal relations have entered the lexicon. Our hope is that these findings will contribute -- albeit modestly -- to the status of Brazilian Sign Language.}
}

@article{motamedi:22,
  title = {From improvisation to learning: how naturalness and systematicity shape language evolution},
  author = {Motamedi, Yasamin and Wolters, Lucie and Naegeli, Danielle and Kirby, Simon and Schouwstra, Marieke},
  publisher = {Elsevier},
  journal = {Cognition},
  volume = {228},
  year = {2022},
  doi = {10.1016/j.cognition.2022.105206},
  url = {https://reader.elsevier.com/reader/sd/pii/S0010027722001949?token=30EF48857FED119FAFE86A8780B2A3F46374F7A756DC93BE40B355F59199CFD7D202EA7569D0ED9CB6DB465E74E8B841&originRegion=eu-west-1&originCreation=20220928152802},
  abstract = {Silent gesture studies, in which hearing participants from different linguistic backgrounds produce gestures to communicate events, have been used to test hypotheses about the cognitive biases that govern cross-linguistic word order preferences. In particular, the differential use of SOV and SVO order to communicate, respectively, extensional events (where the direct object exists independently of the event; e.g., girl throws ball) and intensional events (where the meaning of the direct object is potentially dependent on the verb; e.g., girl thinks of ball), has been suggested to represent a natural preference, demonstrated in improvisation contexts. However, natural languages tend to prefer systematic word orders, where a single order is used regardless of the event being communicated. We present a series of studies that investigate ordering preferences for SOV and SVO orders using an online forced-choice experiment, where English-speaking participants select orders for different events i) in the absence of conventions and ii) after learning event-order mappings in different frequencies in a regularisation experiment. Our results show that natural ordering preferences arise in the absence of conventions, replicating previous findings from production experiments. In addition, we show that participants regularise the input they learn in the manual modality in two ways, such that, while the preference for systematic order patterns increases through learning, it exists in competition with the natural ordering preference, that conditions order on the semantics of the event. Using our experimental data in a computational model of cultural transmission, we show that this pattern is expected to persist over generations, suggesting that we should expect to see evidence of semantically-conditioned word order variability in at least some languages.}
}

@inproceedings{dona:22,
  title = {Modelling the Emergence of Linguistic Conventions for Word Order: The Roles of Semantics, Structural Priming, and Population Structure},
  author = {Dona, Lo{\"\i}s and Schouwstra, Marieke},
  booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume = {44},
  number = {44},
  year = {2022},
  url = {https://escholarship.org/content/qt5dp2600s/qt5dp2600s.pdf?t=reckca&v=lg},
  abstract = {We used agent-based modelling to study the emergence of linguistic conventions for basic word order (the order of subject, object and verb) in different populations. As a starting point, we take word order variation based on semantic properties, as observed in improvised gesture experiments. In our first simulation we explore the relative contributions of two pressures, one for semantically conditioned variation, and the other structural priming (which takes place when two individuals engage in communication), and show that a relatively increasing influence of structural priming best explains an increase in word order regularity. Next we implement a larger simulation, investigating how properties of the population affect regularization of word order. Our models compare population sizes with different population densities, and show that the speed of regularization in languages is heavily influenced by population density, and population size has little effect.}
}

@inproceedings{naegeli:22,
  title = {Cross-cultural differences in the emergence of referential strategies in artificial sign languages},
  author = {Naegeli, Danielle and Peeters, David and Krahmer, Emiel and Schouwstra, Marieke and Motamedi, Yasamin and De Vos, Connie},
  booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume = {44},
  number = {44},
  year = {2022},
  url = {https://escholarship.org/content/qt7861289g/qt7861289g.pdf?t=recks3&v=lg},
  abstract = {While the grammatical use of space for referential strategies is attested across many sign languages of Western Europe, Kata Kolok, a rural sign language used in Northern Bali, has not developed anaphoric pointing in space nor agreement verbs (Engberg-Pedersen, 1993; Liddell, 2003; de Vos, 2012). To find out whether such typological differences can be explained by differences in the respective co-speech gesture systems, this preregistered study is collecting data for a cross-cultural comparison. Building on Motamedi et al. (2021), we are conducting studies in Bali and the Netherlands using an iterated learning silent gesture paradigm in which hearing people communicate transitive events using only gestures. Preliminary data indeed suggest that our Balinese participants do not employ space the same way our Dutch participants do. We will present comparative analyses and evaluate the role of co-speech gesture systems in sign language emergence in the lab or when evolving from spontaneous interaction.}
}

@article{schouwstra:22,
  title = {Investigating Word Order Emergence: Constraints From Cognition and Communication},
  author = {Schouwstra, Marieke and Naegeli, Danielle and Kirby, Simon},
  publisher = {Frontiers},
  journal = {Frontiers in Psychology},
  pages = {1855},
  year = {2022},
  doi = {10.3389/fpsyg.2022.805144},
  url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2022.805144/full},
  abstract = {How do cognitive biases and mechanisms from learning and use interact when a system of language conventions emerges? We investigate this question by focusing on how transitive events are conveyed in silent gesture production and interaction. Silent gesture experiments (in which participants improvise to use gesture but no speech) have been used to investigate cognitive biases that shape utterances produced in the absence of a conventional language system. In this mode of communication, participants do not follow the dominant order of their native language (e.g., Subject-Verb-Object), and instead condition the structure on the semantic properties of the events they are conveying. An important source of variability in structure in silent gesture is the property of reversibility. Reversible events typically have two animate participants whose roles can be reversed (girl kicks boy). Without a syntactic/conventional means of conveying who does what to whom, there is inherent unclarity about the agent and patient roles in the event (by contrast, this is less pressing for non-reversible events like girl kicks ball). In experiment 1 we test a novel, fine-grained analysis of reversibility. Presenting a silent gesture production experiment, we show that the variability in word order depends on two factors (properties of the verb and properties of the direct object) that together determine how reversible an event is. We relate our experimental results to principles from information theory, showing that our data support the “noisy channel” account of constituent order. In experiment 2, we focus on the influence of interaction on word order variability for reversible and non-reversible events. We show that when participants use silent gesture for communicative interaction, they become more consistent in their usage of word order over time, however, this pattern less pronounced for events that are classified as strongly non-reversible. We conclude that full consistency in word order is theoretically a good strategy, but word order use in practice is a more complex phenomenon.}
}

@misc{motamedi:21a,
	title = {The effects of iconicity and conventionalisation on word order preferences},
	author = {Motamedi, Yasamin and Wolters, Lucie and Schouwstra, Marieke and Kirby, Simon},
  publisher = {PsyArXiv},
  year = {2021},
  doi = {10.31234/osf.io/u5amg},
	url = {https://doi.org/10.31234/osf.io/u5amg},
  abstract = {Of the 6 possible orderings of the 3 main constituents of language (subject, verb and object), two —- SOV and SVO —- are predominant cross-linguistically. Previous research using the silent gesture paradigm in which hearing participants produce or respond to gestures without speech, has shown that different factors such as reversibility, salience and animacy can affect the preferences for different orders. Here, we test whether participants’ preferences for orders that are conditioned on the semantics of the event change depending on i) the iconicity of individual gestural elements and ii) the prior knowledge of a conventional lexicon. Our findings demonstrate the same preference for semantically-conditioned word order found in previous studies, specifically that SOV and SVO are preferred differentially for different types of events. We do not find that iconicity of individual gestures affects participants’ ordering preferences, however we do find that learning a lexicon leads to a stronger preference for SVO-like orders overall. Finally, we compare our findings from English speakers, using an SVO-dominant language, with data from speakers of an SOV-dominant language, Turkish. We find that, while learning a lexicon leads to an increase in SVO preference for both sets of participants, this effect is mediated by language background and event type, suggesting that an interplay of factors together determine preferences for different ordering patterns. Taken together, our results support a view of word order as a gradient phenomenon responding to multiple biases.}
}

@misc{royka:21,
  title = {I Know You Know I’m Signaling: Novel gestures are designed to guide observers’ inferences about communicative goals},
  author = {Royka, Amanda and Schouwstra, Marieke and Kirby, Simon and Jara-Ettinger, Julian},
  publisher = {PsyArXiv},
  year = {2021},
  doi = {10.31234/osf.io/2h5vu},
  url = {psyarxiv.com/2h5vu},
  abstract = {For a gesture to be successful, observers must recognize its communicative purpose. Are communicators sensitive to this problem and do they try to ease their observer’s inferential burden? We propose that people shape their gestures to help observers easily infer that their movements are meant to communicate. Using computational models of recursive goal inference, we show that this hypothesis predicts that gestures ought to reveal that the movement is inconsistent with the space of non-communicative goals in the environment. In two gesture-design experiments, we find that people spontaneously shape communicative movements in response to the distribution of potential instrumental goals, ensuring that the movement can be easily differentiated from instrumental action. Our results show that people are sensitive to the inferential demands that observers face. As a result, people actively work to help ensure that the goal of their communicative movement is understood.}
}

@article{motamedi:21b,
  title = {The emergence of systematic argument distinctions in artificial sign languages},
  author = {Motamedi, Yasamin and Smith, Kenny and Schouwstra, Marieke and Culbertson, Jennifer and Kirby, Simon},
  publisher = {Oxford University Press},
  journal = {Journal of Language Evolution},
  volume = {6},
  number = {2},
  pages = {77--98},
  year = {2021},
  doi = {10.1093/jole/lzab002},
  url = {https://academic.oup.com/jole/article/6/2/77/6303767},
  abstract = {Word order is a key property by which languages indicate the relationship between a predicate and its arguments. However, sign languages use a number of other modality-specific tools in addition to word order such as spatial agreement, which has been likened to verbal agreement in spoken languages, and role shift, where the signer takes on characteristics of propositional agents. In particular, data from emerging sign languages suggest that, though some use of a conventional word order can appear within a few generations, systematic spatial modulation as a grammatical feature takes time to develop. We experimentally examine the emergence of systematic argument marking beyond word order, investigating how artificial gestural systems evolve over generations of participants in the lab. We find that participants converge on different strategies to disambiguate clause arguments, which become more consistent through the use and transmission of gestures; in some cases, this leads to conventionalized iconic spatial contrasts, comparable to those found in natural sign languages. We discuss how our results connect with theoretical issues surrounding the analysis of spatial agreement and role shift in established and newly emerging sign languages, and the possible mechanisms behind its evolution.}
}

@inproceedings{motamedi:21c,
  title = {Regularisation, systematicity and naturalness in a silent gesture learning task},
  author = {Motamedi, Yasamin and Wolters, Lucie and Naegeli, Danielle and Schouwstra, Marieke and Kirby, Simon},
  booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume = {43},
  number = {43},
  year = {2021},
  url = {https://escholarship.org/content/qt8xf3216h/qt8xf3216h.pdf?t=qwi3pz&v=lg},
  abstract = {Typological analysis of the world’s language shows that, of the 6 possible basic word orders, SOV and SVO orders are predominant, a preference supported by experimental studies in which participants improvise gestures to describe events. Silent gesture studies have also provided evidence for natural ordering patterns, where SOV and SVO orders are used selectively depending on the semantics of the event, a finding recently supported by data from natural sign languages. We present an artificial language learning task using gesture to ask to what extent preferences for natural ordering patterns, in addition to biases for regular languages, are at play during learning in the manual modality.}
}

@article{kirton:21,
  title = {Constituent order in silent gesture reflects the perspective of the producer},
  author = {Kirton, Fiona and Kirby, Simon and Smith, Kenny and Culbertson, Jennifer and Schouwstra, Marieke},
  publisher = {Oxford University Press},
  journal = {Journal of Language Evolution},
  volume = {6},
  number = {1},
  pages = {54--76},
  year = {2021},
  doi = {10.1093/jole/lzaa010},
  url = {https://academic.oup.com/jole/article/6/1/54/6179035},
  abstract = {Understanding the relationship between human cognition and linguistic structure is a central theme in language evolution research. Numerous studies have investigated this question using the silent gesture paradigm in which participants describe events using only gesture and no speech. Research using this paradigm has found that Agent–Patient–Action (APV) is the most commonly produced gesture order, regardless of the producer’s native language. However, studies have uncovered a range of factors that influence ordering preferences. One such factor is salience, which has been suggested as a key determiner of word order. Specifically, humans, who are typically agents, are more salient than inanimate objects, so tend to be mentioned first. In this study, we investigated the role of salience in more detail and asked whether manipulating the salience of a human agent would modulate the tendency to express humans before objects. We found, first, that APV was less common than expected based on previous literature. Secondly, salience influenced the relative ordering of the patient and action, but not the agent and patient. For events involving a non-salient agent, participants typically expressed the patient before the action and vice versa for salient agents. Thirdly, participants typically omitted non-salient agents from their descriptions. We present details of a novel computational solution that infers the orders participants would have produced had they expressed all three constituents on every trial. Our analysis showed that events involving salient agents tended to elicit AVP; those involving a non-salient agent were typically described with APV, modulated by a strong tendency to omit the agent. We argue that these findings provide evidence that the effect of salience is realized through its effect on the perspective from which a producer frames an event.}
}

@misc{schouwstra:20,
 title = {The emergence of word order conventions: improvisation, interaction and transmission},
 author = {Schouwstra, Marieke and Smith, Kenny and Kirby, Simon},
 publisher = {PsyArXiv},
 year = {2020},
 doi = {10.31234/osf.io/wdfu2},
 url = {psyarxiv.com/wdfu2},
 abstract = {When people improvise to convey information by using only gesture and no speech (‘silent gesture’), they show language-independent word order preferences: SOV for extensional events (e.g., boy-ball-throw), but SVO for intensional events (e.g., boy-search-ball). Real languages tend not to condition word order on this kind of semantic distinction but instead use the same order irrespective of event type. Word order therefore exemplifies a contrast between naturalness in improvisation and conventionalised regularity in linguistic systems. We present an experimental paradigm in which initially-improvised silent gesture is both used for communication and culturally transmitted through artificial generations of lab participants. In experiments 1 and 2 we investigate the respective contributions of communicative interaction and cultural transmission on natural word order behaviour. We show that both interaction and iterated learning lead to a simplification of the word order regime, and the way in which this unfolds over time is surprisingly similar under the two mechanisms. The resulting dominant word order is mostly SVO, the order of the native language of our participants. In experiment 3, we manipulate the frequency of different semantic event types, and show that this can allow SOV order, rather than SVO order, to conventionalise. Taken together, our experiments demonstrate that where pressures for naturalness and regularity are in conflict, naturalness will give way to regularity as word order becomes conventionalised through repeated usage.}
}

@article{sato:20,
  title = {Do all aspects of learning benefit from iconicity? Evidence from motion capture},
  author = {Sato, Asha and Schouwstra, Marieke and Flaherty, Molly and Kirby, Simon},
  publisher = {Cambridge University Press},
  journal = {Language and Cognition},
  volume = {12},
  number = {1},
  pages = {36--55},
  year = {2020},
  doi = {10.1017/langcog.2019.37},
  url = {https://www.cambridge.org/core/services/aop-cambridge-core/content/view/55EDF990ED0E81A85100F8F01988B7C2/S1866980819000371a.pdf/do-all-aspects-of-learning-benefit-from-iconicity-evidence-from-motion-capture.pdf},
  abstract = {Recent work suggests that not all aspects of learning benefit from an iconicity advantage (Ortega, 2017). We present the results of an artificial sign language learning experiment testing the hypothesis that iconicity may help learners to learn mappings between forms and meanings, whilst having a negative impact on learning specific features of the form. We used a 3D camera (Microsoft Kinect) to capture participants’ gestures and quantify the accuracy with which they reproduce the target gestures in two conditions. In the iconic condition, participants were shown an artificial sign language consisting of congruent gesture–meaning pairs. In the arbitrary condition, the language consisted of non-congruent gesture–meaning pairs. We quantified the accuracy of participants’ gestures using dynamic time warping (Celebi et. al., 2013). Our results show that participants in the iconic condition learn mappings more successfully than participants in the arbitrary condition, but there is no difference in the accuracy with which participants reproduce the forms. While our work confirms that iconicity helps to establish form–meaning mappings, our study did not give conclusive evidence about the effect of iconicity on production; we suggest that iconicity may only have an impact on learning forms when these are complex.}
}

@article{culbertson:20,
  title = {From the world to word order: deriving biases in noun phrase order from statistical properties of the world},
  author = {Culbertson, Jennifer and Schouwstra, Marieke and Kirby, Simon},
  publisher = {Linguistic Society of America},
  journal = {Language},
  volume = {96},
  number = {3},
  pages = {696--717},
  year = {2020},
  doi = {10.1353/lan.2020.0045},
  url = {https://www.linguisticsociety.org/sites/default/files/08_96.3Culbertson.pdf},
  abstract = {The world’s languages exhibit striking diversity. At the same time, recurring linguistic patterns suggest the possibility that this diversity is shaped by features of human cognition. One well-studied example is word order in complex noun phrases (like these two red vases). While many orders of these elements are possible, a subset appear to be preferred. It has been argued that this ordering reflects a single underlying representation of noun phrase structure, from which preferred orders are straightforwardly derived (e.g. Cinque 2005). Building on previous experimental evidence using artificial language learning (Culbertson & Adger 2014), we show that these preferred orders arise not only in existing languages, but also in improvised sequences of gestures produced by English speakers. We then use corpus data from a wide range of languages to argue that the hypothesized underlying structure of the noun phrase might be learnable from statistical features relating objects and their properties conceptually. Using an information-theoretic measure of strength of association, we find that adjectival properties (e.g. red) are on average more closely related to the objects they modify (e.g. wine) than numerosities are (e.g. two), which are in turn more closely related to the objects they modify than demonstratives are (e.g. this). It is exactly those orders which transparently reflect this—by placing adjectives closest to the noun, and demonstratives farthest away—that are more common across languages and preferred in our silent gesture experiments. These results suggest that our experience with objects in the world, combined with a preference for transparent mappings from conceptual structure to linear order, can explain constraints on noun phrase order.}
}

@article{veigabusto:22,
title = {Person and number in Catalan Sign Language pronouns},
author = {Veiga Busto, Raquel},
journal = {Sign Language and Linguistics},
year = {2022},
doi = {10.1075/sll.00069.vei},
abstract = {The category of person encodes the semantic distinction between discourse roles, and number specifies the numerosity of the referents. While these are two basic grammatical categories of human languages, they have not yet been documented in detail in many sign languages. This dissertation provides the first in-depth analysis of person and number in Catalan Sign Language (LSC) pronouns. To a lesser extent, the form and interpretation of number in nouns is also addressed. The dissertation takes a descriptive approach, but it also offers formal arguments to account for the interpretation of person and number markers. Besides, the results are contrasted with prior findings from signed and spoken languages to determine whether LSC complies with the tendencies documented in the two cat- egories across the world’s languages.
Drawing on a combination of elicited and corpus data analysis, this study shows that person and number in LSC are formally marked through a set of dis- tinctive phonological features: person is encoded through spatial features, and number by the path specifications of the sign. Further, this thesis demonstrates that person marking has an influence on the meaning of certain number mor- phemes. Thus, the same morphological operation might yield different interpre- tations depending on the person features with which it is combined.}
}

@inproceedings{veigabusto:23a,
  title = {The indefinite-interrogative affinity in sign languages: the case of Catalan Sign Language},
  author = {Veiga Busto, Raquel and Roelofsen, Floris and Navarrete González, Alexandra},
  booktitle = {Proceedings of the 4th Workshop on Inquisitiveness Below and Beyond the Sentence Boundary (InqBnB4)},
  year = {2023},
  pages={50--60},
  publisher = {Association for Computational Linguistics},
  url = {https://iwcs2023.loria.fr/files/2023/06/inqbnb4_proceedings.pdf},
  abstract = {Prior studies on spoken languages have shown that indefinite and interrogative pronouns may be formally very similar. Our research aims to understand if sign languages exhibit this type of affinity. This paper presents an overview of the phenomenon and reports on the results of two studies: a cross-linguistic survey based on a sample of 30 sign languages and an empirical investigation conducted with three deaf consultants of Catalan Sign Language (LSC). Our research shows that, in sign languages, certain signs have both existential and interrogative readings and it identifies the environments that make existential interpretations available in LSC.}
}

@book{veigabusto:23b,
title = {Person and Number. An Empirical Study of Catalan Sign Language Pronouns},
author = {Veiga Busto, Raquel},
publisher = {De Gruyter Mouton},
address = {Berlin, Boston},
url = {https://doi.org/10.1515/9783110988956},
doi = {doi:10.1515/9783110988956},
isbn = {9783110988956},
year = {2023},
keywords={Catalan Sign Language, Llengua de Signes Catalana, Person (Grammar), Number (Grammar)},
abstract={Person and number are two basic grammatical categories. However, they have not yet been exhaustively documented in many sign languages. This volume presents a thorough description of the form and interpretation of person and number in Catalan Sign Language (LSC) personal pronouns. This is the first book exploring together the two categories (and their interaction) in a sign language.
Building on a combination of elicitation methods and corpus data analysis, this book shows that person and number are encoded through a set of distinctive phonological features: person is formally marked through spatial features, and number by the path specifications of the sign. Additionally, this study provides evidence that the same number marker might have a different semantic import depending on the person features with which it is combined.
Results of this investigation contribute fresh data to cross-linguistic studies on person and number, which are largely based on evidence from spoken language only. Furthermore, while this research identifies a number of significant differences with respect to prior descriptions of person and number in other sign languages, it also demonstrates that, from a typological standpoint, the array of distinctions that LSC draws within each category is not exceptional.}
}

@incollection{veigabusto:23c,
  title = {Intérprete de lengua de signos},
  author = {Veiga Busto, Raquel},
  publisher = {Editorial Síntesis},
  booktitle = {Lingüistas de hoy. Profesiones para el siglo XXI},
  editor={Queralt Estévez (coord.), Sheila},
  pages = {117--122},
  year = {2023},
  url = {https://www.sintesis.com/claves%20de%20la%20ling%C3%BC%C3%ADstica-200/ling%C3%BCistas%20de%20hoy-ebook-3113.html}
}
