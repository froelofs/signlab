<!doctype html>
<html lang="en">
<head>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>SignLab Amsterdam</title>

<meta http-equiv="Access-Control-Allow-Origin" content="*">
<meta http-equiv="Access-Control-Allow-Methods" content="GET">
<meta http-equiv="Access-Control-Allow-Methods" content="POST">

<!-- Meta tag to make the website responsive to different types of devices -->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<!-- Icon -->
<link rel="icon" type="image/x-icon" href="images/hand-icon.png" />

<!-- =============================================== -->
<!-- Fonts -->

<!-- Fonts for grayscale theme -->
<script src="https://use.fontawesome.com/releases/v5.13.0/js/all.js" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Varela+Round" rel="stylesheet" />
<link href="https://fonts.googleapis.com/css?family=Nunito:200,200i,300,300i,400,400i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet" />
<!-- <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons"> -->
<!-- =============================================== -->
<!-- CSS files -->

<!-- CSS for Jquery autocomplete and tooltips -->
<link rel="stylesheet" href="https://code.jquery.com/ui/1.12.1/themes/smoothness/jquery-ui.css"></link>
<!-- Bootstrap core CSS -->
<link rel="stylesheet" href="css/bootstrap.min.css">
<!-- Timepicker css -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap-timepicker/0.5.2/css/bootstrap-timepicker.min.css">
<!-- CSS for question circle -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
<!-- CSS file for bootstrap grayscale theme -->
<link rel="stylesheet" href="css/grayscalestyles.css">
<!-- CSS file for flag icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.css">
<!-- CSS file for avatar panel and controls, taken from the UEA website but reduced in order to avoid clashes with bootstrap css -->
<link rel="stylesheet" href="css/cwasa-reduced.css">
<!-- CSS file for bootstrap icons -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.3.0/font/bootstrap-icons.css">

</head>


<body id="page-top" >
  <!-- onload="CWASA.init();"> -->

<div id="page-container" class="bg-light">
<div id="content-wrap">
<!--================================================================-->

<!--Navigation bar-->
<div id="nav-placeholder"></div>
<!--end of Navigation bar-->


<!--================================================================-->

<!-- About -->
<section class="projects-section bg-light fadeIn" id="About">
    <div class="container-fluid">

        <!-- Challenge Row first section -->
        <div class="row align-items-start no-gutters mb-4 mb-lg-5">
            <!-- Column for info -->
            <div class="col-12 col-md order-2">
              

                <div class="project-text pb-1 w-100 my-auto text-left no-top-padding textDIV">
                  <h2 class="mb-4">Welcome!</h2>
                  <p class="mb-6 mt-6">
                    <!-- SignLab Amsterdam is a cross-faculty research lab at the University of Amsterdam, founded in 2020.
                    It brings together a long tradition of sign linguistics in Amsterdam
                    with recent advances in artificial intelligence to obtain 
                    new linguistic insights and develop practical applications for sign language users and learners.
                     -->
                    SignLab Amsterdam was founded in 2020, with the ambition to leverage recent advances in artificial intelligence, 
                    computer vision and computer graphics to add new computational and applied dimensions to the long tradition of 
                    theoretical sign language research at the University of Amsterdam.
                    Our team includes both deaf and hearing researchers, with diverse backgrounds and types of expertise.
                    Our research agenda is driven by fundamental scientific and technological challenges but also by 
                    urgent societal issues. We collaborate with several non-academic organisations to maximise the societal 
                    impact of our work.
                    <br>
                  </p>
                  
                  <hr class="d-none d-lg-block mb-5 ml-0" />
                  <h5>Societal challenges</h5>
                  <p class="mb-4">
                    Globally, around <a href="https://wfdeaf.org/our-work/" target="_blank">70 million people</a> are deaf.
                    Evidently, deaf people have no sensory access to spoken language. 
                    What is perhaps less evident is that written texts (e.g., captions, educational materials,  
                    healthcare information) are difficult to process for many deaf people as well.
                    <!-- Several <a href="https://link.springer.com/article/10.1007/s11145-004-5894-0" target="_blank">studies</a> have shown
                    that it is relatively difficult for many deaf people to learn to read.  -->
                    To understand this as a hearing person, imagine learning to read in a language with an unfamiliar alphabet
                    (for instance, Thai, if you are used to the Roman alphabet) without being told how the characters in the 
                    alphabet are pronounced.
                    Limited access to important public services, including education and healthcare,  
                    leads to unequal opportunities and social exclusion, 
                    as witnessed for instance by high rates of
                    <a href="https://nationaldeafcenter.org/wp-content/uploads/2019/10/Deaf-People-and-Employment-in-the-United-States_-2019-7.26.19ENGLISHWEB.pdf" target="_blank">unemployment</a> 
                    and <a href="https://academic.oup.com/jdsde/article/12/1/1/435942" target="_blank">depression</a> among deaf adults.
                  </p>

                  <p class="mb-4">
                    Deaf children are especially vulnerable. Most deaf children (95%) 
                    have hearing parents, and only a small percentage of these parents (in the Netherlands, around 10%) 
                    manage to learn sign language. As a consequence, during 
                    the first years of their lives, many deaf children receive little language input that is accessible 
                    to them, which in turn often negatively affects their linguistic and cognitive development, as well as 
                    their mental well-being throughout the lifespan.
                  </p>

                  <hr class="d-none d-lg-block mb-5 ml-0" />
                  <h5>Scientific challenges</h5>
                  <p class="mb-4">
                    The language sciences have focused predominantly on spoken languages. 
                    We still know relatively little about the linguistic structure of sign languages. A complicating factor is that 
                    there is often a large amount of variation, both in terms of lexicon and in terms of grammar, 
                    even within a single sign language community. An important theoretical challenge is to 
                    characterise sign languages in a way that does justice to this variation while also capturing 
                    what is <i>not</i> subject to variation.
                  </p>
                  <p class="mb-4">
                    Another fundamental question concerns the relationship between conventionalised elements of sign languages and 
                    non-conventionalised, depictive elements which are commonplace in visual communication 
                    (especially alongside sign in purely visual communication but also alongside speech in multimodal communication), 
                    how these elements are integrated structurally and semantically.
                    <!-- , and whether they are processed the same or 
                    differently by the brain.  -->
                    
                    <!-- Finally, much remains to be discovered about how linguistic features that are 
                    specific to sign languages-such as the linguistic use of space-are acquired and processed by sign language 
                    users and learners. -->
                  </p>

                  <hr class="d-none d-lg-block mb-5 ml-0" />
                  <h5>Technological challenges</h5>
                  <p class="mb-4">
                    Sign language technologies are also highly underdeveloped. For instance, while tools like ChatGPT and Google Translate 
                    already work for more than 100 spoken languages, they don't work for any sign language yet. A major stumbling block, 
                    both for scientific and for technological progress, is that sign language data is lacking both in quantity and in quality. 
                    Sign languages do not have a written form. Most available data is therefore in the form of annotated videos, 
                    where annotations usually consist in a label for each sign occurring in the video and a translation of each utterance. 
                    Putting together such annotated video datasets is highly time-consuming. As a result, existing datasets are relatively small. 
                    For instance, the Corpus NGT (<i>Nederlandse Gebarentaal</i>, Sign Language of the Netherlands) currently contains almost 
                    180.000 annotated signs, while the Corpus Spoken Dutch contains 9.000.000 words with extensive annotations, i.e., 
                    50 times as many, and the latter is just one out of several large Dutch corpora. Moreover, the quality of these sign 
                    language datasets for scientific and technological purposes is low. Videos are 2D representations of a 3D reality. 
                    Furthermore, they often involve occlusion and motion blur. Annotations are often not consistent across datasets. 
                    Consequently, much information is lost in the process of measuring and representing the movement of signers. 
                    The field needs a much stronger foundation when it comes to data collection methodologies and data representation formats.
                  </p>

                  <hr class="d-none d-lg-block mb-5 ml-0" />

                  <!-- <h5>New methods, deeper linguistic insights</h5>
                  <p class="mb-4">
                    To investigate the structure of signs and signed sentences, we do not only make use of
                    traditional methods to collect and analyze sign language data,
                    but also develop new methods making use of motion capture equipment,
                    computer vision software, and machine learning algorithms.
                    
                    Investigating sign languages has the potential to yield important linguistic insights which
                    are more difficult to obtain by investigating spoken languages alone, because linguistic 
                    structures are sometimes easier to detect in sign languages than in spoken languages. 
                    Quite literally, sign languages often make linguistic structures
                    more directly visible.   
                  </p>-->

                  <!-- <hr class="d-none d-lg-block mb-5 ml-0" />
                  <h5>Applications for sign language users and learners</h5>
                  <p class="mb-4">
                    Scientific investigation of sign languages is not only necessary to obtain a general understanding of human languages,
                    but also has important applications.
                    Deeper insight into the grammar of sign languages is essential 
                    to develop efficient curricula for sign language learners, including sign language interpreters and 
                    hearing families of deaf children, and to lay a foundation for sign language technologies.
                  </p>
                  <hr class="d-none d-lg-block mb-5 ml-0" /> -->
              </div>
            </div> 

          <!-- Column for picture -->

          <div class="col-12 col-md-5 order-1 order-md-12 avatarGIF ml-md-5">
            
            <div class="embed-responsive embed-responsive-16by9 mb-5">
              <iframe src="https://www.youtube.com/embed/6FfPrcuE8gQ?rel=0&autoplay=1&playlist=6FfPrcuE8gQ&loop=1" title="SignLab Avatar Welcome" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div> 
            
            <!-- <div class="project-text pb-1 w-100 my-auto text-left no-top-padding textDIV">
              <h5>SignLab Open House</h5>
              <p class="mb-6 mt-6">
                Signlab is organizing another open evening on April 19, 2024. Are you coming? This evening 
                we will talk about the research we are doing sign languages.
                The open evening is held at the University Library, Singel 425 Amsterdam, Room C007 (Doelenzaal). 
                Registration is mandatory and can be done until April 12 (or until the maximum number of registrations is reached).<br><br>
                The registration form is <a href="https://uva.fra1.qualtrics.com/jfe/form/SV_6Eui1omADfYPI6G">here</a>.<br><br>
                The program is as follows: <br><br>
                6.15 PM Walk-in <br>
                6:30-8:30 PM Presenations and demos <br>
                8:30-10:00 PM Drinks! <br><br>
                The event will be in NGT and Dutch. NGT-NL interpreters will be present all evening.
                Questions or remarks? Feel free to email us at signlab@uva.nl.
                We also ask you to email us if you have registered, but can no longer come. Maybe someone else can fill the spot. <br>
                
              </p>                  -->
              <!-- <hr class="d-none d-lg-block mb-5 ml-0" /> -->

              <div class="mt-5">
                <img src="images/logo-uva.png" class="img-fluid" style="image-orientation:portrait;" alt="University of Amsterdam">
              </div>
            </div>
          </div>
        </div>
    </div>


</section>

<!-- Footer-->
<footer class="footer bg-white small text-center text-black-50">
  <div style="line-height:150%;">
    <br>
    <i class="bi bi-envelope"></i>: signlab@uva.nl
  </div>
</footer>

</div>

<!-- Javascripts -->

<!-- Jquery JS is loaded in the beginning, see above -->

<!-- jQuery -->
<script type="text/javascript" src="js/jquery.min.js"></script>

<!-- jquery ui -->
<script src="https://code.jquery.com/ui/1.12.1/jquery-ui.js"></script>

<script type="text/javascript">
//Solves naming conflicts between jquery ui and bootstrap
  $.widget.bridge('uitooltip', $.ui.tooltip);
  $.widget.bridge('uibutton', $.ui.button);
</script>

<!-- Bootstrap tooltips -->
<script type="text/javascript" src="js/popper.min.js"></script>
<!-- Bootstrap core JavaScript -->
<script type="text/javascript" src="js/bootstrap.min.js"></script>


<!-- Grayscale theme JS-->
<script type="text/javascript" src="js/grayscalescript.js"></script>
<!-- Javascript for smooth scrolling-->
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
<!-- script for timepicker -->
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap-timepicker/0.5.2/js/bootstrap-timepicker.js"></script>
<!-- script for generating avatar animations -->
<script type="text/javascript" src="cwasa/uva2021/cwa/allcsa.js"> </script>


<!-- =============================================== -->

<!-- script for communication with and set up of the avatar -->
<script language="javascript" type="text/javascript" src="js/avatar.js"></script>
<!-- script for shared functions across all pages -->
<script language="javascript" type="text/javascript" src="js/general.js"></script>
<!-- script specific to main page -->
<script language="javascript" type="text/javascript" src="js/signlab.js"></script>
<!-- These variables are defined so that the dicts from the ZonMw project can be used -->
<!-- <script type="text/javascript">
  var sentPath;
  var vidPath;
  var varPath;
</script> -->
</div>
</body>
</html>
